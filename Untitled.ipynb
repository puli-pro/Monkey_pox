{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52e9939b-e3a2-4600-9daf-015176065eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Systemic Illness</th>\n",
       "      <th>Rectal Pain</th>\n",
       "      <th>Sore Throat</th>\n",
       "      <th>Penile Oedema</th>\n",
       "      <th>Oral Lesions</th>\n",
       "      <th>Solitary Lesion</th>\n",
       "      <th>Swollen Tonsils</th>\n",
       "      <th>HIV Infection</th>\n",
       "      <th>Sexually Transmitted Infection</th>\n",
       "      <th>MonkeyPox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P1</td>\n",
       "      <td>Fever</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P2</td>\n",
       "      <td>Fever</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P4</td>\n",
       "      <td>Swollen Lymph Nodes</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>P24995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>P24996</td>\n",
       "      <td>Fever</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>P24997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>P24998</td>\n",
       "      <td>Swollen Lymph Nodes</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>P24999</td>\n",
       "      <td>Swollen Lymph Nodes</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Patient_ID     Systemic Illness  Rectal Pain  Sore Throat  \\\n",
       "0             P0                  NaN        False         True   \n",
       "1             P1                Fever         True        False   \n",
       "2             P2                Fever        False         True   \n",
       "3             P3                  NaN         True        False   \n",
       "4             P4  Swollen Lymph Nodes         True         True   \n",
       "...          ...                  ...          ...          ...   \n",
       "24995     P24995                  NaN         True         True   \n",
       "24996     P24996                Fever        False         True   \n",
       "24997     P24997                  NaN         True         True   \n",
       "24998     P24998  Swollen Lymph Nodes        False         True   \n",
       "24999     P24999  Swollen Lymph Nodes        False        False   \n",
       "\n",
       "       Penile Oedema  Oral Lesions  Solitary Lesion  Swollen Tonsils  \\\n",
       "0               True          True            False             True   \n",
       "1               True          True            False            False   \n",
       "2               True         False            False            False   \n",
       "3              False         False             True             True   \n",
       "4               True         False            False             True   \n",
       "...              ...           ...              ...              ...   \n",
       "24995          False          True             True            False   \n",
       "24996           True         False             True             True   \n",
       "24997          False         False             True             True   \n",
       "24998          False          True             True             True   \n",
       "24999           True         False            False             True   \n",
       "\n",
       "       HIV Infection  Sexually Transmitted Infection MonkeyPox  \n",
       "0              False                           False  Negative  \n",
       "1               True                           False  Positive  \n",
       "2               True                           False  Positive  \n",
       "3               True                           False  Positive  \n",
       "4               True                           False  Positive  \n",
       "...              ...                             ...       ...  \n",
       "24995          False                            True  Positive  \n",
       "24996           True                            True  Positive  \n",
       "24997          False                           False  Positive  \n",
       "24998          False                           False  Negative  \n",
       "24999           True                           False  Positive  \n",
       "\n",
       "[25000 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(\"DATA.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3f01676-67db-43b6-af2d-7e7ae1cceb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Patient_ID', 'Systemic Illness', 'Rectal Pain', 'Sore Throat',\n",
       "       'Penile Oedema', 'Oral Lesions', 'Solitary Lesion', 'Swollen Tonsils',\n",
       "       'HIV Infection', 'Sexually Transmitted Infection', 'MonkeyPox'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4a0ae9f-fc61-4506-9cc9-373de3a272f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of       Patient_ID     Systemic Illness  Rectal Pain  Sore Throat  \\\n",
       "0             P0                  NaN        False         True   \n",
       "1             P1                Fever         True        False   \n",
       "2             P2                Fever        False         True   \n",
       "3             P3                  NaN         True        False   \n",
       "4             P4  Swollen Lymph Nodes         True         True   \n",
       "...          ...                  ...          ...          ...   \n",
       "24995     P24995                  NaN         True         True   \n",
       "24996     P24996                Fever        False         True   \n",
       "24997     P24997                  NaN         True         True   \n",
       "24998     P24998  Swollen Lymph Nodes        False         True   \n",
       "24999     P24999  Swollen Lymph Nodes        False        False   \n",
       "\n",
       "       Penile Oedema  Oral Lesions  Solitary Lesion  Swollen Tonsils  \\\n",
       "0               True          True            False             True   \n",
       "1               True          True            False            False   \n",
       "2               True         False            False            False   \n",
       "3              False         False             True             True   \n",
       "4               True         False            False             True   \n",
       "...              ...           ...              ...              ...   \n",
       "24995          False          True             True            False   \n",
       "24996           True         False             True             True   \n",
       "24997          False         False             True             True   \n",
       "24998          False          True             True             True   \n",
       "24999           True         False            False             True   \n",
       "\n",
       "       HIV Infection  Sexually Transmitted Infection MonkeyPox  \n",
       "0              False                           False  Negative  \n",
       "1               True                           False  Positive  \n",
       "2               True                           False  Positive  \n",
       "3               True                           False  Positive  \n",
       "4               True                           False  Positive  \n",
       "...              ...                             ...       ...  \n",
       "24995          False                            True  Positive  \n",
       "24996           True                            True  Positive  \n",
       "24997          False                           False  Positive  \n",
       "24998          False                           False  Negative  \n",
       "24999           True                           False  Positive  \n",
       "\n",
       "[25000 rows x 11 columns]>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "402ef58e-6908-4982-8a2b-8558982aaa13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Systemic Illness</th>\n",
       "      <th>Rectal Pain</th>\n",
       "      <th>Sore Throat</th>\n",
       "      <th>Penile Oedema</th>\n",
       "      <th>Oral Lesions</th>\n",
       "      <th>Solitary Lesion</th>\n",
       "      <th>Swollen Tonsils</th>\n",
       "      <th>HIV Infection</th>\n",
       "      <th>Sexually Transmitted Infection</th>\n",
       "      <th>MonkeyPox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25000</td>\n",
       "      <td>18784</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>25000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>P0</td>\n",
       "      <td>Fever</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>6382</td>\n",
       "      <td>12655</td>\n",
       "      <td>12554</td>\n",
       "      <td>12612</td>\n",
       "      <td>12514</td>\n",
       "      <td>12527</td>\n",
       "      <td>12533</td>\n",
       "      <td>12584</td>\n",
       "      <td>12554</td>\n",
       "      <td>15909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Patient_ID Systemic Illness Rectal Pain Sore Throat Penile Oedema  \\\n",
       "count       25000            18784       25000       25000         25000   \n",
       "unique      25000                3           2           2             2   \n",
       "top            P0            Fever       False        True          True   \n",
       "freq            1             6382       12655       12554         12612   \n",
       "\n",
       "       Oral Lesions Solitary Lesion Swollen Tonsils HIV Infection  \\\n",
       "count         25000           25000           25000         25000   \n",
       "unique            2               2               2             2   \n",
       "top           False            True            True          True   \n",
       "freq          12514           12527           12533         12584   \n",
       "\n",
       "       Sexually Transmitted Infection MonkeyPox  \n",
       "count                           25000     25000  \n",
       "unique                              2         2  \n",
       "top                             False  Positive  \n",
       "freq                            12554     15909  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a201899-deab-41c1-a88d-190fbf293713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Patient_ID                           0\n",
       "Systemic Illness                  6216\n",
       "Rectal Pain                          0\n",
       "Sore Throat                          0\n",
       "Penile Oedema                        0\n",
       "Oral Lesions                         0\n",
       "Solitary Lesion                      0\n",
       "Swollen Tonsils                      0\n",
       "HIV Infection                        0\n",
       "Sexually Transmitted Infection       0\n",
       "MonkeyPox                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CHECKING  NO OF MISSING VALUES IN EACH COLUMN\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b24667a-1bae-408c-bc37-cb6fb2eb7ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MonkeyPox\n",
       "Positive    15909\n",
       "Negative     9091\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DISTRIBUTION  OF Positive cases and negative cases \n",
    "data['MonkeyPox'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5670639-1afb-43ae-abd4-2093567ca58d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MonkeyPox\n",
       "Positive    15909\n",
       "Negative     9091\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DISTRIBUTION  OF Positive cases and negative cases \n",
    "data['MonkeyPox'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92829eb9-f11c-4d88-afc4-af26e14affa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of No Positive cases: 63.64%\n",
      "Percentage of Negative cases: 36.36%\n"
     ]
    }
   ],
   "source": [
    "print('Percentage of No Positive cases: {}%'.format(round(data.MonkeyPox.value_counts()['Positive']/len(data) * 100.0,2)))\n",
    "print('Percentage of Negative cases: {}%'.format(round(data.MonkeyPox.value_counts()['Negative']/len(data) * 100.0,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "585b3bfa-a21c-4669-91f9-3eb36cd0c482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIQUE VALUES IN A COLUMN'Patient_ID':['P0' 'P1' 'P2' ... 'P24997' 'P24998' 'P24999']'\n",
      "\n",
      "UNIQUE VALUES IN A COLUMN'Systemic Illness':[nan 'Fever' 'Swollen Lymph Nodes' 'Muscle Aches and Pain']'\n",
      "\n",
      "UNIQUE VALUES IN A COLUMN'Rectal Pain':[False  True]'\n",
      "\n",
      "UNIQUE VALUES IN A COLUMN'Sore Throat':[ True False]'\n",
      "\n",
      "UNIQUE VALUES IN A COLUMN'Penile Oedema':[ True False]'\n",
      "\n",
      "UNIQUE VALUES IN A COLUMN'Oral Lesions':[ True False]'\n",
      "\n",
      "UNIQUE VALUES IN A COLUMN'Solitary Lesion':[False  True]'\n",
      "\n",
      "UNIQUE VALUES IN A COLUMN'Swollen Tonsils':[ True False]'\n",
      "\n",
      "UNIQUE VALUES IN A COLUMN'HIV Infection':[False  True]'\n",
      "\n",
      "UNIQUE VALUES IN A COLUMN'Sexually Transmitted Infection':[False  True]'\n",
      "\n",
      "UNIQUE VALUES IN A COLUMN'MonkeyPox':['Negative' 'Positive']'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Unique values present in every column  \n",
    "for col in data.columns:\n",
    "    unique_values=data[col].unique()\n",
    "    print(f\"UNIQUE VALUES IN A COLUMN'{col}':{unique_values}'\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c29f8ca-e1b9-4cd8-8e05-f282ee8a72ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pulip\\AppData\\Local\\Temp\\ipykernel_2012\\270484086.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[col]=data[col].replace({True:1,False:0})\n"
     ]
    }
   ],
   "source": [
    "#Converting the text into numerical of all the columns \n",
    "features=[\"Rectal Pain\",\"Sore Throat\",\"Penile Oedema\",\"Oral Lesions\",\"Solitary Lesion\",\"Swollen Tonsils\",\"HIV Infection\",\"Sexually Transmitted Infection\"]\n",
    "for col in features:\n",
    "    data[col]=data[col].replace({True:1,False:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2d9da3c-5cec-4f85-a42b-d790bb2fd68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pulip\\AppData\\Local\\Temp\\ipykernel_2012\\2458704213.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data['MonkeyPox']=data['MonkeyPox'].replace({'Negative':0,'Positive':1})\n"
     ]
    }
   ],
   "source": [
    "data['MonkeyPox']=data['MonkeyPox'].replace({'Negative':0,'Positive':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4fc027a2-0700-455e-93b0-33b51b53563b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pulip\\AppData\\Local\\Temp\\ipykernel_2012\\3671776756.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data['Systemic Illness']=data['Systemic Illness'].replace({'None':0,'Fever':1,'Swollen Lymph Nodes':2,'Muscle Aches and Pain':3})\n"
     ]
    }
   ],
   "source": [
    "# None =0  fever =1   Swollen Lymph Nodes=2     Muscle Aches and Pain=3\n",
    "data['Systemic Illness']=data['Systemic Illness'].replace({'None':0,'Fever':1,'Swollen Lymph Nodes':2,'Muscle Aches and Pain':3})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a96de7e-f286-4858-a5e5-c2452d8ccc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Patient_ID'] = data['Patient_ID'].str.replace('P','', regex=False).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a39bc49e-a47b-488c-8f49-01b831dcf41c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Systemic Illness</th>\n",
       "      <th>Rectal Pain</th>\n",
       "      <th>Sore Throat</th>\n",
       "      <th>Penile Oedema</th>\n",
       "      <th>Oral Lesions</th>\n",
       "      <th>Solitary Lesion</th>\n",
       "      <th>Swollen Tonsils</th>\n",
       "      <th>HIV Infection</th>\n",
       "      <th>Sexually Transmitted Infection</th>\n",
       "      <th>MonkeyPox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>24995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>24996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>24997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>24998</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>24999</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Patient_ID  Systemic Illness  Rectal Pain  Sore Throat  Penile Oedema  \\\n",
       "0               0               NaN            0            1              1   \n",
       "1               1               1.0            1            0              1   \n",
       "2               2               1.0            0            1              1   \n",
       "3               3               NaN            1            0              0   \n",
       "4               4               2.0            1            1              1   \n",
       "...           ...               ...          ...          ...            ...   \n",
       "24995       24995               NaN            1            1              0   \n",
       "24996       24996               1.0            0            1              1   \n",
       "24997       24997               NaN            1            1              0   \n",
       "24998       24998               2.0            0            1              0   \n",
       "24999       24999               2.0            0            0              1   \n",
       "\n",
       "       Oral Lesions  Solitary Lesion  Swollen Tonsils  HIV Infection  \\\n",
       "0                 1                0                1              0   \n",
       "1                 1                0                0              1   \n",
       "2                 0                0                0              1   \n",
       "3                 0                1                1              1   \n",
       "4                 0                0                1              1   \n",
       "...             ...              ...              ...            ...   \n",
       "24995             1                1                0              0   \n",
       "24996             0                1                1              1   \n",
       "24997             0                1                1              0   \n",
       "24998             1                1                1              0   \n",
       "24999             0                0                1              1   \n",
       "\n",
       "       Sexually Transmitted Infection  MonkeyPox  \n",
       "0                                   0          0  \n",
       "1                                   0          1  \n",
       "2                                   0          1  \n",
       "3                                   0          1  \n",
       "4                                   0          1  \n",
       "...                               ...        ...  \n",
       "24995                               1          1  \n",
       "24996                               1          1  \n",
       "24997                               0          1  \n",
       "24998                               0          0  \n",
       "24999                               0          1  \n",
       "\n",
       "[25000 rows x 11 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1899a6-fb58-4bb3-85ee-da575b367d51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f459cd6-4e6f-416c-8aba-437840d34735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient_ID                           0\n",
      "Systemic Illness                  6216\n",
      "Rectal Pain                          0\n",
      "Sore Throat                          0\n",
      "Penile Oedema                        0\n",
      "Oral Lesions                         0\n",
      "Solitary Lesion                      0\n",
      "Swollen Tonsils                      0\n",
      "HIV Infection                        0\n",
      "Sexually Transmitted Infection       0\n",
      "MonkeyPox                            0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "MonkeyPox\n",
      "Positive    15909\n",
      "Negative     9091\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentage of No Positive cases: 63.64%\n",
      "Percentage of Negative cases: 36.36%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data=pd.read_csv(\"DATA.csv\")\n",
    "# CHECKING  NO OF MISSING VALUES IN EACH COLUMN\n",
    "print(data.isnull().sum())\n",
    "print()\n",
    "print()\n",
    "\n",
    "# DISTRIBUTION  OF Positive cases and negative cases \n",
    "print(data['MonkeyPox'].value_counts())\n",
    "print()\n",
    "\n",
    "print('Percentage of No Positive cases: {}%'.format(round(data.MonkeyPox.value_counts()['Positive']/len(data) * 100.0,2)))\n",
    "print('Percentage of Negative cases: {}%'.format(round(data.MonkeyPox.value_counts()['Negative']/len(data) * 100.0,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c62242-e85c-4a9e-b2a5-730cf6126652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4bfb54a-1f0e-44af-867e-ec837c3334a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIQUE VALUES IN A COLUMN'Patient_ID':['P0' 'P1' 'P2' ... 'P24997' 'P24998' 'P24999']'\n",
      "\n",
      "UNIQUE VALUES IN A COLUMN'Systemic Illness':[nan 'Fever' 'Swollen Lymph Nodes' 'Muscle Aches and Pain']'\n",
      "\n",
      "UNIQUE VALUES IN A COLUMN'Rectal Pain':[False  True]'\n",
      "\n",
      "UNIQUE VALUES IN A COLUMN'Sore Throat':[ True False]'\n",
      "\n",
      "UNIQUE VALUES IN A COLUMN'Penile Oedema':[ True False]'\n",
      "\n",
      "UNIQUE VALUES IN A COLUMN'Oral Lesions':[ True False]'\n",
      "\n",
      "UNIQUE VALUES IN A COLUMN'Solitary Lesion':[False  True]'\n",
      "\n",
      "UNIQUE VALUES IN A COLUMN'Swollen Tonsils':[ True False]'\n",
      "\n",
      "UNIQUE VALUES IN A COLUMN'HIV Infection':[False  True]'\n",
      "\n",
      "UNIQUE VALUES IN A COLUMN'Sexually Transmitted Infection':[False  True]'\n",
      "\n",
      "UNIQUE VALUES IN A COLUMN'MonkeyPox':['Negative' 'Positive']'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pulip\\AppData\\Local\\Temp\\ipykernel_2012\\3847041099.py:10: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[col]=data[col].replace({True:1,False:0})\n",
      "C:\\Users\\pulip\\AppData\\Local\\Temp\\ipykernel_2012\\3847041099.py:12: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data['MonkeyPox']=data['MonkeyPox'].replace({'Negative':0,'Positive':1})\n",
      "C:\\Users\\pulip\\AppData\\Local\\Temp\\ipykernel_2012\\3847041099.py:15: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data['Systemic Illness']=data['Systemic Illness'].replace({'None':0,'Fever':1,'Swollen Lymph Nodes':2,'Muscle Aches and Pain':3})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Systemic Illness</th>\n",
       "      <th>Rectal Pain</th>\n",
       "      <th>Sore Throat</th>\n",
       "      <th>Penile Oedema</th>\n",
       "      <th>Oral Lesions</th>\n",
       "      <th>Solitary Lesion</th>\n",
       "      <th>Swollen Tonsils</th>\n",
       "      <th>HIV Infection</th>\n",
       "      <th>Sexually Transmitted Infection</th>\n",
       "      <th>MonkeyPox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>24995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>24996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>24997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>24998</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>24999</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Patient_ID  Systemic Illness  Rectal Pain  Sore Throat  Penile Oedema  \\\n",
       "0               0               NaN            0            1              1   \n",
       "1               1               1.0            1            0              1   \n",
       "2               2               1.0            0            1              1   \n",
       "3               3               NaN            1            0              0   \n",
       "4               4               2.0            1            1              1   \n",
       "...           ...               ...          ...          ...            ...   \n",
       "24995       24995               NaN            1            1              0   \n",
       "24996       24996               1.0            0            1              1   \n",
       "24997       24997               NaN            1            1              0   \n",
       "24998       24998               2.0            0            1              0   \n",
       "24999       24999               2.0            0            0              1   \n",
       "\n",
       "       Oral Lesions  Solitary Lesion  Swollen Tonsils  HIV Infection  \\\n",
       "0                 1                0                1              0   \n",
       "1                 1                0                0              1   \n",
       "2                 0                0                0              1   \n",
       "3                 0                1                1              1   \n",
       "4                 0                0                1              1   \n",
       "...             ...              ...              ...            ...   \n",
       "24995             1                1                0              0   \n",
       "24996             0                1                1              1   \n",
       "24997             0                1                1              0   \n",
       "24998             1                1                1              0   \n",
       "24999             0                0                1              1   \n",
       "\n",
       "       Sexually Transmitted Infection  MonkeyPox  \n",
       "0                                   0          0  \n",
       "1                                   0          1  \n",
       "2                                   0          1  \n",
       "3                                   0          1  \n",
       "4                                   0          1  \n",
       "...                               ...        ...  \n",
       "24995                               1          1  \n",
       "24996                               1          1  \n",
       "24997                               0          1  \n",
       "24998                               0          0  \n",
       "24999                               0          1  \n",
       "\n",
       "[25000 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Unique values present in every column  \n",
    "for col in data.columns:\n",
    "    unique_values=data[col].unique()\n",
    "    print(f\"UNIQUE VALUES IN A COLUMN'{col}':{unique_values}'\")\n",
    "    print()\n",
    "\n",
    "#Converting the text into numerical of all the columns \n",
    "features=[\"Rectal Pain\",\"Sore Throat\",\"Penile Oedema\",\"Oral Lesions\",\"Solitary Lesion\",\"Swollen Tonsils\",\"HIV Infection\",\"Sexually Transmitted Infection\"]\n",
    "for col in features:\n",
    "    data[col]=data[col].replace({True:1,False:0})\n",
    "    \n",
    "data['MonkeyPox']=data['MonkeyPox'].replace({'Negative':0,'Positive':1})\n",
    "\n",
    "# None =0  fever =1   Swollen Lymph Nodes=2     Muscle Aches and Pain=3\n",
    "data['Systemic Illness']=data['Systemic Illness'].replace({'None':0,'Fever':1,'Swollen Lymph Nodes':2,'Muscle Aches and Pain':3})\n",
    "\n",
    "data['Patient_ID'] = data['Patient_ID'].str.replace('P','', regex=False).astype(int)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5602ce4-ffa0-49a1-8024-6457607a44e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example: Visualizing the distribution of positive and negative cases\n",
    "sns.countplot(x='MonkeyPox', data=data)\n",
    "plt.title('Distribution of Monkeypox Cases')\n",
    "plt.xlabel('Monkeypox Status')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "sns.countplot(x='MonkeyPox', hue='Rectal Pain', data=data)\n",
    "plt.title('Distribution of Monkeypox Cases by Rectal Pain Status')\n",
    "plt.xlabel('Monkeypox Status')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Rectal Pain', loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4d4120-900f-4ae3-9678-c86db10baec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f47e90-979b-4371-8b49-786c9c6851aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3069832-5b89-4c2b-953d-32e203863f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6623 - accuracy: 0.6286 - val_loss: 0.6485 - val_accuracy: 0.6482\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6596 - accuracy: 0.6294 - val_loss: 0.6494 - val_accuracy: 0.6482\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6500 - val_accuracy: 0.6482\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6516 - val_accuracy: 0.6482\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6493 - val_accuracy: 0.6482\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6485 - val_accuracy: 0.6482\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6491 - val_accuracy: 0.6482\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6596 - accuracy: 0.6294 - val_loss: 0.6499 - val_accuracy: 0.6482\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6596 - accuracy: 0.6294 - val_loss: 0.6503 - val_accuracy: 0.6482\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6485 - val_accuracy: 0.6482\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6596 - accuracy: 0.6294 - val_loss: 0.6500 - val_accuracy: 0.6482\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6596 - accuracy: 0.6294 - val_loss: 0.6492 - val_accuracy: 0.6482\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6596 - accuracy: 0.6294 - val_loss: 0.6504 - val_accuracy: 0.6482\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6496 - val_accuracy: 0.6482\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6507 - val_accuracy: 0.6482\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6490 - val_accuracy: 0.6482\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6487 - val_accuracy: 0.6482\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6488 - val_accuracy: 0.6482\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6501 - val_accuracy: 0.6482\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6593 - accuracy: 0.6294 - val_loss: 0.6487 - val_accuracy: 0.6482\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6596 - accuracy: 0.6294 - val_loss: 0.6497 - val_accuracy: 0.6482\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6493 - val_accuracy: 0.6482\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6497 - val_accuracy: 0.6482\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6496 - val_accuracy: 0.6482\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6487 - val_accuracy: 0.6482\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6489 - val_accuracy: 0.6482\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6489 - val_accuracy: 0.6482\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6497 - val_accuracy: 0.6482\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6505 - val_accuracy: 0.6482\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6503 - val_accuracy: 0.6482\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6488 - val_accuracy: 0.6482\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6485 - val_accuracy: 0.6482\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6493 - val_accuracy: 0.6482\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6490 - val_accuracy: 0.6482\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6495 - val_accuracy: 0.6482\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6494 - val_accuracy: 0.6482\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6487 - val_accuracy: 0.6482\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6489 - val_accuracy: 0.6482\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6488 - val_accuracy: 0.6482\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6493 - val_accuracy: 0.6482\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6490 - val_accuracy: 0.6482\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6596 - accuracy: 0.6294 - val_loss: 0.6496 - val_accuracy: 0.6482\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6493 - val_accuracy: 0.6482\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6497 - val_accuracy: 0.6482\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6493 - val_accuracy: 0.6482\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6491 - val_accuracy: 0.6482\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.6593 - accuracy: 0.6294 - val_loss: 0.6515 - val_accuracy: 0.6482\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6488 - val_accuracy: 0.6482\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6488 - val_accuracy: 0.6482\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6505 - val_accuracy: 0.6482\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.6501 - accuracy: 0.6492\n",
      "157/157 [==============================] - 0s 1ms/step\n",
      "\n",
      "--- Performance Metrics ---\n",
      "Test Accuracy: 64.92%\n",
      "Precision: 64.92%\n",
      "Recall: 100.00%\n",
      "F1 Score: 78.73%\n",
      "AUC-ROC: 50.00%\n",
      "Specificity: 0.00%\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "[[   0 1754]\n",
      " [   0 3246]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pulip\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\pulip\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\pulip\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Assuming your data is already preprocessed and stored in 'data'\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop(['MonkeyPox'], axis=1)  # Features (11 features)\n",
    "y = data['MonkeyPox']  # Target variable (0 for Negative, 1 for Positive)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the features (optional but recommended)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Build the ANN model with an explicit input layer\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(X_train.shape[1],)),  # Explicit input layer with number of features\n",
    "    keras.layers.Dense(128, activation='relu'),       # First hidden layer with 128 neurons\n",
    "    keras.layers.Dense(64, activation='relu'),        # Second hidden layer with 64 neurons\n",
    "    keras.layers.Dense(1, activation='sigmoid')       # Output layer for binary classification\n",
    "])  \n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "y_pred_prob = model.predict(X_test).flatten()  # Get predicted probabilities\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)       # Convert probabilities to binary predictions\n",
    "\n",
    "# Calculate performance metrics\n",
    "classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "auc_roc = roc_auc_score(y_test, y_pred_prob)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "TN = conf_matrix[0][0]  # True Negatives\n",
    "FP = conf_matrix[0][1]  # False Positives\n",
    "\n",
    "specificity = TN / (TN + FP) if (TN + FP) > 0 else 0  # Specificity calculation\n",
    "\n",
    "# Print all results at once\n",
    "print(\"\\n--- Performance Metrics ---\")\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {classification_rep['1']['precision'] * 100:.2f}%\")\n",
    "print(f\"Recall: {classification_rep['1']['recall'] * 100:.2f}%\")\n",
    "print(f\"F1 Score: {classification_rep['1']['f1-score'] * 100:.2f}%\")\n",
    "print(f\"AUC-ROC: {auc_roc * 100:.2f}%\")\n",
    "print(f\"Specificity: {specificity * 100:.2f}%\")\n",
    "\n",
    "# Display confusion matrix\n",
    "print(\"\\n--- Confusion Matrix ---\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c778dc-6438-4638-b4a6-5a62487e887f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fee31c3-14e0-4416-9764-ce69db624411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7f02f42-a4ae-421e-8024-4dd7ba632d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkkAAAHFCAYAAADmGm0KAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB7oklEQVR4nO3deVyU1f4H8M/MADPsq+yyuCDuC7iSmlmUpjfrmmaWa3XNJcmrt7q26c0o+2W2qGW5tJjZZtduppKaomaZirtioqICIiAM6wAzz++Pw8wwMiDLDMPyeb9e85qHZ57lzAPM851zvuccmSRJEoiIiIjIhNzWBSAiIiJqihgkEREREZnBIImIiIjIDAZJRERERGYwSCIiIiIyg0ESERERkRkMkoiIiIjMYJBEREREZAaDJCIiIiIzGCQRUaNZv349ZDIZZDIZfv311yqvS5KEDh06QCaT4c4777TouWUyGV599dU673fp0iXIZDKsX7/eItsRUfPBIImIGp2rqyvWrFlTZf2ePXtw4cIFuLq62qBURESmGCQRUaMbP348vvvuO6jVapP1a9aswcCBAxESEmKjkhERGTFIIqJGN2HCBADAxo0bDevy8vLw3XffYdq0aWb3ycnJwcyZMxEUFAQHBwe0a9cOCxcuhEajMdlOrVbjySefhLe3N1xcXHDfffchOTnZ7DHPnz+PRx99FL6+vlAqlejcuTNWrFhhoXcp7Nu3D8OHD4erqyucnJwwaNAg/PTTTybbFBUVYf78+QgPD4dKpYKXlxeio6NNrk9KSgoeeeQRBAYGQqlUws/PD8OHD0dSUpJFy0tERna2LgARtT5ubm4YO3Ys1q5di3/84x8ARMAkl8sxfvx4LF++3GT7kpISDBs2DBcuXMCiRYvQo0cPJCYmIj4+HklJSYagQ5IkjBkzBgcOHMDLL7+Mvn37Yv/+/RgxYkSVMpw+fRqDBg1CSEgI3n77bfj7+2P79u145plnkJWVhVdeeaXB73PPnj2455570KNHD6xZswZKpRIrV67E6NGjsXHjRowfPx4AMG/ePHz++ed47bXX0Lt3bxQWFuLkyZPIzs42HGvkyJHQarVYunQpQkJCkJWVhQMHDiA3N7fB5SSiakhERI1k3bp1EgDp0KFD0u7duyUA0smTJyVJkqS+fftKU6ZMkSRJkrp27SoNHTrUsN+HH34oAZC+/vprk+O9+eabEgBpx44dkiRJ0s8//ywBkN59912T7ZYsWSIBkF555RXDunvvvVcKDg6W8vLyTLadPXu2pFKppJycHEmSJOnixYsSAGndunU1vjdz2w0YMEDy9fWV8vPzDevKy8ulbt26ScHBwZJOp5MkSZK6desmjRkzptpjZ2VlSQCk5cuX11gGIrIsNrcRkU0MHToU7du3x9q1a3HixAkcOnSo2qa2Xbt2wdnZGWPHjjVZP2XKFADAzp07AQC7d+8GAEycONFku0cffdTk55KSEuzcuRMPPvggnJycUF5ebniMHDkSJSUlOHjwYIPeX2FhIX7//XeMHTsWLi4uhvUKhQKPP/44rl69inPnzgEA+vXrh59//hnPP/88fv31VxQXF5scy8vLC+3bt8dbb72FZcuW4ejRo9DpdA0qHxHdHoMkIrIJmUyGqVOn4osvvsCHH36IiIgIDB482Oy22dnZ8Pf3h0wmM1nv6+sLOzs7Q7NUdnY27Ozs4O3tbbKdv79/leOVl5fj/fffh729vclj5MiRAICsrKwGvb+bN29CkiQEBARUeS0wMNBQDgB477338Nxzz+GHH37AsGHD4OXlhTFjxuD8+fMAxLXauXMn7r33XixduhR9+vRBmzZt8MwzzyA/P79B5SSi6jFIIiKbmTJlCrKysvDhhx9i6tSp1W7n7e2N69evQ5Ikk/WZmZkoLy+Hj4+PYbvy8nKTXB4AyMjIMPnZ09MTCoUCU6ZMwaFDh8w+9MFSfXl6ekIulyM9Pb3Ka2lpaQBgKLezszMWLVqEs2fPIiMjA6tWrcLBgwcxevRowz6hoaFYs2YNMjIycO7cOTz77LNYuXIlFixY0KByElH1GCQRkc0EBQVhwYIFGD16NCZPnlztdsOHD0dBQQF++OEHk/WfffaZ4XUAGDZsGABgw4YNJtt9+eWXJj87OTlh2LBhOHr0KHr06IHo6Ogqj1tro+rK2dkZ/fv3x/fff2/SfKbT6fDFF18gODgYERERVfbz8/PDlClTMGHCBJw7dw5FRUVVtomIiMCLL76I7t2748iRIw0qJxFVj73biMim3njjjdtuM2nSJKxYsQKTJ0/GpUuX0L17d+zbtw+vv/46Ro4cibvvvhsAEBsbiyFDhuBf//oXCgsLER0djf379+Pzzz+vcsx3330Xd9xxBwYPHoynn34aYWFhyM/Px19//YUff/wRu3btavB7i4+Pxz333INhw4Zh/vz5cHBwwMqVK3Hy5Els3LjR0HzYv39/jBo1Cj169ICnpyfOnDmDzz//HAMHDoSTkxOOHz+O2bNn4+GHH0bHjh3h4OCAXbt24fjx43j++ecbXE4iMo9BEhE1eSqVCrt378bChQvx1ltv4caNGwgKCsL8+fNNuurL5XJs2bIF8+bNw9KlS1FaWoqYmBhs3boVkZGRJsfs0qULjhw5gv/85z948cUXkZmZCQ8PD3Ts2LHBTW16Q4cOxa5du/DKK69gypQp0Ol06NmzJ7Zs2YJRo0YZtrvrrruwZcsWvPPOOygqKkJQUBAmTZqEhQsXAhA5Ve3bt8fKlStx5coVyGQytGvXDm+//TbmzJljkbISUVUy6dZGfiIiIiJiThIRERGROQySiIiIiMxgkERERERkBoMkIiIiIjMYJBERERGZwSCJiIiIyAyOk1RPOp0OaWlpcHV1rTKfFBERETVNkiQhPz8fgYGBkMtrritikFRPaWlpaNu2ra2LQURERPVw5coVBAcH17gNg6R6cnV1BSAuspubm41LQ0RERLWhVqvRtm1bw328JgyS6knfxObm5sYgiYiIqJmpTaoME7eJiIiIzGCQRERERGQGgyQiIiIiM5iTZGVarRZlZWW2LgZZgL29PRQKha2LQUREjYRBkpVIkoSMjAzk5ubauihkQR4eHvD39+fYWERErQCDJCvRB0i+vr5wcnLiTbWZkyQJRUVFyMzMBAAEBATYuERERGRtDJKsQKvVGgIkb29vWxeHLMTR0REAkJmZCV9fXza9ERG1cEzctgJ9DpKTk5ONS0KWpv+dMs+MiKjlY5BkRWxia3n4OyUiaj0YJBERERGZwSCJrO7OO+9EXFycrYtBRERUJ0zcJoPbNSVNnjwZ69evr/Nxv//+e9jb29ezVERERLbBIKmJkSQJ5VoJOkhQ2jVu76n09HTD8qZNm/Dyyy/j3LlzhnX63l16ZWVltQp+vLy8LFdIIiKiRsLmtiYmp7AUZzLUSM8tafRz+/v7Gx7u7u6QyWSGn0tKSuDh4YGvv/4ad955J1QqFb744gtkZ2djwoQJCA4OhpOTE7p3746NGzeaHPfW5rawsDC8/vrrmDZtGlxdXRESEoLVq1c38rslIiKqGYOkRiJJEopKy2/7KNfpUFKmRV5xWa22v91DkiSLvo/nnnsOzzzzDM6cOYN7770XJSUliIqKwv/+9z+cPHkSTz31FB5//HH8/vvvNR7n7bffRnR0NI4ePYqZM2fi6aefxtmzZy1aViIiooZgc1sjKS7TosvL2xv9vKcX3wsnB8v9muPi4vDQQw+ZrJs/f75hec6cOdi2bRu++eYb9O/fv9rjjBw5EjNnzgQgAq933nkHv/76KyIjIy1WViIiooaweU3SypUrER4eDpVKhaioKCQmJta4vUajwcKFCxEaGgqlUon27dtj7dq1Jtvk5uZi1qxZCAgIgEqlQufOnbF161bD6/Hx8ejbty9cXV3h6+uLMWPGmOTeUPWio6NNftZqtViyZAl69OgBb29vuLi4YMeOHUhNTa3xOD169DAs65v19FN+EBERNQU2rUnatGkT4uLisHLlSsTExOCjjz7CiBEjcPr0aYSEhJjdZ9y4cbh+/TrWrFmDDh06IDMzE+Xl5YbXS0tLcc8998DX1xfffvstgoODceXKFbi6uhq22bNnD2bNmoW+ffuivLwcCxcuRGxsLE6fPg1nZ2ervFdHewVOL763Vtuev14ATbkWod5OcFU1rFeYo71lk79vvT5vv/023nnnHSxfvhzdu3eHs7Mz4uLiUFpaWuNxbk34lslk0Ol0Fi0rERFRQ9g0SFq2bBmmT5+OJ554AgCwfPlybN++HatWrUJ8fHyV7bdt24Y9e/YgJSXF0GMqLCzMZJu1a9ciJycHBw4cMNyIQ0NDqxynsnXr1sHX1xeHDx/GkCFDLPX2TMhkslo3e7k72kNdAtjJ5RZtKrOGxMREPPDAA3jssccAADqdDufPn0fnzp1tXDIiIqKGsVlzW2lpKQ4fPozY2FiT9bGxsThw4IDZfbZs2YLo6GgsXboUQUFBiIiIwPz581FcXGyyzcCBAzFr1iz4+fmhW7dueP3116HVaqstS15eHoCau6prNBqo1WqTh7U42Ilfi6a86desdOjQAQkJCThw4ADOnDmDf/zjH8jIyLB1sYiIiBrMZtUUWVlZ0Gq18PPzM1nv5+dX7U02JSUF+/btg0qlwubNm5GVlYWZM2ciJyfHkJeUkpKCXbt2YeLEidi6dSvOnz+PWbNmoby8HC+//HKVY0qShHnz5uGOO+5At27dqi1vfHw8Fi1a1IB3XHvKiiCptBkESS+99BIuXryIe++9F05OTnjqqacwZswYQ+BJRETUXMkkS/cRr6W0tDQEBQXhwIEDGDhwoGH9kiVL8Pnnn5vtDh4bG4vExERkZGTA3d0dgBjNeezYsSgsLISjoyMiIiJQUlKCixcvQqEQ+TjLli3DW2+9ZTJYot6sWbPw008/Yd++fQgODq62vBqNBhqNxvCzWq1G27ZtkZeXBzc3N5Nt9efXJ6TXVUFJGVKyCqG0U6CTv+vtd6BG09DfLRER2ZZarYa7u7vZ+/etbFaT5OPjA4VCUaXWKDMzs0rtkl5AQACCgoIMARIAdO7cGZIk4erVq+jYsSMCAgJgb29vCJD022RkZKC0tBQODg6G9XPmzMGWLVuwd+/eGgMkAFAqlVAqlfV5q3XmUDHSdqlWB0mSOPM8ERGRDdgsJ8nBwQFRUVFISEgwWZ+QkIBBgwaZ3ScmJgZpaWkoKCgwrEtOToZcLjcEOTExMfjrr79MekolJycjICDAECBJkoTZs2fj+++/x65duxAeHm7pt9cg9goZZDIZJElCqbbpN7kRERG1RDYdJ2nevHn45JNPsHbtWpw5cwbPPvssUlNTMWPGDADACy+8gEmTJhm2f/TRR+Ht7Y2pU6fi9OnT2Lt3LxYsWIBp06YZ5hV7+umnkZ2djblz5yI5ORk//fQTXn/9dcyaNctwnFmzZuGLL77Al19+CVdXV2RkZCAjI8MkAdyWZDIZlIrmk5dERETUEtm0f/n48eORnZ2NxYsXIz09Hd26dcPWrVsNXfbT09NNBiV0cXFBQkIC5syZg+joaHh7e2PcuHF47bXXDNu0bdsWO3bswLPPPosePXogKCgIc+fOxXPPPWfYZtWqVQDEnGKVrVu3DlOmTLHeG64DBzs5Ssq10JTrwKwkIiKixmezxO3mrqbEL0sk96bnFeNGvgY+LkoEejhaoshkAUzcJiJq3uqSuG3zaUnIPAdF8xkriYiIqCVikNREGcdKqn4QTCIiIrIeBklNlGEYgHIJOraIEhERNToGSU2UvUIGuUwGCRLK2ORGRETU6BgkNVEymaxZzeGmd+eddyIuLs7wc1hYGJYvX17jPjKZDD/88EODz22p4xAREQEMkpq0xp7DbfTo0bj77rvNvvbbb79BJpPhyJEjdTrmoUOH8NRTT1mieAavvvoqevXqVWV9eno6RowYYdFzERFR68UgqQkz1CQ10qjb06dPx65du3D58uUqr61duxa9evVCnz596nTMNm3awMnJyVJFrJG/v3+jTR1DREQtH4OkJkxfk6Qpa5webqNGjYKvry/Wr19vsr6oqAibNm3CmDFjMGHCBAQHB8PJyQndu3fHxo0bazzmrc1t58+fx5AhQ6BSqdClS5cq09IAwHPPPYeIiAg4OTmhXbt2eOmll1BWVgYAWL9+PRYtWoRjx45BJhPTt+jLe2tz24kTJ3DXXXfB0dER3t7eeOqpp0ymtJkyZQrGjBmD//u//0NAQAC8vb0xa9Ysw7mIiKh1s+mI262KJAFlRXXaxUFXDllZEcokOVBaz0lu7Z2AWk6Qa2dnh0mTJmH9+vV4+eWXDRPrfvPNNygtLcUTTzyBjRs34rnnnoObmxt++uknPP7442jXrh369+9/2+PrdDo89NBD8PHxwcGDB6FWq03yl/RcXV2xfv16BAYG4sSJE3jyySfh6uqKf/3rXxg/fjxOnjyJbdu24ZdffgEAkwmP9YqKinDfffdhwIABOHToEDIzM/HEE09g9uzZJkHg7t27ERAQgN27d+Ovv/7C+PHj0atXLzz55JO1umZERNRyMUhqLGVFwOuBddrFBUD3hp7332mAg3OtN582bRreeust/Prrrxg2bBgA0dT20EMPISgoCPPnzzdsO2fOHGzbtg3ffPNNrYKkX375BWfOnMGlS5cMExK//vrrVfKIXnzxRcNyWFgY/vnPf2LTpk3417/+BUdHR7i4uMDOzg7+/v7VnmvDhg0oLi7GZ599Bmdn8f4/+OADjB49Gm+++Sb8/PwAAJ6envjggw+gUCgQGRmJ+++/Hzt37mSQREREDJLIVGRkJAYNGoS1a9di2LBhuHDhAhITE7Fjxw5otVq88cYb2LRpE65duwaNRgONRmMIQm7nzJkzCAkJMQRIADBw4MAq23377bdYvnw5/vrrLxQUFKC8vPy2Q8ebO1fPnj1NyhYTEwOdTodz584ZgqSuXbtCoVAYtgkICMCJEyfqdC4iImqZGCQ1FnsnUatTR39lFqC4TItQLye4OdrX77x1NH36dMyePRsrVqzAunXrEBoaiuHDh+Ott97CO++8g+XLl6N79+5wdnZGXFwcSktLa3Vcc9MEym5pCjx48CAeeeQRLFq0CPfeey/c3d3x1Vdf4e23367Te5AkqcqxzZ3T3t6+yms6XfMZcoGIiKyHQVJjkcnq1OylZ+8IFKEMGrkj4NA4PbfGjRuHuXPn4ssvv8Snn36KJ598EjKZDImJiXjggQfw2GOPARA5RufPn0fnzp1rddwuXbogNTUVaWlpCAwUTY+//fabyTb79+9HaGgoFi5caFh3a287BwcHaLU1J7N36dIFn376KQoLCw21Sfv374dcLkdEREStyktERK0be7c1cbaYw83FxQXjx4/Hv//9b6SlpWHKlCkAgA4dOiAhIQEHDhzAmTNn8I9//AMZGRm1Pu7dd9+NTp06YdKkSTh27BgSExNNgiH9OVJTU/HVV1/hwoULeO+997B582aTbcLCwnDx4kUkJSUhKysLGo2myrkmTpwIlUqFyZMn4+TJk9i9ezfmzJmDxx9/3NDURkREVBMGSU2cfg63xh51e/r06bh58ybuvvtuhISEAABeeukl9OnTB/feey/uvPNO+Pv7Y8yYMbU+plwux+bNm6HRaNCvXz888cQTWLJkick2DzzwAJ599lnMnj0bvXr1woEDB/DSSy+ZbPP3v/8d9913H4YNG4Y2bdqYHYbAyckJ27dvR05ODvr27YuxY8di+PDh+OCDD+p+MYiIqFWSSeYSRei21Go13N3dkZeXVyWpuKSkBBcvXkR4eDhUKlWDzlOoKceFGwVwUMgRGVC35GWyPEv+bomIqPHVdP++FWuSmjj9qNulWh10OsazREREjYVBUhNnJ5dBUdEbq7SRpichIiIiBklNnkwmM87h1sh5SURERK0Zg6RmwBY93IiIiFo7BklWZKmceFv1cKOq2M+BiKj1YJBkBfpRnIuK6jahbXWMNUkMkmxN/zu9daRuIiJqeTjithUoFAp4eHggMzMTgBizp7opMmpD0pZDKi9Fsa4cJSX8ldmCJEkoKipCZmYmPDw8TOZ7IyKilol3XCvRz1CvD5QaQqeTkJlXAgCQFagaFHBRw3h4eBh+t0RE1LIxSLISmUyGgIAA+Pr6oqysrEHHkiQJz67Yj0JNOT6Z1Bfhbeo+Bxw1nL29PWuQiIhaEQZJVqZQKCxyY3VUqZCclYfLeWXo3JYjPRMREVkbE7ebiTAfUXt0KbvQxiUhIiJqHRgkNRNh3hVBUhaDJCIiosbAIKmZCK+oSbrIIImIiKhRMEhqJkK9nQCwuY2IiKixMEhqJvQ1SdfVGhSVltu4NERERC0fg6RmwsPJAR5OYpTnS1mWGcmbiIiIqscgqRkxJG+zyY2IiMjqGCQ1I0zeJiIiajwMkpoRDgNARETUeBgkNSNhPuzhRkRE1FgYJDUjxuY2Jm4TERFZG4OkZkQ/NUlWgQYFGg4DQEREZE02D5JWrlyJ8PBwqFQqREVFITExscbtNRoNFi5ciNDQUCiVSrRv3x5r16412SY3NxezZs1CQEAAVCoVOnfujK1btzbovE2Bm8oe3s4OAJiXREREZG12tjz5pk2bEBcXh5UrVyImJgYfffQRRowYgdOnTyMkJMTsPuPGjcP169exZs0adOjQAZmZmSgvN9aqlJaW4p577oGvry++/fZbBAcH48qVK3B1dW3QeZuKMB9nZBeW4lJ2IboFudu6OERERC2WTJIkyVYn79+/P/r06YNVq1YZ1nXu3BljxoxBfHx8le23bduGRx55BCkpKfDy8jJ7zA8//BBvvfUWzp49C3t7e4uc1xy1Wg13d3fk5eXBzc2tVvtYwj+/PobvjlzF/NgIzL6rY6Odl4iIqCWoy/3bZs1tpaWlOHz4MGJjY03Wx8bG4sCBA2b32bJlC6Kjo7F06VIEBQUhIiIC8+fPR3Fxsck2AwcOxKxZs+Dn54du3brh9ddfh1arrfd5AdHMp1arTR62EF7Rw43J20RERNZls+a2rKwsaLVa+Pn5maz38/NDRkaG2X1SUlKwb98+qFQqbN68GVlZWZg5cyZycnIMeUkpKSnYtWsXJk6ciK1bt+L8+fOYNWsWysvL8fLLL9frvAAQHx+PRYsWNfBdN5w+eZvDABAREVmXzRO3ZTKZyc+SJFVZp6fT6SCTybBhwwb069cPI0eOxLJly7B+/XpDbZJOp4Ovry9Wr16NqKgoPPLII1i4cKFJ01pdzwsAL7zwAvLy8gyPK1eu1OftNhgHlCQiImocNqtJ8vHxgUKhqFJ7k5mZWaWWRy8gIABBQUFwdzcmLHfu3BmSJOHq1avo2LEjAgICYG9vD4VCYbJNRkYGSktL63VeAFAqlVAqlfV5qxalr0nKLiyFuqQMbirzeVdERETUMDarSXJwcEBUVBQSEhJM1ickJGDQoEFm94mJiUFaWhoKCgoM65KTkyGXyxEcHGzY5q+//oJOpzPZJiAgAA4ODvU6b1PiorSDj4sI1libREREZD02bW6bN28ePvnkE6xduxZnzpzBs88+i9TUVMyYMQOAaOKaNGmSYftHH30U3t7emDp1Kk6fPo29e/diwYIFmDZtGhwdHQEATz/9NLKzszF37lwkJyfjp59+wuuvv45Zs2bV+rxNnTF5m0ESERGRtdh0nKTx48cjOzsbixcvRnp6Orp164atW7ciNDQUAJCeno7U1FTD9i4uLkhISMCcOXMQHR0Nb29vjBs3Dq+99pphm7Zt22LHjh149tln0aNHDwQFBWHu3Ll47rnnan3epi7M2xmHLt3EJfZwIyIishqbjpPUnNlqnCQAWLH7L7y1/Rwe7B2Ed8b3atRzExERNWfNYpwkqj/jRLdsbiMiIrIWBknNkD5ISrqSi3Ef/ob/HU9DmVZ3m72aj+JSLW4WlkKnaz6VnCVlWmTkleC6uqRZlZuIiKpn05wkqp9Ofq54OCoY3x+9hj8u5eCPSznwdVViYv9QTOjfFr6uKlsXsUblWh3S80pw5WYRruYUIzWnCFduFuFKThFSc4qRVaABANjJZfBydoCPixLeLg5oU/Hs46KEj4sS/u4qdA92r/cwCOVaHU6nq3H48k0UlYoR2fVDZckgu+VnoLBUi9yiUtwsKsPNwlLcLCpFblEZcgpLUVymNRxXaSdHqLcTQr2dEebthJCK5zBvZwS4q2CnaJ3fTSRJwndHrmH5L8lwclBgaEQbDI3wRXSYJ1T2itsfgKgFkCQJmfka2Mll8Hax/bAyVDPmJNWTLXOS9DLySvDlH6n48vdUQ2Bhr5BhRLcATBoYiqhQzxoHyLQmnU5CWl4xLmYV4lJWIVKyCnGx4nHtZjHKLVTbIpOJoDE6zBPRoV6ICvVEsKej2fetD4oOpmTjYEoODl3MQb6m3MxR60chF+fU1vDe7BUyBHo4ok1FoOfjagz6fFyUaFPxs4ejA24WleK6ugTX8zW4XlFLdT1fg+vqEmSqS3AjXwMvFwe0b+OC9m1c0MHXpWLZucl9+GYXaPDvzSew/dT1Kq852iswsL03hnT0wdBOvgjzdrLZ321TkXw9H39czEFJmRZlWgml5TqUaXUo1epQWm581uokBLirEObjjPCKh7ezg8Wv39WbRfjf8XRk5JWga6Abeod4oJ2PC+Ty1vN7Ki3X4crNIihkMjgpFXBysIOTvaLaa1BUWo6UG+KzL+VGQcVyAS7eKERhxZeyAHcVugW5o3vFo1uQO9q4Wu5/V6uT8L/jafj28FXIZTJ4ONnD08kB7o728HSyh6ezftkBnk4OCPZ0bBW/07rcvxkk1VNTCJL0Sst12HYqA58duIQ/L980rO8S4IbYrmKAzDKtDmVaqeJZh7LyimWdhHKt+LDVSYBOkqCTJGh1EiQJFevFsp1CBnuFHPYKORzsZLCTG5ftFXLIZTKk6wOj7CKUllffBGivkCHY0wltvZzQ1tMRIV5iOcTLCW09neDooEBOYSmyCjQVj4rlfA2yK9Zfyi7ElZziKsf2dVUiOswTUaFe6OTnitPpedUGRa4qO/QL84KPixISxL+C/j9C/48hSYAECU4OCng6OcDDycHwAeNZadlVaYdynYS03GJcyi7C5exCXK54vpRdhNScmq+JJXk62RuCJ393FVyUdnBSKsSzgx2cKy27KO1gp5BBU65DSZkWmjIdNOValNzyrLSTY3DHNnBW1q0CeueZ63juu+PIKiiFvUKGuLsjEObtjF/PZWJP8g1k5mtMtg/xcsLQiDZo18YZ5VoJZTodtFrJ8LdarhN/u+VaCQq5DG4qO7g52sNNZS+eHe3gprKHu6P42VVpZ7UP/pIyLXKLypBbXIqbhWXIKy6Fh5MDerX1qHPtWEZeCbYcu4bNR9NwJr3+c0O6Ku0MQVOYjzPa+Tijk78rOvq61KkW80a+Bj8dT8OWY2k4kppb9TwqO/Rq62HyqCk4lyQJRaVaFGjKkV9SjptFpcguEDWyOYXG5ezCUkNNrZ1cJn6HKvE7NT5XLDvaI9jTET2C3eHkYJmGEX1Nz5l0Nc5m5ONsxfNfmQVmv9yp7OVwdhD/X072dlA5KJCpLkF6Xkm151DIZYbP1Vv5uxkDpz6hHhjQzhv2dax91gdH7+08jws3ap+72q6NM14d3RVDItrU6XyVqUvKkKkuadJBNIOkRtCUgqTKTl7Lw+e/XcYPSdegaaQbcnXsFTKEeDkh3McF4T7iOcxHNDv5uakMNS8NkakuweHLN/FnxePUtbwaa6lcVXboH+6FAe28MaCdNzoHuFmkHLWh00nIUJfgSk6RMeireNzIN/25pEwHR3sF/N1V8HVVws9NZbLs56aCj4sDbuRrcOFGIf7KLMCFG+Jx9WbVwNFSXJR2eLB3ECYOCEGkf81/9wWacrz2v9P46pCYwifCzwXvjO+FroHGEfMlScLZjHzsSb6BPedu4M/LOSjTWv4jSWUvh5ODHRztFXByEA9HB0XFz3ZQ2Ssgk8Fw4xJfFsQzKp61Ogn5JeXILS6raHYtRUmZ+f8xe4UMPYM90C/cC/3CRQ2nq5lm4bziMmw7mY4fjqbh4MVsw03TXiHDgHbe8HRygIOdXDwUps/2CjlkMuDazWJDLW1aXrHZG6/+GnQJcBO1FsEe6BHsjvZtXEz+/vOKyrDtVDq2HEvDbxeyof9XksmAAeHeiAxwxclreThxLc/se2/r5YhOfm4o1epQUFKGAk05CkrKka8pR6GmHNZK11PIZegS4IY+IR7oE+qJqFBPBHmYr1HWK9PqcO1mMS7nFCE1W9T4nE3Px9kMNW4WlZndx9lBAZlMhsLS8mqvc2Vezg5o5+OMdm2c0a6NS8WyC0K8nFCq1eF0mhrHr+YarmlKVmGV43o62WNE9wCM7hGIfuFeNX5eaXUSfjqRjvd2nsdfmWLQZXdHe0y/IxwB7irkFZcZ0gQqB/e5RaXIKiw1fImL7eKHl0Z1QVsvp9u/yQo5haX4ODEFnx24hMJSLbydHTAkog3u7NQGQzq2gaezQ62Ppaf/kubuaNmZJRgkNYKmGiTp5RaV4tvDV3H+egHs7Yw1QPaKqst2chnkchkUMhnkMrEsl4kPHplMrJfJIL7BV1T7i6r/itoo/TqdBF9XJcJ9nNHOxwWBHo2ff1NSpsWxK7n48/JNHL58E+cz89HJz9UmQVFDaMq1cFDI69VsUlyqRUpWgSF4yi7QGL7BF2rKUViqFc+VftbqJDjYyaG0k0NlrzB51i9fvSnyx/SiQj0xsX8IRnYPqFJrcuhSDuZ9nYQrOcWQyYAn7gjHP2M73bZ2pUBTjt8uZCPx/A3kFIqaBLuKv1U7uRx2CplxnVyG8orARV1SBnVxGdQl5VAXlyGvuAzqkrJqgxhLUshl8HC0h4eTqL26lluM62rT2jG5DOgS6IZ+Yd7oF+4FAPhv0jXsPJtpUrvYN8wTY3oHYWS3gHrdVErKtEjNKTIETZeyCpFyoxCn09UoMNO07GivQNdAN3QLcsfVm0XYk3zDJEjt1dYDf+sZiPt7BMDPzZjrWKbV4VxGPpKu5Boe+pvy7chlItj2cnaAp7MDvJ0dTJY9nRzg7SJqbEVgWgZ1cbl4Nvyuxc95xWU4f70AGeqqtTa+rkpEhXqiT4gnAj0ccfVmUUVAVITLOYVIyy2ptmlcLgPatXFBpL8rOge4IdLfFZEBbgh0V0Emk0GSJJSU6VBUWo6iUi2KSrUoLC1HccX/lreLEu3bOMPDqW6/wwJNOU6nqXHiWh5OXM3Fvr+ykFVQanjdz02J+7sHYnTPAPRq62H4fNBVCo7OVwqOnhwcjsmDwswG6LdSl5Th3V/OY/2BS9DqJCjt5JgxtD2evrN9jf+32QUafJx4EZ/9dsmQ22lX8b9Z+Xr2bOuBOyN8cWenNuge5G6oZZIkCdfVGtEkWfH3mpIlmiev3izCxP6h+M+YbnW6jrd9rwySrK+pB0lEtSVV1J7crmpcp5Nw4EI2vvzjMnacum74EHR3tMfYqGA82j8EwZ6OWJaQjNV7UyBJQJCHI94e1xMD2nk3xlupQlOuRUGJuJEVl2krbmjiZqZf1r8mg/hyIK/4UiCXVfxc8WVBf3PXN7d6ODrAw1k051UOZiVJQmpOEf64mCMel3JwObv6gV87+rpgTO8g/K1nYJ2+udeFTifhYnYhTl7Lw/GreThxNQ+n0vIMuTGVRfq7YnTPQIzuEYgQ79qXR11ShuNX8nAxqwCOFc24rirx7KISy65Ke6js6xf81yQttxiHL9/EkdSbOHL5Jk6lqWuV96iylyPEywkhXs4I9XZCJ39XdAlwQwdflybRmaBcq8PBlBxsOXYN205mQF1iDHSDPR0xumcgwn2c8fHeFENw5Kayw5OD22FyTFi9OrUkX8/Hq1tO4cCFbADif/ilUV1wb1c/k99bdoEGqxNT8Plvlw3BUddAN8wd3hFDO7XBkcu5+PVcJn49dwPnruebnMPb2QG9QzyQoS4xydEyZ3ikL9ZM6Vvn91ETBkmNgEEStWaZ6hJ8/ecVbPzjCq7lGpv3fFwcDN98H44Kxsuju9TqW2xLl5FXInqiXsyuSMjW4b5u/nigVyC6BLjZJFFdq5NwMaugotZCDReVHUb1CECEn2ujl8XSiku1OHEtD4crapSzCzVo6+mEUG+R9xjqLYIiX1dls+kkoCnXIjE5Cz8eT0PC6euGwETPTWWHJwa3w5R6BkeVSZKErScysOSn00iryK0a3NEHr4zuCg8ne6zeK4Ijfa/ebkFuiBsegeGdfc1ez7TcYuxJvoFfz2Vi/1/ZVWo1FXIZ2no6mjRJiiZKZ7RxsfzviEFSI2CQRCRutHuTb2DD75ex62wmdJL4lhj/UHfEdvW3dfGIWqTiUi12nr2OH4+l4cKNQozuEYgpMWEWz90pKi3Hyt0XsHpvCkq1uoqmbpmhGbtHsDvmDu+IuyLNB0fmlJbrcPjyTZzNUCPIwxHt2jgjxMsZDnaNl5rBIKkRMEgiMpWWW4x9f2Xhrkhf+DSxIQiIqP4uZxfiP/87jV/OZAIAega7I+7uCNzZqU2zqYmrjEFSI2CQRERErcnBlGzodBIGtvdulsGRXl3u3xxxm4iIiG7LVh0wbKl1zo9AREREdBsMkoiIiIjMYJBEREREZAaDJCIiIiIzGCQRERERmcEgiYiIiMgMBklEREREZjBIIiIiIjKDQRIRERGRGQySiIiIiMxgkERERERkBoMkIiIiIjMYJBERERGZwSCJiIiIyAwGSURERERmMEgiIiIiMoNBEhEREZEZDJKIiIiIzGCQRERERGQGgyQiIiIiMxgkEREREZnBIImIiIjIDAZJRERERGYwSCIiIiIyg0ESERERkRk2D5JWrlyJ8PBwqFQqREVFITExscbtNRoNFi5ciNDQUCiVSrRv3x5r1641vL5+/XrIZLIqj5KSEsM25eXlePHFFxEeHg5HR0e0a9cOixcvhk6ns9r7JCIioubFzpYn37RpE+Li4rBy5UrExMTgo48+wogRI3D69GmEhISY3WfcuHG4fv061qxZgw4dOiAzMxPl5eUm27i5ueHcuXMm61QqlWH5zTffxIcffohPP/0UXbt2xZ9//ompU6fC3d0dc+fOtfwbJSIiombHpkHSsmXLMH36dDzxxBMAgOXLl2P79u1YtWoV4uPjq2y/bds27NmzBykpKfDy8gIAhIWFVdlOJpPB39+/2vP+9ttveOCBB3D//fcbjrFx40b8+eefFnhXRERE1BLYrLmttLQUhw8fRmxsrMn62NhYHDhwwOw+W7ZsQXR0NJYuXYqgoCBERERg/vz5KC4uNtmuoKAAoaGhCA4OxqhRo3D06FGT1++44w7s3LkTycnJAIBjx45h3759GDlyZLXl1Wg0UKvVJg8iIiJquWxWk5SVlQWtVgs/Pz+T9X5+fsjIyDC7T0pKCvbt2weVSoXNmzcjKysLM2fORE5OjiEvKTIyEuvXr0f37t2hVqvx7rvvIiYmBseOHUPHjh0BAM899xzy8vIQGRkJhUIBrVaLJUuWYMKECdWWNz4+HosWLbLQuyciIqKmzqbNbYBoGqtMkqQq6/R0Oh1kMhk2bNgAd3d3AKLJbuzYsVixYgUcHR0xYMAADBgwwLBPTEwM+vTpg/fffx/vvfceAJEL9cUXX+DLL79E165dkZSUhLi4OAQGBmLy5Mlmz/3CCy9g3rx5hp/VajXatm3boPdORERETZfNgiQfHx8oFIoqtUaZmZlVapf0AgICEBQUZAiQAKBz586QJAlXr1411BRVJpfL0bdvX5w/f96wbsGCBXj++efxyCOPAAC6d++Oy5cvIz4+vtogSalUQqlU1vl9EhERUfNks5wkBwcHREVFISEhwWR9QkICBg0aZHafmJgYpKWloaCgwLAuOTkZcrkcwcHBZveRJAlJSUkICAgwrCsqKoJcbvrWFQoFhwAgIiIiA5uOkzRv3jx88sknWLt2Lc6cOYNnn30WqampmDFjBgDRxDVp0iTD9o8++ii8vb0xdepUnD59Gnv37sWCBQswbdo0ODo6AgAWLVqE7du3IyUlBUlJSZg+fTqSkpIMxwSA0aNHY8mSJfjpp59w6dIlbN68GcuWLcODDz7YuBeAiIiImiyb5iSNHz8e2dnZWLx4MdLT09GtWzds3boVoaGhAID09HSkpqYatndxcUFCQgLmzJmD6OhoeHt7Y9y4cXjttdcM2+Tm5uKpp55CRkYG3N3d0bt3b+zduxf9+vUzbPP+++/jpZdewsyZM5GZmYnAwED84x//wMsvv9x4b56IiIiaNJkkSZKtC9EcqdVquLu7Iy8vD25ubrYuDhEREdVCXe7fNp+WhIiIiKgpYpBEREREZAaDJCIiIiIzGCQRERERmcEgiYiIiMgMBklEREREZjBIIiIiIjKDQRIRERGRGQySiIiIiMxgkERERERkBoMkIiIiIjMYJBERERGZwSCJiIiIyAwGSURERERmMEgiIiIiMoNBEhEREZEZDJKIiIiIzGCQRERERGQGgyQiIiIiMxgkEREREZnBIImIiIjIDAZJRERERGYwSCIiIiIyg0ESERERkRkMkoiIiIjMYJBEREREZAaDJCIiIiIzGCQRERERmcEgiYiIiMgMBklEREREZjBIIiIiIjKDQRIRERGRGQySiIiIiMxgkERERERkBoMkIiIiIjMYJBERERGZwSCJiIiIyAwGSURERERm2DxIWrlyJcLDw6FSqRAVFYXExMQat9doNFi4cCFCQ0OhVCrRvn17rF271vD6+vXrIZPJqjxKSkpMjnPt2jU89thj8Pb2hpOTE3r16oXDhw9b5T0SERFR82Nny5Nv2rQJcXFxWLlyJWJiYvDRRx9hxIgROH36NEJCQszuM27cOFy/fh1r1qxBhw4dkJmZifLycpNt3NzccO7cOZN1KpXKsHzz5k3ExMRg2LBh+Pnnn+Hr64sLFy7Aw8PD4u+RiIiImiebBknLli3D9OnT8cQTTwAAli9fju3bt2PVqlWIj4+vsv22bduwZ88epKSkwMvLCwAQFhZWZTuZTAZ/f/9qz/vmm2+ibdu2WLdunWGdueMQERFR62Wz5rbS0lIcPnwYsbGxJutjY2Nx4MABs/ts2bIF0dHRWLp0KYKCghAREYH58+ejuLjYZLuCggKEhoYiODgYo0aNwtGjR80e5+GHH4avry969+6Njz/+uMbyajQaqNVqkwcRERG1XDYLkrKysqDVauHn52ey3s/PDxkZGWb3SUlJwb59+3Dy5Els3rwZy5cvx7fffotZs2YZtomMjMT69euxZcsWbNy4ESqVCjExMTh//rzJcVatWoWOHTti+/btmDFjBp555hl89tln1ZY3Pj4e7u7uhkfbtm0beAWIiIioKZNJkiTZ4sRpaWkICgrCgQMHMHDgQMP6JUuW4PPPP8fZs2er7BMbG4vExERkZGTA3d0dAPD9999j7NixKCwshKOjY5V9dDod+vTpgyFDhuC9994DADg4OCA6OtqkxuqZZ57BoUOH8Ntvv5ktr0ajgUajMfysVqvRtm1b5OXlwc3NrX4XgYiIiBqVWq2Gu7t7re7fNqtJ8vHxgUKhqFJrlJmZWaV2SS8gIABBQUGGAAkAOnfuDEmScPXqVbP7yOVy9O3b16QmKSAgAF26dDHZrnPnzkhNTa22vEqlEm5ubiYPIiIiarnqFSRduXLFJCj5448/EBcXh9WrV9f6GA4ODoiKikJCQoLJ+oSEBAwaNMjsPjExMUhLS0NBQYFhXXJyMuRyOYKDg83uI0kSkpKSEBAQYHKcW3u/JScnIzQ0tNblJyIiohZOqoc77rhD+uyzzyRJkqT09HTJzc1NGjhwoOTt7S0tWrSo1sf56quvJHt7e2nNmjXS6dOnpbi4OMnZ2Vm6dOmSJEmS9Pzzz0uPP/64Yfv8/HwpODhYGjt2rHTq1Clpz549UseOHaUnnnjCsM2rr74qbdu2Tbpw4YJ09OhRaerUqZKdnZ30+++/G7b5448/JDs7O2nJkiXS+fPnpQ0bNkhOTk7SF198Ueuy5+XlSQCkvLy8Wu9DREREtlWX+3e9giQPDw/p7NmzkiRJ0rvvvisNGjRIkiRJ2r59uxQeHl6nY61YsUIKDQ2VHBwcpD59+kh79uwxvDZ58mRp6NChJtufOXNGuvvuuyVHR0cpODhYmjdvnlRUVGR4PS4uTgoJCZEcHBykNm3aSLGxsdKBAweqnPfHH3+UunXrJimVSikyMlJavXp1ncrNIImIiKj5qcv9u16J2y4uLjh58iTCwsLwt7/9DTExMXjuueeQmpqKTp06VemS3xLVJfGLiIiImgarJ2537doVH374IRITE5GQkID77rsPgOix5u3tXZ9DEhERETUp9QqS3nzzTXz00Ue48847MWHCBPTs2ROAGKSxX79+Fi0gERERkS3Ue5wkrVYLtVoNT09Pw7pLly7ByckJvr6+FitgU8XmNiIioubH6s1txcXF0Gg0hgDp8uXLWL58Oc6dO9cqAiQiIiJq+eoVJD3wwAOGKTxyc3PRv39/vP322xgzZgxWrVpl0QISERER2UK9gqQjR45g8ODBAIBvv/0Wfn5+uHz5Mj777DPD1B9EREREzVm9gqSioiK4uroCAHbs2IGHHnoIcrkcAwYMwOXLly1aQCIiIiJbqFeQ1KFDB/zwww+4cuUKtm/fjtjYWABi3jUmMRMREVFLUK8g6eWXX8b8+fMRFhaGfv36YeDAgQBErVLv3r0tWkAiIiIiW6j3EAAZGRlIT09Hz549IZeLWOuPP/6Am5sbIiMjLVrIpohDABARETU/dbl/29X3JP7+/vD398fVq1chk8kQFBTEgSSJiIioxahXc5tOp8PixYvh7u6O0NBQhISEwMPDA//5z3+g0+ksXUYiIiKiRlevmqSFCxdizZo1eOONNxATEwNJkrB//368+uqrKCkpwZIlSyxdTiIiIqJGVa+cpMDAQHz44Yf429/+ZrL+v//9L2bOnIlr165ZrIBNFXOSiIiImh+rT0uSk5NjNjk7MjISOTk59TkkERERUZNSryCpZ8+e+OCDD6qs/+CDD9CjR48GF4qIiIjI1uqVk7R06VLcf//9+OWXXzBw4EDIZDIcOHAAV65cwdatWy1dRiIiIqJGV6+apKFDhyI5ORkPPvggcnNzkZOTg4ceeginTp3CunXrLF1GIiIiokZX78EkzTl27Bj69OkDrVZrqUM2WUzcJiIian6snrhNRERE1NIxSCIiIiIyg0ESERERkRl16t320EMP1fh6bm5uQ8pCRERE1GTUKUhyd3e/7euTJk1qUIGIiIiImoI6BUns3k9EREStBXOSiIiIiMxgkERERERkBoMkIiIiIjMYJBERERGZwSCJiIiIyAwGSURERERmMEgiIiIiMoNBEhEREZEZDJKIiIiIzGCQRERERGQGgyQiIiIiMxgkEREREZnBIImIiIjIDJsHSStXrkR4eDhUKhWioqKQmJhY4/YajQYLFy5EaGgolEol2rdvj7Vr1xpeX79+PWQyWZVHSUmJ2ePFx8dDJpMhLi7Okm+LiIiImjk7W55806ZNiIuLw8qVKxETE4OPPvoII0aMwOnTpxESEmJ2n3HjxuH69etYs2YNOnTogMzMTJSXl5ts4+bmhnPnzpmsU6lUVY516NAhrF69Gj169LDcmyIiIqIWwaZB0rJlyzB9+nQ88cQTAIDly5dj+/btWLVqFeLj46tsv23bNuzZswcpKSnw8vICAISFhVXZTiaTwd/fv8ZzFxQUYOLEifj444/x2muvNfzNEBERUYtis+a20tJSHD58GLGxsSbrY2NjceDAAbP7bNmyBdHR0Vi6dCmCgoIQERGB+fPno7i42GS7goIChIaGIjg4GKNGjcLRo0erHGvWrFm4//77cffdd9eqvBqNBmq12uRBRERELZfNapKysrKg1Wrh5+dnst7Pzw8ZGRlm90lJScG+ffugUqmwefNmZGVlYebMmcjJyTHkJUVGRmL9+vXo3r071Go13n33XcTExODYsWPo2LEjAOCrr77CkSNHcOjQoVqXNz4+HosWLarnuyUiIqLmxqbNbYBoGqtMkqQq6/R0Oh1kMhk2bNgAd3d3AKLJbuzYsVixYgUcHR0xYMAADBgwwLBPTEwM+vTpg/fffx/vvfcerly5grlz52LHjh1m85Sq88ILL2DevHmGn9VqNdq2bVuXt0pERETNiM2CJB8fHygUiiq1RpmZmVVql/QCAgIQFBRkCJAAoHPnzpAkCVevXjXUFFUml8vRt29fnD9/HgBw+PBhZGZmIioqyrCNVqvF3r178cEHH0Cj0UChUFQ5jlKphFKprNd7JSIioubHZjlJDg4OiIqKQkJCgsn6hIQEDBo0yOw+MTExSEtLQ0FBgWFdcnIy5HI5goODze4jSRKSkpIQEBAAABg+fDhOnDiBpKQkwyM6OhoTJ05EUlKS2QCJiIiIWh+bNrfNmzcPjz/+OKKjozFw4ECsXr0aqampmDFjBgDRxHXt2jV89tlnAIBHH30U//nPfzB16lQsWrQIWVlZWLBgAaZNmwZHR0cAwKJFizBgwAB07NgRarUa7733HpKSkrBixQoAgKurK7p162ZSDmdnZ3h7e1dZT0RERK2XTYOk8ePHIzs7G4sXL0Z6ejq6deuGrVu3IjQ0FACQnp6O1NRUw/YuLi5ISEjAnDlzEB0dDW9vb4wbN86kC39ubi6eeuopZGRkwN3dHb1798bevXvRr1+/Rn9/RERE1HzJJEmSbF2I5kitVsPd3R15eXlwc3OzdXGIiIioFupy/7b5tCRERERETRGDJCIiIiIzGCQRERERmcEgiYiIiMgMBklEREREZjBIIiIiIjKDQRIRERGRGQySiIiIiMxgkERERERkBoMkIiIiIjMYJBERERGZwSCJiIiIyAwGSURERERmMEgiIiIiMoNBEhEREZEZDJKIiIiIzGCQRERERGQGgyQiIiIiMxgkEREREZnBIImIiIjIDAZJRERERGYwSCIiIiIyg0ESERERkRkMkoiIiIjMYJBEREREZAaDJCIiIiIzGCQRERERmcEgiYiIiMgMBklEREREZjBIIiIiIjKDQRIRERGRGQySiIiIiMxgkERERERkBoMkIiIiIjMYJBERERGZwSCJiIiIyAwGSURERERmMEgiIiIiMsPmQdLKlSsRHh4OlUqFqKgoJCYm1ri9RqPBwoULERoaCqVSifbt22Pt2rWG19evXw+ZTFblUVJSYtgmPj4effv2haurK3x9fTFmzBicO3fOau+RiIiImh87W55806ZNiIuLw8qVKxETE4OPPvoII0aMwOnTpxESEmJ2n3HjxuH69etYs2YNOnTogMzMTJSXl5ts4+bmViXoUalUhuU9e/Zg1qxZ6Nu3L8rLy7Fw4ULExsbi9OnTcHZ2tvwbJSIiomZHJkmSZKuT9+/fH3369MGqVasM6zp37owxY8YgPj6+yvbbtm3DI488gpSUFHh5eZk95vr16xEXF4fc3Nxal+PGjRvw9fXFnj17MGTIkFrto1ar4e7ujry8PLi5udX6XERERGQ7dbl/26y5rbS0FIcPH0ZsbKzJ+tjYWBw4cMDsPlu2bEF0dDSWLl2KoKAgREREYP78+SguLjbZrqCgAKGhoQgODsaoUaNw9OjRGsuSl5cHANUGXoBo5lOr1SYPIiIiarls1tyWlZUFrVYLPz8/k/V+fn7IyMgwu09KSgr27dsHlUqFzZs3IysrCzNnzkROTo4hLykyMhLr169H9+7doVar8e677yImJgbHjh1Dx44dqxxTkiTMmzcPd9xxB7p161ZteePj47Fo0aIGvGMiIiJqTmyakwQAMpnM5GdJkqqs09PpdJDJZNiwYQPc3d0BAMuWLcPYsWOxYsUKODo6YsCAARgwYIBhn5iYGPTp0wfvv/8+3nvvvSrHnD17No4fP459+/bVWM4XXngB8+bNM/ysVqvRtm3bWr9PIiIial5sFiT5+PhAoVBUqTXKzMysUrukFxAQgKCgIEOABIgcJkmScPXqVbM1RXK5HH379sX58+ervDZnzhxs2bIFe/fuRXBwcI3lVSqVUCqVtXlrRERE1ALYLCfJwcEBUVFRSEhIMFmfkJCAQYMGmd0nJiYGaWlpKCgoMKxLTk6GXC6vNsiRJAlJSUkICAgwWTd79mx8//332LVrF8LDwy3wjoiIiKglsek4SfPmzcMnn3yCtWvX4syZM3j22WeRmpqKGTNmABBNXJMmTTJs/+ijj8Lb2xtTp07F6dOnsXfvXixYsADTpk2Do6MjAGDRokXYvn07UlJSkJSUhOnTpyMpKclwTACYNWsWvvjiC3z55ZdwdXVFRkYGMjIyqiSAExERUetl05yk8ePHIzs7G4sXL0Z6ejq6deuGrVu3IjQ0FACQnp6O1NRUw/YuLi5ISEjAnDlzEB0dDW9vb4wbNw6vvfaaYZvc3Fw89dRTyMjIgLu7O3r37o29e/eiX79+hm30Qw7ceeedJuVZt24dpkyZYr03TERERM2GTcdJas44ThIREVHz0yzGSSIiIiJqyhgktXZlJUDuFVuXgoiIqMlhkNTabZ0PLO8OXP3T1iUhIiJqUhgktWY6HXDmRwAScHGPrUtDRETUpDBIas2yzgEluWL5xjmbFoWIiKipYZDUmqX+ZlxmkERERDXZvlA8WhEGSa1Z6kHjclayaH4jIiK6VX4G8NsH4lGQaevSNBoGSa1Z5ZqksiIgj73ciIjIjBtnjcs5F21XjkbGIKm1yrsG5KYCMjngESLWZSXbtkxERNQ03ah0f8i5YLtyNDIGSa3VlYqmNr9uQFCUWK78TYGIiEgvq1Leak6K7crRyGw6dxvZkD4fKWQg4OgplhkkERGROTcYJFFros9HChlgXHeDzW1ERGRG5XQMBknUopWogeunxHLIAKA4VyzfOAdIEiCT2axoRETUxBTnAgXXjT9np7SaewVzklqjq4cASQd4hAJugYB3e5HArckT3TyJiIj09LVITt7iWZMHFN+0XXkaEYOk1qhyPhIA2CkBr3ZiOYuDShIRUSX6fCT/7oBbkFhuJU1uDJJaI3P5SG0ixTNH3iYiosr0X57bRBq/UDNIohZJWwZc/VMs62uSAMAnQjwzSCIiosr0nXp8IgCvcLHcSoIkJm63NunHgfJi0e1fHxgBrEkiIiLzDDVJnQCNWixnt44BJRkktTb6pra2AwB5pYrENvqaJI6VREREFcqKgZuXxbJPJ6AoWyy3kpokNre1NubykQBjrVJRFlCY3bhlIiKipinrPABJtD44+zAniVowSaras03PwbnSHG5sciMiIhi7//t0EuMieVbkJBXntIphABgktSbZF0RNkUIJBPaq+rpPJ/HMJjciIgKMear6lAylC+DiJ5ZzLtqmTI2IQVJrom9qC4oSYyPdqo0+SOL0JEREBGPLgv5LNNCqmtwYJLUmhqa2AeZfN/RwY02STd28BHz3BHsaEpHt6b80t6kcJLUXz6xJohaluqRtPUNNEm/ONrVrCXDiG2Dv/9m6JETUmmnLgey/xHLlIWNa0VhJDJJai4JMIKdiXIu2/cxvo/8nyE8Tk+BS4ysrBs5tFcvX/rRtWYiodbt5CdCVAfZOgHtb43o2t1GLc+V38ezbRXTlNMfRA3ANEMtZzEuyib92AqUFYjknBSjKsW15iKj10ucjeXcwHVfPECS1/AElGSS1FrfLR9Lz4aCSNnXqe9Ofr7I2iYhs5EalkbYr0ze3Fd6wXquDJh9Qp1vn2HXAIKm1MOQjDax5O05PYjulRcC5bWK5TWfxzCa31qlEDSRvF38TRLZSeYykylTugJOPWL5ppeTtc9uAZZHAxgnWOX4tMUhqDUoLgfRjYvl2NUlM3radvxKAskLAPQToO12su3rItmUi2/h2GvDlOODdHsD+dwFNga1LRK3RrWMkVWbtvCT9Z59HqHWOX0sMklqDa4cBXTngFmSafGdOGw4oaTOnNovnrmOA4L5i+dphQKezWZHIBq4cEgEzIJozEl4GlncH9r4FlOTZtmzUekhSxZQkMLYwVNZYQVJwtHWOX0sMklqDyvlIMlnN2+r/GXJTWdVfV9py0TutPkoLRfMKAHR9EPDrCtg5ipuivgsutQ57l4rnnhOAB1aKMWmKc4Bdr4lgaXd8q5gOgmxMnQaU5gNyO2NAVJm3fqwkKwRJZSVAxgmxzCCJrK62+UiAmMDQyRuABGSft2qxWhRJAj57AHinG5B3re77n98BlBUBnmFAYG9AYW+cOoZ5Sa3HtSPib0GmAIb+C+g9EZj1B/DQJyIvpCQP2PMG8E534JdFnIyarEffmuDVTnwe3cpQk2SFnKSM42LoAec2bG4jK9OWA1f+EMu3y0fS8+H0JHV24xxweZ+YG2//8rrvb2hqe9BY26f/BsW8pNZj71viucc4401IYQf0eBiYeRB4eD3g1018w9+3DFjeDUjZY7PiUgtmSNo2k48EWHdASUNTW9/bt35YGYOkli7zlBh3R+kmxkiqjeaQl5R2VNxQyjW2Lolw5kfj8uFP69Z1VVMAJO8Qy10fNK4P0gdJrElqFdKPiYFEZXJg8D+rvi6Xi7+PfyQCj3wJ+HcXtY/73238slLLV133fz19EJ+fLtIFLEn/mRcUZdnj1gODpJZOn4/Uth8gV9Run6Y+h1vKHmDtCJGjcfxrW5dGOPNf8WznCGg1wIH3ar9v8jagvFh86Pj3MK7XJ29fP8X8sNZAX4vU9SHAp2P128nlQOT9wJgPxc+pBwFtmfXLR61Ldd3/9Rw9jQMTW7rJTR8k6T8DbYhBUkt3u/nazNF392yKo25f2CW6RpdXJEjrRxK3pZyLIslQJgce+ECs+3MtkH+9dvuba2oDAPcgMQK6pAXSkyxaZGpirp+qqI2UAUPm124f/ej5ZZWG+CCylJq6/+tZo4dbfgaQlwpABgT1sdxx68nmQdLKlSsRHh4OlUqFqKgoJCYm1ri9RqPBwoULERoaCqVSifbt22Pt2rWG19evXw+ZTFblUVJS0qDzNkuSVKlnWy2StvX0NUnZF4DyUsuXq77O/wJ8+QhQXiISnAHRRd7Wzv5PPIfGAN3+LprJykuA396//b6afOB8RXfvyk1tek0lL0mSWFthTfpapC4PAL6da7ePXC7+5gDgUgv8/CLbKcoR+ZVA9TlJgHWCJH0tkm9nQOlquePWk02DpE2bNiEuLg4LFy7E0aNHMXjwYIwYMQKpqanV7jNu3Djs3LkTa9aswblz57Bx40ZERpqO4eDm5ob09HSTh0qlatB5m6Xcy6K9WG4PBNYhIncNEDlMkrbpzM2TvAP4aoJoyup0PzC5IjDJPGP7yXhPbxHPXR4QNUFDnxM/H1oDFGbVvO+5beI9eXcUCbm3aip5SbtfB5YENI2gtKXJPAuc+kEsD1lQt30NQdJ+ixaJWjl9LZJ7W8DBufrtrBEk6Xvz2rjrv55Ng6Rly5Zh+vTpeOKJJ9C5c2csX74cbdu2xapVq8xuv23bNuzZswdbt27F3XffjbCwMPTr1w+DBg0y2U4mk8Hf39/k0ZDzNlupFU1RAT0BB6fa7yeTVZrDrQmMvH12K/DVo4C2FOj8N2Dcp4BHWzEyNSQg7YjtyqZOB65W9B6MvF88d7wHCOglkmp/W1Hz/tU1tenp2+RtGSTpdMDh9aJL7vFvbFeOlirx/wBIQOQowN9MoFyTsDvEc+pvoicrkSXoJ7atqRYJsG5NUhPIRwJsGCSVlpbi8OHDiI2NNVkfGxuLAwcOmN1ny5YtiI6OxtKlSxEUFISIiAjMnz8fxcWmA/gVFBQgNDQUwcHBGDVqFI4ePdqg8zZb9clH0msqc7id+RH4+nFxg+76IDB2rXHMjuAmUMuib2oL7gu4BYrlyrVJf6wWVdfmlOQZR1Y219QGiLGSZAogP61+4y9ZwvWTQGGmWL641zZlaKmy/gJOfieWh/6r7vv7dRXzaJUWMC+JLEc//Et1Pdv0vPQDSloocVunFWOFAQySsrKyoNVq4efnZ7Lez88PGRkZZvdJSUnBvn37cPLkSWzevBnLly/Ht99+i1mzZhm2iYyMxPr167FlyxZs3LgRKpUKMTExOH/+fL3PC4hcKLVabfJo0nQ64NI+sVyXfCQ9fbKeLXu4ndoMfD1ZTKnSbawYUK/yoGaWCJLKioGt/wIu7K7f/vqu/53/Zrq+0wjAr7u4eR2spoby3M+idsynU/V5KA7OgF/F0A22GlRSH8gBYkiJghu2KUdLlPg2IOmAiBGixreu5Apjk9vlfZYtG7Veda1JUl+t/2wDlWWeER0RHFxvf+5GYvPEbdktTQySJFVZp6fT6SCTybBhwwb069cPI0eOxLJly7B+/XpDbdKAAQPw2GOPoWfPnhg8eDC+/vprRERE4P33TZNo63JeAIiPj4e7u7vh0bbtbeZAs7WkL8SI2fZOQOig229/K31Nkq16uJ34Fvh2usiL6vEI8NBqMaheZYb5zf4UicX1cewr4I+PgO+eqHs3+6IcYyDaeZTpazIZMLQiv+T3D4Hi3Kr7366pTc/WeUl/7TT9+RJrkywiJwU4vkksD61jLlJlhrwkBklkIbWtSXLyApTuYvnm5YafV99BJahP7YessTKbBUk+Pj5QKBRVam8yMzOr1PLoBQQEICgoCO7u7oZ1nTt3hiRJuHr1qtl95HI5+vbta6hJqs95AeCFF15AXl6e4XHlypVavU+bKMgEdrwoloctFH/IdaX/58g63/i5Die+Bb5/UgRIvR4Dxqw0/w/j30MkpRfeEEnq9XGxYrTioizgyGd12/fcVlFGv+7m5zaKHA206Qxo1MDvH5m+VpxrDD6qa2rTqzzZbWMryTMOs9CpIueKTW6WkbhM/P10uLthg+YZ8pIOMi+JGq60sKILPqofI0lPJqs08rYFOvk0sXwkwIZBkoODA6KiopCQkGCyPiEhoUoitl5MTAzS0tJQUFBgWJecnAy5XI7g4GCz+0iShKSkJAQEBNT7vACgVCrh5uZm8miytj0vbm4BPYH+M+p3DPcQ48CI9Q1A6qMoB9gyRzRB9JkE/O396r9R2KvEqMNA/WpZdDrgYqWu0wfeq9uQB/qmti5/M/+6XG6sITi4wrQX3rmtIs/Ktwvga2aG7cr0zYppRxv/Jnhxr2ju9Govfh/6ddQwNy8DxzaKZX3+Wn35dxff5jVqMecVUUNkVczZ6eQNOHvffntLJm83sZ5tgI2b2+bNm4dPPvkEa9euxZkzZ/Dss88iNTUVM2aIG/sLL7yASZMmGbZ/9NFH4e3tjalTp+L06dPYu3cvFixYgGnTpsHR0REAsGjRImzfvh0pKSlISkrC9OnTkZSUZDhmbc7brCXvEImgMjkw+r2qTVS1JZcbR/1tzOTtQ2tErzD/7sCod0U5atKQvKQbZ0QNkr2TGPZAfc1447qdErUY2BIAOo+ufrsuY0TbekkecOhj4/rKTW23491R3ATLioDM07Urn6X89Yt47nC3aLaVKcSHYW4TrkltDva9I4LPdneK0fAbQq4AQivyDi9zKABqIP3n/e1qkfQsFSQV5xpzYIMYJAEAxo8fj+XLl2Px4sXo1asX9u7di61btyI0VMz6m56ebjJ2kYuLCxISEpCbm4vo6GhMnDgRo0ePxnvvGaeAyM3NxVNPPYXOnTsjNjYW165dw969e9GvX79an7fZ0hQAP1XM+TRgpnEW+fpq7OlJykpEfhAADJp7+wAJqNRFvh6DLeonBg0ZCAyaI5b3vVO72przO0TStXcH43UyR64ABleMoHzgA/E7KsoxBli1CZLkcuPIs405qKQkGZsEO94DqNyAwN7iZw5eWH95V4GjX4jlhtYi6TEviSxFn7R9u3wkPUsFSfqhXDzDAJc2DTuWBdWzmsFyZs6ciZkzZ5p9bf369VXWRUZGVmkqq+ydd97BO++806DzNlu/xou2ZPcQYNi/G368xp6e5PgmkV/kFgx0HVO7ffQ1SRnHxWS3dsran0/fbBQ+BIiaAuz9P+DmReD0D0D3sTXvW7lX2+1mqe72d2DPG+JD5M81gKOXqEXw617zHF2VBfcFUnaLvKS+02u3T0NlJQN5VwCF0ngTbjdUVImn7AF6Pdo45ahOYbb4e/ftCtg52LYsdbFvuWhqDRtcv04V5ujzki7/JrpRN5GkV2oEknT7z6C6uN3EtreyVJB0tSLnsgnVIgFNoHcbWUjaUeDgSrE8alnNo6TWVmPWJOl0wIGKHogDZ5p29a+JZ7hoO9eWivnTaktbbmyaaDdUXK8BFUFz4tuiPNUpKzZOJVJTU5uews5Ym7T/PWOTXm0DQcA205Pom9rCYoyDkYYPEc8X99a/R6El5KYCH8YAq+8E4oOBtfcBCS+LgUdvN8q5LRXcAI5+LpbrOrp2Tfx7iG7Tmry6/R9Q87Y7HljaDji6wXLHNExsW8su+PogKe+q+KJaX/rPtiaUtA0wSGoZtOXAlmdEsnO3saJpxBIMQVJyzUGDJZzfLoYsULobE4RrQyarXxf59CSR6KpyFzcYAOj3pJiOJfM0kPxz9fte2CXG8nBva2x+up0e4wCPUJEDpQ/OatPUpqd/j1nJ5ocTsIbK+Uh6bfsDCgcxuGV2PXqz5F4B3o8SzcL1TUIvzAI+f1BMuSOTi84Fqb8B+98VU9e81V6c44eZYqTw+pTTWg59Iub1C+xjDDgtQWHHvKTW5tAnooa6OAf470zgj49vv8/taMuMNUK1rUly8QUcXMT9J7eeU3tJEoMksqLfV4nmJpUHcF+85Y7rGS662JcViqRma9pfkVcWPaXukxrWp5ZF3/U/bLCxacLRA+j7hFje+3/V15QYmtpG176aW2EPDJ5n/Nm/B+DdvvbldfYWvw+gcYYCKC0yzgdWOUiydxSBEmC8hnXx5xog+y/xAf/d9LpPoKwpADY8LI7h3haIOwnM/hN4YIUIrg2TM/8FJG0AfpwLvN9HdGiwtbJiY/L+oNmWbSIBmJfUnFxMbFgv0eQdwNaKmkj9F6it842fo/WVkyJSARxcALeg2u1jMgxAPZvcbl4UwZ7Coe5T81gZg6Tm7uYlMfkoAMS+JqJ6S1HYicRkwLo93K7+CaQeEAFZfYYsqFeQpM9HGmq6fuAsMfRB2hGRA3Sr8lLRfR+oXVNbZT0fFflWQN1qkfQac7yky/tFDY1726rV7pWb3OpCpxWDd+qd/gHY9JhI2K+N8lIxRU3aEZHX9dj3gHuQyOvq/ZgYLmLW78C/LgKPfiOaOP0qhoj47YO6ldUajm0EirJFzmDnByx//LDB4vnyAevX/FL9XTsCfDpaPHa/Xvdm6/RjwDdTRM1N78eAJ34xNucnvAT8+mb9m8INPds61i2Ib2hekr4VIKBn3fJKGwGDpOZMkkSzRVmR+IDs/Zjlz6GvcrVmXpI+F6n7w8b5z+oisKLnV+7l2k2ZUVYiBt4DqjZ5OPuIJG4A2Pt21X0vJYru/M5tjDUqtWXnADy8Duj/NNDvqbrtCzRuXpKhqW141Q9L/TW7lFi3m/GF3aKJzNELeGQjYKcSzawbx4sB7Gqi0wE/PC2aOu2dgInfGDsW3MrJC4iIBYa/BEz4UjTJXdxjHEXYFnQ60bsRqMi5s0KfmYCeogagJFfMt0dNj04nanxQEcTseRP47yzRzFUbedeAL8eL2v3wocCo5eL/c/hLwF0viW1+fR345ZX6BUpZdez+r6cPkurbtN1Em9oABknN28nvxM1MoTT+s1iaYeRtK9Uk5VwEzmwRy4Nm1+8Yjh7Gf+razG929ZDIC3HxM9/uPmiOqNW6vM8YTOnpm9oiR9WvB1HbfsCINwClS933rTwmlLWTps3lI+kFRQH2zqJWJPNU7Y+ZVNHtvcc4IHIkMPFbcZyUX4HPHxLBpzmSBGz/N3DyW0BuB4z/vPaDzXmEABH3ieU/19a+rJaW/LMYkVjlbp0vM4AIvPSTWTflvKSzPwFvhou8sY2PAr8sEjWM146I5tSW7OjnoibYwRW4+1Ux7ljSBtGEXHmwWXNK1MCX48QXjTadgXGfmXZwGTIfuLci3WL/u8DP/6p7jaJhOpI6zptmqZqkhow8byUMkpqrohzg54oxVoYsAHw6WOc8hpokKwVJB1eKauMOd4sZzevLMF5SLYIkfS5N+BDzgaV7ENBrglhOrFSbpNMCZ/8nluva1GYJft1FQFycY5nRbauTc1Hk9MjtzCcXK+yNXddr2+RWfFPcHAHj0AHhg4FJ/xXJ+lcOAp89IP6ub7XvHZF3BwBjVpkP3GqiHzIh6cvb11hZi74WKWpq3XPu6qKp5yWlHxPzJBbniL+xcz8B+5YBm/8BfDwMiA8ClnUVifk/P9+0ku4bqigH+OVVsXzn88AdzwITvhI1oym7gXUjAXW6+X21ZaKJ7fpJ8eVu4tfiy+GtBs4UX5ghA/5YDfw4R3xu1VZDa5Lq87lUVmwcKZ41SWQxCS+JnlJtIoGYudY7T+VhACxde1GUYxxUTz+YY30FV3wDqU1TVOXxkaoTEyeaac7vEB/sgJjDrPCGqA3Q5380JjsH40zx1sxLulAxgGTb/uK9mlPXvKST34lhGvy6m85237YvMHmLaIJLOwqsHyXmHtQ78jmwc5FYvjde1ELVVbu7RNK7Jk/MC9jYTHLu/mHdcxnykvY3vbyk/OvAxgkiPaD9XcDjm4H73gSipwGhd4gmbEDMKH9hlwiM1420XWBrabteE8Fhm87Gv4OIWGDKT+K9Xz8BfHI3kHnGdD9JEk10F3aKgGrCV6KGtDrRU4EHPxKfX0e/AL5/qnbNeTqdcUqS2vZs09MHSbmptW861Es/LpLFnX1rfl82wiCpObp+yhhcjH7PugPpeXcQ/2wleaY3L0swTEHSo2oCdV0ZkpqP1PzNSZNvDDBqOqd3ezEIJGCsTdI3tXUaabvBCxsjL0k/ynaH4dVvY8hL2l+7rvz6cVzMDUAZ2AuYulV8Q848BawbIXIvzm4FfnxGbHPHs+Jbcn3I5cbapEMfN/74Tg3NuauLwF6iCbP4ZuNPYVOTshJg00TRS9a7IzB2nQiUBswARr0DTP0JWPCXSLqftl18rrm3BQoygIOrbF16o+un6h4EAEBakrG5d+Rbps1kQX1E8rV3RxEgrrnXdE7J/e+KoSwgA/7+iXH0/Zr0HC+usdxONFN/M+X2Yxipr4rPY7m9sSdtbbn4iw4vkrbuwwAY5mvra52UkQZikNQc6T80ujwAhNQxebiu7JTGfxhLJm+bTEHyTMP/Odp0Ft+ySvNrHiH88m/iW4tHKOB5m2lo7qjosn96i2hurNz131b0bfb1mauuNspLjdO11NSs5d9dDDlRmi/GnKpJ5hnRI01uV31NkG9nYOrPovdf9l/A2nuBb6cae/AMf6U+78ao10SRKJ5xwnrXzpyblxqec1cXCnvjZ4Kl85K05XUfsgEQQemPz4jAXuUBPLrJfFMRIJLuQwYAUZONv/P974rR1W1tz1vAqkGitlOTX/v9Kidrd/u7aGa+lWcYMH0H0HaAqPH84iFR63lqs0jCBoD73gAi76/9ebuOAcZvEE30Z/8HfDy85r99fT6Sd/u6dyyQyysNA3CxbvsakrabXj4SwCCp+SnMBk58I5YH1PObdV0ZmtwsmJd0/Ku6T0FSE4WdsZdbTbUslfORbsevi0jQhiSqrPOuiG/p7e9qcHHrTV9jlnGi9l3n6+LKQdFzxtnX2H3eHLnCOBXG7cZLSqqoRYq4T/QerI53e2DazyIoz7sikusjRoiJjhsaRDt5GWsGD33SsGPVxcFVItBrf1fDcu7qQv97seT8epIkkobfaCvG4qlLnsu+d8SUQzIFMO7T2o8P1u3vopZZowYS/69+5baUzDOiJxog/kc2PFz7QOnYl+IzycFFDNNSHScvkaPX+W+iafq76cB3T4rX+s8QtW511ek+EZSqPIzNeT/NN99JwpCPVMekbb365iVdrVST1AQxSGpujqwXN4+AXnXvgl5f+g93/TfihqrSHbqWU5DcTuXeX9XR59C0u7N2x9QPAKmvLel4jxhQ0VY8QkT+gq7MmOxoSZW7/t9ugmF9c2VKDUGSthw4tkks12auN48QUaMUPkTUlI5da7nu8tEVTW6nvm+cmomiHJFTBTQ8564uQvXzuFlwvKS/doqcmPISkQ+5bmTtkqrP/gTsXCyWR7xZ+/87QPz93VORj/bHx6JWzhZ0WuC/s8X/nD5PL/W32gVKxTeBhIqaoKH/un1zq70KePhTYMCsinOXieb9e1+vf/nbDxMDrvZ4BIAkmpw/6Aec+sG06VnfUlDXfCS9+gRJ+RniC5FMXvvZCxoZg6TmRFsG/FHxLbj/jMZrv42aLEZCvZRY8w2xtuo7Bcnt3C5IKsoxzmtV28TroCig3TDjz7ZsagPE79zQk88KeUnna+j6f6t2FUHSld+rr9W6sBMozAScfICOsbUrg1sAMPlH0cVZP2ecJQT1EV8utKXG4Qis6fA6USvn1830b8jaAnuLpueibMs0kUsSsHepWA69Q3Rfv3IQ+PAO4PfV1QdiGScrakIkMZJ9vyfrfu72d4lrpysDdi2p91tokD9Wi7wZpZvI83n8B/HZZQiUahi2YHe86GDjEyHGR6sNuRy473XRk3PgbJGH1NAJi13aAA99JGqqvNqJXK9vJosxl25eFtvom9vq2rNNrz5Bkv6zuk1n6/b6bAAGSc3JmS1izixnX6DbQ413Xvdg4wCLu5c0PPHVMAWJhbtD64fnv3HG/De8S4kAJNF86OpX++MOqRjN1k5V+xu9NVkrL0mdVjHukax2N3WfCJFsXV5SfcCm72DQY7zlagzrSyYzTjtzaI11e3+Va0QAAYhapMZMSLVzEONxAZbJS7qUKAJhhRIYuwaYeUDU9JUVAT8vAD5/oGqybsGNip5sFYMe3vdG/c9/96vi+cTXxp6mjeXmZWNN2D2LxPAgQX2AST9UCpTGmg+UMk4Yp6EZ+VbdO3v0ehS4d4llJivXa3cn8PRvwNDnRIL2+e3AygEi70vf3FbXMZL0DEFSHYZtMOQj1XLcMxtgkNSc/F6R6Bw9rfGHbh/8TxEkXPnd2PupPqzZHdotQOQ4STrRnfxW1U1FcjthdwAPfQJM2Aio3Bpezoaqy5hQdaH/vQb1EXPF3Y5MVvNQAEU5wLmKiYJr09TWGLr9XTSX5F42DnVgDSe+Fd/WXQOAro34hUbPknlJeypqkfpMAlz9RZPo4/8FRv6fqLG6uBdYOQg48pn4AlWuEdPN5KWKG+fD6xsWIAf2Ej0DAeM4Q41BkoD/xYlgMDQG6DPF+NrtAiVJEnOrSTqgy5i6NTNam70KGPZv4On94n2VFQEJL4umQchEL7v60AdJNy/XfvJqfU/jJpqPBDBIaj6uHREBitxeBEmNzdXf+C28IbVJBypqkazVHbqmLvL6psL6zL7e42HbJmxXFtgbgEzchCw5LENNo2xXp6Yg6cQ3opkkoGfTmbTSwQnoVTHitbUSuCXJ2O2//wzbDBehz0u6tL9hNb+pB0WgJbc3HY9NLhfNZzP2iR5ZpfnAljkiufuHmaI5TukOTNgkEpIb6q4XRRku7BLT2zSGYxvF+RRKMSTBrTl6QX2ASZvNN70d3yTW2TuJ2qCmqE0nMUbTAysAR0+xzjOs/k3cbkHiWunKxHACt6MtF/c1gDVJZAG/fyieuz1Ut6YiS4qJE//0aUeA5G113//KIWM3emslshqCpFsGW1SniTwomdz4Lbu5UrmJLvOA5WqTtOXGCX3rEyRd+7Nqk4O+V1uviQ0vnyXpv2QkbzfmY1jSXztFk6+Di7GZurEF9RHj1hRlNaxX6t63xHOvCYBH26qve7cXY1zd8x9xgzy/Q4zLI1OIeQrr23RzK88w45e0hJetP1BmQSaw7QWxfOfz1c9oEBRVKVA6IAIldTqwo2IetSELRLpCUyWTiSE2Zv8pJskdtaz+x5LLxe8JqF1e0o0zojlW6Vb/PKhGwCCpOcjPAE5+L5atPWJvTVzaGCdm3b2kbh9UJXnAd9NE9XP3h0X3emuonNRc+Ru0fnC2gJ7Vj9HSnBjykiyUvH3tsPgdqTyMQynUhmeYaH7RlYtvznoZJ0X+iNze2FTSVPh0qMi5kkRytaX9VlGL1Gey7f7W7JRiNHNAzEFYH9eOiNpFmcI4Zpg5cgUQ8wzwj73GWs4Rb9Y8GGl9DJkvksYzjoseitb087/ERMH+3W//hS4oSowerg+UVvQTnRW8O4jE6+bA2UdMktvQ2vK6JG8b5mvrc/uetDbUdEtGRn+uE1WYwf1sPwFgzNyKD6oTwNkfa7ePJAE/xonkTo9Q4P63b7tLvQX0FIMWFmaKrqV6dRkfqTnQB4PHN1lmdnt9U1v7YXXvcq/P8ao8XlLSl+K50wjLNLdYmr5W4shntx+JuC7Sj4sJe2WK+o1rY0n6Hpz1ncdtb8XYRN0fNg4UWBPfSOCJXcD88/XryXY7zj7AHRVNfjsXW/b3VtnZrWIQR5kC+NsHtcunCq4UKGkqJqodsdR2I/PbiiFIqsWAkoYgqek2tQEMkpq+cg3w5xqxbOsPXUDc8AZUdGXdHV+7QeWOfiG++cntxLg31c0HZgn2jqLLNWCsZZGk+idtN1Vd/iYGXVRfA9bcI3JPGqI++Uh6hiCp4hpry0TwBjS9pja9iPtEDkVRNnD6vzVvW14qOk280x1Y2h54Pxr45B5gwzjg+3+IiVh/fVP0ZtOPjtx1jO3noTJMdluPvKSMk2LyWchEp43akstFjbO1DJgppsDIvSy+PFpaSR7wU0Wt2aA5Imm8tvSBkncHUU5L16Q1B951qUnS92xruknbAIOkpu/k92JkatdAMRJrUzBwlvjGdOOM+MZVkxvnRNU1IJIvGyNBz9DkVpGXdPOiqFWS24spD1oCR08x31NwP9Es8PkY4Pg39TtWYZaxN2D7enyw66dZSD8uerSd3yFyYZx96xd0NQaFnTFfqLoEbkkSf98r+om/4bxU8b6yzwNX/xDdp49/JSZi/fV10R3+wi6xb1NoZgmKEj1SCzONE5fWln6E664PWi6vyBIcnEWOECDGbipR17y9JInRslP21G6E7IRXgPx0wKu98Tx1ERwFzDkM3Bdf931bgto2txXnGoccaMJJ2wBgoaFsySokyZiw3Xe67ceZ0XP0EPNQ7V4C/Bovuriaa6IpKwG+nSa6mLa7Exg0t+o21hAcLcYn0X9T0fdqC+5r2TFHbM3ZB5i8RUyZcmYL8P0TQO4lkYBZl3F5LuwGIIkaOLeAupfD1V8kXmadE+PyHPtKrO853nKjZVtDn0liqokrv4vmY/9K07BcPiCSb/WTbzr7AsNeED25im9W88gRzyGDajcJqbXZq8Tf/KVEkZdU22DnxjkxGjNgHCOsKen9OPDbChGsHnhPfPmqTFsueted3Qqc2yq+JAGi+Sywt+i4ETZYzHFXeZy2S/uMOWp/e8+2I+s3V5Wb23S66nON0ip6tXmG1TxVURPQhD/BCFd+F9Nh2KmAqKm2Lo2p/jOAgyvFZKQnvhG9X26V8DJw/aQYbfnBjxovOU9fk5R+TDSVGKYiaSFNbZXZO4ppDH55WXQ73/Wa6LE16p3aBdXacmNuWUOaB8KHiCDp5HfGno9NtalNz9VfjKB+arMYXHL0cpHf9csr4uYKiLn6Yp4RNUNKF5sWt17C7hBB0pn/Ab0n1S5oTVwGQBLzFjbWfHN1obAD7n5FjMX02wqRX+bgIsa9Ovez+Psrvllpe6WYykd9VQS91/4E9i83DZpCY4BtFTVHUVOafw9YW3ELFjX2Wg3w31kiqV9XLprgdeXG5dyKXqVNvKkNYJDUtB1cJZ67P1y7wf0ak8pNJHH/8iqw5w2g+1jTm/LZrcAfFYNfPvihuCE1Fq92ojmq+KaoITDkI7WQpO1byeVi4kyPUNEsdPRzIO+qmNbD3OCXOq3oiXbye5GPU5Ql1jekaSx8iKi90ze/BvYxDlPQlPV9QpT5+Nei5+XRLwBJK26gfSYBd75guyE3LCHiXlHbe2EnsO4+4KHVxm/75uSkGCfQboq1SHqRo0RT89U/gLX3im732kqJ3I6eIu+s00jRY0vpIjqOXNovaowuJYobdeWgCRCDf96z2CZvqUVQ2ImR+DNPiYl9b6cZfCYzSGqq8q4axxTq3wQSts3p95T4JnfzkujNFDVZrFenAf+dKZYHzhaTwjYmmUz0mPgrATj6mQgC7J2afC+KBuv3JODeFvh2qhjzaO19wMRvxFQKkiSaH09+J5pSCjKM+zl6ilqf0AZ8ew67A4AMQEWCcFMZYft2QmPENDU3zgJHPhXrOt0vairqO9FnUxLYW3SW+PFZ8fv/cLAYKbvnI+abZBOXiSCxwz1NdsJRAKLs9ywWgZ9+4lvPcCDyftGjsu2AqrVmHiFArxBjrfetQVN+OvC3963bsaQ1ePBDce+SK0RnHYW9qF2S24nfidxerHP0ajoD9NZAJkkNnYirdVKr1XB3d0deXh7c3KwwVcUvrwL73hFt51P+Z/njW8pvK4Dt/xY35zmHxT/Cp38TORABvYDpCbbpBvvrmyKZVuEgJjRtPxx43MpjqzQVaUfFxJUF1yumxXhQfGhVHhJB6Q50HiWmzGg31DL5bh8NEU2cCgdgfrJxFN+m7sS3wHfTRRAd+x8gdJCtS2R5uamiJ17qAfFz14dEk2zlcZxyrwDv9RJNItMTjPO/NWXHvhLBTcR9IthtyBx5NeXQUItSl/s3a5KaotIi4PB6sdxUa5H0oqeJCWvzrohmnqIcESA5uIhvsLYaJyS4Yjwpbal4bgbVuhYT2Fv0fNvwsKghObhSrHdwEc0P3R4S3+AsPf9fu2EiSIq8v/kESIBoKu54jxj5tzEnom1MHiHiy9a+ZWLojlPfi5qlBz8CwiqGCti/XARI4UOaR4AEiBoxS2GARGYwSGqKTnwt8mk8QkTVcVNm7yjGUfl5AbBrieiODogBI73b265ctw662RKTtmviEQJM2w78/JwIFLuOATrGWrfHzuB/ipqJ3o9b7xzW0hqaWOQKMU1Gu2HAd0+IXl+fjhKjaUdNAY58LrYb8i+bFpOoKWFzWz1ZrblNkoBVg4DM0yIZ11pznFlSuQZ4r49xUsMe40WCqK29Hy26CavcgX9dFDcJIhJjBv38nHF+PaWbGCk6ZCAw9eeWW6NGhLrdv1m/2NRc3CsCJHun5vON3E4JDK349unVzrrTjtSFvntp2GAGSESVKV2BMSuBsevElwj9VBpD6jjGFlELx+a2piY/XXxodRvbvCZi7TNJDAoWFGU6QJst9f+HqEmKaaRBLImam24PifyjhJfFeGb1GXGdqAVjc1s9WbV3W2mhGK26qY2NRERE1Myxd1tz5+DcsqbPICIiaoaYk0RERERkBoMkIiIiIjMYJBERERGZwSCJiIiIyAwGSURERERm2DxIWrlyJcLDw6FSqRAVFYXExMQat9doNFi4cCFCQ0OhVCrRvn17rF271uy2X331FWQyGcaMGWOyvry8HC+++CLCw8Ph6OiIdu3aYfHixdDpdJZ6W0RERNTM2XQIgE2bNiEuLg4rV65ETEwMPvroI4wYMQKnT59GSEiI2X3GjRuH69evY82aNejQoQMyMzNRXl5eZbvLly9j/vz5GDx4cJXX3nzzTXz44Yf49NNP0bVrV/z555+YOnUq3N3dMXcuBx4kIiIiGw8m2b9/f/Tp0werVq0yrOvcuTPGjBmD+Pj4Kttv27YNjzzyCFJSUuDl5VXtcbVaLYYOHYqpU6ciMTERubm5+OGHHwyvjxo1Cn5+flizZo1h3d///nc4OTnh888/r1XZrTqYJBEREVlFs5i7rbS0FIcPH0ZsbKzJ+tjYWBw4cMDsPlu2bEF0dDSWLl2KoKAgREREYP78+SguLjbZbvHixWjTpg2mT59u9jh33HEHdu7cieTkZADAsWPHsG/fPowcOdIC74yIiIhaAps1t2VlZUGr1cLPz89kvZ+fHzIyMszuk5KSgn379kGlUmHz5s3IysrCzJkzkZOTY8hL2r9/P9asWYOkpKRqz/3cc88hLy8PkZGRUCgU0Gq1WLJkCSZMmFDtPhqNBhqNxvCzWq2uw7slIiKi5sbm05LIbplxWpKkKuv0dDodZDIZNmzYAHd3dwDAsmXLMHbsWKxYsQLl5eV47LHH8PHHH8PHx6fac27atAlffPEFvvzyS3Tt2hVJSUmIi4tDYGAgJk+ebHaf+Ph4LFq0qJ7vkoiIiJobmwVJPj4+UCgUVWqNMjMzq9Qu6QUEBCAoKMgQIAEih0mSJFy9ehWFhYW4dOkSRo8ebXhd32PNzs4O586dQ/v27bFgwQI8//zzeOSRRwAA3bt3x+XLlxEfH19tkPTCCy9g3rx5hp/VajXatm1bvzdPRERETZ7NgiQHBwdERUUhISEBDz74oGF9QkICHnjgAbP7xMTE4JtvvkFBQQFcXFwAAMnJyZDL5QgODoZMJsOJEydM9nnxxReRn5+Pd9991xDUFBUVQS43TcdSKBQ1DgGgVCqhVCrr9V6JiIio+bFpc9u8efPw+OOPIzo6GgMHDsTq1auRmpqKGTNmABC1N9euXcNnn30GAHj00Ufxn//8B1OnTsWiRYuQlZWFBQsWYNq0aXB0dAQAdOvWzeQcHh4eVdaPHj0aS5YsQUhICLp27YqjR49i2bJlmDZtWq3Lru8UyNwkIiKi5kN/365V537JxlasWCGFhoZKDg4OUp8+faQ9e/YYXps8ebI0dOhQk+3PnDkj3X333ZKjo6MUHBwszZs3TyoqKqr2+JMnT5YeeOABk3VqtVqaO3euFBISIqlUKqldu3bSwoULJY1GU+tyX7lyRQLABx988MEHH3w0w8eVK1due6+36ThJzZlOp0NaWhpcXV2rTTSvL32+05UrVzgGUyPg9W5cvN6Ni9e7cfF6N676XG9JkpCfn4/AwMAqqTe3snnvtuZKnwdlTW5ubvwna0S83o2L17tx8Xo3Ll7vxlXX6125A1hNbD53GxEREVFTxCCJiIiIyAwGSU2QUqnEK6+8wiEHGgmvd+Pi9W5cvN6Ni9e7cVn7ejNxm4iIiMgM1iQRERERmcEgiYiIiMgMBklEREREZjBIIiIiIjKDQVITs3LlSoSHh0OlUiEqKgqJiYm2LlKLsHfvXowePRqBgYGQyWT44YcfTF6XJAmvvvoqAgMD4ejoiDvvvBOnTp2yTWFbgPj4ePTt2xeurq7w9fXFmDFjcO7cOZNteM0tZ9WqVejRo4dhQL2BAwfi559/NrzOa21d8fHxkMlkiIuLM6zjNbecV199FTKZzOTh7+9veN2a15pBUhOyadMmxMXFYeHChTh69CgGDx6MESNGIDU11dZFa/YKCwvRs2dPfPDBB2ZfX7p0KZYtW4YPPvgAhw4dgr+/P+655x7k5+c3cklbhj179mDWrFk4ePAgEhISUF5ejtjYWBQWFhq24TW3nODgYLzxxhv4888/8eeff+Kuu+7CAw88YLhR8Fpbz6FDh7B69Wr06NHDZD2vuWV17doV6enphseJEycMr1n1Wtd6Rleyun79+kkzZswwWRcZGSk9//zzNipRywRA2rx5s+FnnU4n+fv7S2+88YZhXUlJieTu7i59+OGHNihhy5OZmSkBMExgzWtufZ6entInn3zCa21F+fn5UseOHaWEhARp6NCh0ty5cyVJ4t+3pb3yyitSz549zb5m7WvNmqQmorS0FIcPH0ZsbKzJ+tjYWBw4cMBGpWodLl68iIyMDJNrr1QqMXToUF57C8nLywMAeHl5AeA1tyatVouvvvoKhYWFGDhwIK+1Fc2aNQv3338/7r77bpP1vOaWd/78eQQGBiI8PByPPPIIUlJSAFj/WnOC2yYiKysLWq0Wfn5+Juv9/PyQkZFho1K1Dvrra+7aX7582RZFalEkScK8efNwxx13oFu3bgB4za3hxIkTGDhwIEpKSuDi4oLNmzejS5cuhhsFr7VlffXVVzhy5AgOHTpU5TX+fVtW//798dlnnyEiIgLXr1/Ha6+9hkGDBuHUqVNWv9YMkpoYmUxm8rMkSVXWkXXw2lvH7Nmzcfz4cezbt6/Ka7zmltOpUyckJSUhNzcX3333HSZPnow9e/YYXue1tpwrV65g7ty52LFjB1QqVbXb8ZpbxogRIwzL3bt3x8CBA9G+fXt8+umnGDBgAADrXWs2tzURPj4+UCgUVWqNMjMzq0TIZFn6XhK89pY3Z84cbNmyBbt370ZwcLBhPa+55Tk4OKBDhw6Ijo5GfHw8evbsiXfffZfX2goOHz6MzMxMREVFwc7ODnZ2dtizZw/ee+892NnZGa4rr7l1ODs7o3v37jh//rzV/74ZJDURDg4OiIqKQkJCgsn6hIQEDBo0yEalah3Cw8Ph7+9vcu1LS0uxZ88eXvt6kiQJs2fPxvfff49du3YhPDzc5HVec+uTJAkajYbX2gqGDx+OEydOICkpyfCIjo7GxIkTkZSUhHbt2vGaW5FGo8GZM2cQEBBg/b/vBqd+k8V89dVXkr29vbRmzRrp9OnTUlxcnOTs7CxdunTJ1kVr9vLz86WjR49KR48elQBIy5Ytk44ePSpdvnxZkiRJeuONNyR3d3fp+++/l06cOCFNmDBBCggIkNRqtY1L3jw9/fTTkru7u/Trr79K6enphkdRUZFhG15zy3nhhRekvXv3ShcvXpSOHz8u/fvf/5bkcrm0Y8cOSZJ4rRtD5d5tksRrbkn//Oc/pV9//VVKSUmRDh48KI0aNUpydXU13Butea0ZJDUxK1askEJDQyUHBwepT58+hi7T1DC7d++WAFR5TJ48WZIk0Y30lVdekfz9/SWlUikNGTJEOnHihG0L3YyZu9YApHXr1hm24TW3nGnTphk+N9q0aSMNHz7cECBJEq91Y7g1SOI1t5zx48dLAQEBkr29vRQYGCg99NBD0qlTpwyvW/NayyRJkhpeH0VERETUsjAniYiIiMgMBklEREREZjBIIiIiIjKDQRIRERGRGQySiIiIiMxgkERERERkBoMkIiIiIjMYJBERWYhMJsMPP/xg62IQkYUwSCKiFmHKlCmQyWRVHvfdd5+ti0ZEzZSdrQtARGQp9913H9atW2eyTqlU2qg0RNTcsSaJiFoMpVIJf39/k4enpycA0RS2atUqjBgxAo6OjggPD8c333xjsv+JEydw1113wdHREd7e3njqqadQUFBgss3atWvRtWtXKJVKBAQEYPbs2SavZ2Vl4cEHH4STkxM6duyILVu2WPdNE5HVMEgiolbjpZdewt///nccO3YMjz32GCZMmIAzZ84AAIqKinDffffB09MThw4dwjfffINffvnFJAhatWoVZs2ahaeeegonTpzAli1b0KFDB5NzLFq0COPGjcPx48cxcuRITJw4ETk5OY36PonIQiwyTS4RkY1NnjxZUigUkrOzs8lj8eLFkiRJEgBpxowZJvv0799fevrppyVJkqTVq1dLnp6eUkFBgeH1n376SZLL5VJGRoYkSZIUGBgoLVy4sNoyAJBefPFFw88FBQWSTCaTfv75Z4u9TyJqPMxJIqIWY9iwYVi1apXJOi8vL8PywIEDTV4bOHAgkpKSAABnzpxBz5494ezsbHg9JiYGOp0O586dg0wmQ1paGoYPH15jGXr06GFYdnZ2hqurKzIzM+v7lojIhhgkEVGL4ezsXKX563ZkMhkAQJIkw7K5bRwdHWt1PHt7+yr76nS6OpWJiJoG5iQRUatx8ODBKj9HRkYCALp06YKkpCQUFhYaXt+/fz/kcjkiIiLg6uqKsLAw7Ny5s1HLTES2w5okImoxNBoNMjIyTNbZ2dnBx8cHAPDNN98gOjoad9xxBzZs2IA//vgDa9asAQBMnDgRr7zyCiZPnoxXX30VN27cwJw5c/D444/Dz88PAPDqq69ixowZ8PX1xYgRI5Cfn4/9+/djzpw5jftGiahRMEgiohZj27ZtCAgIMFnXqVMnnD17FoDoefbVV19h5syZ8Pf3x4YNG9ClSxcAgJOTE7Zv3465c+eib9++cHJywt///ncsW7bMcKzJkyejpKQE77zzDubPnw8fHx+MHTu28d4gETUqmSRJkq0LQURkbTKZDJs3b8aYMWNsXRQiaiaYk0RERERkBoMkIiIiIjOYk0RErQIzC4iorliTRERERGQGgyQiIiIiMxgkEREREZnBIImIiIjIDAZJRERERGYwSCIiIiIyg0ESERERkRkMkoiIiIjMYJBEREREZMb/A4hJJT0/bqNfAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf5cba5-8890-47c9-bd4e-915d00ed8129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1bba036-0c83-4388-945a-f56c513a8d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir\\hyperparameter_tuning\\tuner0.json\n",
      "\n",
      "The hyperparameter search is complete.\n",
      "The optimal number of layers is 3.\n",
      "The optimal number of units in each layer is:\n",
      "\n",
      "Layer 1: 64 units\n",
      "Layer 2: 32 units\n",
      "Layer 3: 32 units\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load your dataset (assuming it's already preprocessed)\n",
    "# data = pd.read_csv(\"DATA.csv\")  # Uncomment and modify this line to load your actual dataset\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop(['MonkeyPox', 'Patient_ID'], axis=1)  # Features (10 features)\n",
    "y = data['MonkeyPox']  # Target variable (0 for Negative, 1 for Positive)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the features (optional but recommended)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the model builder function for Keras Tuner\n",
    "def model_builder(hp):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # Tune the number of hidden layers (1 to 3)\n",
    "    for i in range(hp.Int('num_layers', 1, 3)):\n",
    "        # Tune the number of units in each layer (32 to 128)\n",
    "        model.add(keras.layers.Dense(units=hp.Int('units_' + str(i), min_value=32, max_value=128, step=16),\n",
    "                                      activation='relu'))\n",
    "    \n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Instantiate the Keras Tuner\n",
    "tuner = kt.Hyperband(\n",
    "    model_builder,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=50,\n",
    "    factor=3,\n",
    "    directory='my_dir',\n",
    "    project_name='hyperparameter_tuning'\n",
    ")\n",
    "\n",
    "# Run the hyperparameter search\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Retrieve the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete.\n",
    "The optimal number of layers is {best_hps.get('num_layers')}.\n",
    "The optimal number of units in each layer is:\n",
    "\"\"\")\n",
    "for i in range(best_hps.get('num_layers')):\n",
    "    print(f\"Layer {i + 1}: {best_hps.get('units_' + str(i))} units\")                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dea0320-a4d4-41b4-9b2d-70f22cdf47fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf5391d5-8854-4e41-9b9e-f5a1a767dca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir\\hyperparameter_tuning\\tuner0.json\n",
      "\n",
      "The hyperparameter search is complete.\n",
      "The optimal number of layers is 3.\n",
      "The optimal number of units in each layer is:\n",
      "\n",
      "Layer 1: 32 units\n",
      "Layer 2: 112 units\n",
      "Layer 3: 80 units\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load your dataset (assuming it's already preprocessed)\n",
    "# data = pd.read_csv(\"DATA.csv\")  # Uncomment and modify this line to load your actual dataset\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop(['MonkeyPox', 'Patient_ID'], axis=1)  # Features (10 features)\n",
    "y = data['MonkeyPox']  # Target variable (0 for Negative, 1 for Positive)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the features (optional but recommended)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the model builder function for Keras Tuner\n",
    "def model_builder(hp):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # Tune the number of hidden layers (1 to 3)\n",
    "    for i in range(hp.Int('num_layers', 1, 8)):\n",
    "        # Tune the number of units in each layer (32 to 128)\n",
    "        model.add(keras.layers.Dense(units=hp.Int('units_' + str(i), min_value=32, max_value=128, step=16),\n",
    "                                      activation='relu'))\n",
    "    \n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Instantiate the Keras Tuner\n",
    "tuner = kt.Hyperband(\n",
    "    model_builder,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=50,\n",
    "    factor=3,\n",
    "    directory='my_dir',\n",
    "    project_name='hyperparameter_tuning'\n",
    ")\n",
    "\n",
    "# Run the hyperparameter search\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Retrieve the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete.\n",
    "The optimal number of layers is {best_hps.get('num_layers')}.\n",
    "The optimal number of units in each layer is:\n",
    "\"\"\")\n",
    "for i in range(best_hps.get('num_layers')):\n",
    "    print(f\"Layer {i + 1}: {best_hps.get('units_' + str(i))} units\")     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8730829b-2aee-4158-a170-d8c573a8031d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19823778-37ec-44b1-870c-e6e242a410d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2380c60b-578e-4e76-b1dd-091861a93669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir\\hyperparameter_tuning\\tuner0.json\n",
      "\n",
      "The hyperparameter search is complete.\n",
      "The optimal number of layers is 2.\n",
      "The optimal number of units in each layer is:\n",
      "\n",
      "Layer 1: 32 units\n",
      "Layer 2: 112 units\n",
      "Epoch 1/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6631 - accuracy: 0.6291 - val_loss: 0.6511 - val_accuracy: 0.6482\n",
      "Epoch 2/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6498 - val_accuracy: 0.6482\n",
      "Epoch 3/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6500 - val_accuracy: 0.6482\n",
      "Epoch 4/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6502 - val_accuracy: 0.6482\n",
      "Epoch 5/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6490 - val_accuracy: 0.6482\n",
      "Epoch 6/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6497 - val_accuracy: 0.6482\n",
      "Epoch 7/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6500 - val_accuracy: 0.6482\n",
      "Epoch 8/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6497 - val_accuracy: 0.6482\n",
      "Epoch 9/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6497 - val_accuracy: 0.6482\n",
      "Epoch 10/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6490 - val_accuracy: 0.6482\n",
      "Epoch 11/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6488 - val_accuracy: 0.6482\n",
      "Epoch 12/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6500 - val_accuracy: 0.6482\n",
      "Epoch 13/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6502 - val_accuracy: 0.6482\n",
      "Epoch 14/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6490 - val_accuracy: 0.6482\n",
      "Epoch 15/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6593 - accuracy: 0.6294 - val_loss: 0.6485 - val_accuracy: 0.6482\n",
      "Epoch 16/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6597 - accuracy: 0.6294 - val_loss: 0.6498 - val_accuracy: 0.6482\n",
      "Epoch 17/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6495 - val_accuracy: 0.6482\n",
      "Epoch 18/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6493 - val_accuracy: 0.6482\n",
      "Epoch 19/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6491 - val_accuracy: 0.6482\n",
      "Epoch 20/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6488 - val_accuracy: 0.6482\n",
      "Epoch 21/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6498 - val_accuracy: 0.6482\n",
      "Epoch 22/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6504 - val_accuracy: 0.6482\n",
      "Epoch 23/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6490 - val_accuracy: 0.6482\n",
      "Epoch 24/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6499 - val_accuracy: 0.6482\n",
      "Epoch 25/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6488 - val_accuracy: 0.6482\n",
      "Epoch 26/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6490 - val_accuracy: 0.6482\n",
      "Epoch 27/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6487 - val_accuracy: 0.6482\n",
      "Epoch 28/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6486 - val_accuracy: 0.6482\n",
      "Epoch 29/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6490 - val_accuracy: 0.6482\n",
      "Epoch 30/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6496 - val_accuracy: 0.6482\n",
      "Epoch 31/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6486 - val_accuracy: 0.6482\n",
      "Epoch 32/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6488 - val_accuracy: 0.6482\n",
      "Epoch 33/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6596 - accuracy: 0.6294 - val_loss: 0.6494 - val_accuracy: 0.6482\n",
      "Epoch 34/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6511 - val_accuracy: 0.6482\n",
      "Epoch 35/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6486 - val_accuracy: 0.6482\n",
      "Epoch 36/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6490 - val_accuracy: 0.6482\n",
      "Epoch 37/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6496 - val_accuracy: 0.6482\n",
      "Epoch 38/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6509 - val_accuracy: 0.6482\n",
      "Epoch 39/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6486 - val_accuracy: 0.6482\n",
      "Epoch 40/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6500 - val_accuracy: 0.6482\n",
      "Epoch 41/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6496 - val_accuracy: 0.6482\n",
      "Epoch 42/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6490 - val_accuracy: 0.6482\n",
      "Epoch 43/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6497 - val_accuracy: 0.6482\n",
      "Epoch 44/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6593 - accuracy: 0.6294 - val_loss: 0.6501 - val_accuracy: 0.6482\n",
      "Epoch 45/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6491 - val_accuracy: 0.6482\n",
      "Epoch 46/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6505 - val_accuracy: 0.6482\n",
      "Epoch 47/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6593 - accuracy: 0.6294 - val_loss: 0.6501 - val_accuracy: 0.6482\n",
      "Epoch 48/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6492 - val_accuracy: 0.6482\n",
      "Epoch 49/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6495 - val_accuracy: 0.6482\n",
      "Epoch 50/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6509 - val_accuracy: 0.6482\n",
      "Epoch 51/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6596 - accuracy: 0.6294 - val_loss: 0.6499 - val_accuracy: 0.6482\n",
      "Epoch 52/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6494 - val_accuracy: 0.6482\n",
      "Epoch 53/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6489 - val_accuracy: 0.6482\n",
      "Epoch 54/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6490 - val_accuracy: 0.6482\n",
      "Epoch 55/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6500 - val_accuracy: 0.6482\n",
      "Epoch 56/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6489 - val_accuracy: 0.6482\n",
      "Epoch 57/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6491 - val_accuracy: 0.6482\n",
      "Epoch 58/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6487 - val_accuracy: 0.6482\n",
      "Epoch 59/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6596 - accuracy: 0.6294 - val_loss: 0.6491 - val_accuracy: 0.6482\n",
      "Epoch 60/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6485 - val_accuracy: 0.6482\n",
      "Epoch 61/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6498 - val_accuracy: 0.6482\n",
      "Epoch 62/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6505 - val_accuracy: 0.6482\n",
      "Epoch 63/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6506 - val_accuracy: 0.6482\n",
      "Epoch 64/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6593 - accuracy: 0.6294 - val_loss: 0.6486 - val_accuracy: 0.6482\n",
      "Epoch 65/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6486 - val_accuracy: 0.6482\n",
      "Epoch 66/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6491 - val_accuracy: 0.6482\n",
      "Epoch 67/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6488 - val_accuracy: 0.6482\n",
      "Epoch 68/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6494 - val_accuracy: 0.6482\n",
      "Epoch 69/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6494 - val_accuracy: 0.6482\n",
      "Epoch 70/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6593 - accuracy: 0.6294 - val_loss: 0.6488 - val_accuracy: 0.6482\n",
      "Epoch 71/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6492 - val_accuracy: 0.6482\n",
      "Epoch 72/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6494 - val_accuracy: 0.6482\n",
      "Epoch 73/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6491 - val_accuracy: 0.6482\n",
      "Epoch 74/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6499 - val_accuracy: 0.6482\n",
      "Epoch 75/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6501 - val_accuracy: 0.6482\n",
      "Epoch 76/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6490 - val_accuracy: 0.6482\n",
      "Epoch 77/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6593 - accuracy: 0.6294 - val_loss: 0.6510 - val_accuracy: 0.6482\n",
      "Epoch 78/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6493 - val_accuracy: 0.6482\n",
      "Epoch 79/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6489 - val_accuracy: 0.6482\n",
      "Epoch 80/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6488 - val_accuracy: 0.6482\n",
      "Epoch 81/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6491 - val_accuracy: 0.6482\n",
      "Epoch 82/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6490 - val_accuracy: 0.6482\n",
      "Epoch 83/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6486 - val_accuracy: 0.6482\n",
      "Epoch 84/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6488 - val_accuracy: 0.6482\n",
      "Epoch 85/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6487 - val_accuracy: 0.6482\n",
      "Epoch 86/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6485 - val_accuracy: 0.6482\n",
      "Epoch 87/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6496 - val_accuracy: 0.6482\n",
      "Epoch 88/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6592 - accuracy: 0.6294 - val_loss: 0.6485 - val_accuracy: 0.6482\n",
      "Epoch 89/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6507 - val_accuracy: 0.6482\n",
      "Epoch 90/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6492 - val_accuracy: 0.6482\n",
      "Epoch 91/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6501 - val_accuracy: 0.6482\n",
      "Epoch 92/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6593 - accuracy: 0.6294 - val_loss: 0.6486 - val_accuracy: 0.6482\n",
      "Epoch 93/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6492 - val_accuracy: 0.6482\n",
      "Epoch 94/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6492 - val_accuracy: 0.6482\n",
      "Epoch 95/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6496 - val_accuracy: 0.6482\n",
      "Epoch 96/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6488 - val_accuracy: 0.6482\n",
      "Epoch 97/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6501 - val_accuracy: 0.6482\n",
      "Epoch 98/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6496 - val_accuracy: 0.6482\n",
      "Epoch 99/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6491 - val_accuracy: 0.6482\n",
      "Epoch 100/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6488 - val_accuracy: 0.6482\n",
      "Epoch 101/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6493 - val_accuracy: 0.6482\n",
      "Epoch 102/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6487 - val_accuracy: 0.6482\n",
      "Epoch 103/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6596 - accuracy: 0.6294 - val_loss: 0.6493 - val_accuracy: 0.6482\n",
      "Epoch 104/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6497 - val_accuracy: 0.6482\n",
      "Epoch 105/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6489 - val_accuracy: 0.6482\n",
      "Epoch 106/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6504 - val_accuracy: 0.6482\n",
      "Epoch 107/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6593 - accuracy: 0.6294 - val_loss: 0.6495 - val_accuracy: 0.6482\n",
      "Epoch 108/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6489 - val_accuracy: 0.6482\n",
      "Epoch 109/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6496 - val_accuracy: 0.6482\n",
      "Epoch 110/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6490 - val_accuracy: 0.6482\n",
      "Epoch 111/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6496 - val_accuracy: 0.6482\n",
      "Epoch 112/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6497 - val_accuracy: 0.6482\n",
      "Epoch 113/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6497 - val_accuracy: 0.6482\n",
      "Epoch 114/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6498 - val_accuracy: 0.6482\n",
      "Epoch 115/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6593 - accuracy: 0.6294 - val_loss: 0.6488 - val_accuracy: 0.6482\n",
      "Epoch 116/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6495 - val_accuracy: 0.6482\n",
      "Epoch 117/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6490 - val_accuracy: 0.6482\n",
      "Epoch 118/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6493 - val_accuracy: 0.6482\n",
      "Epoch 119/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6495 - val_accuracy: 0.6482\n",
      "Epoch 120/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6501 - val_accuracy: 0.6482\n",
      "Epoch 121/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6495 - val_accuracy: 0.6482\n",
      "Epoch 122/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6490 - val_accuracy: 0.6482\n",
      "Epoch 123/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6503 - val_accuracy: 0.6482\n",
      "Epoch 124/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6593 - accuracy: 0.6294 - val_loss: 0.6488 - val_accuracy: 0.6482\n",
      "Epoch 125/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6488 - val_accuracy: 0.6482\n",
      "Epoch 126/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6490 - val_accuracy: 0.6482\n",
      "Epoch 127/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6490 - val_accuracy: 0.6482\n",
      "Epoch 128/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6488 - val_accuracy: 0.6482\n",
      "Epoch 129/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6491 - val_accuracy: 0.6482\n",
      "Epoch 130/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6492 - val_accuracy: 0.6482\n",
      "Epoch 131/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6492 - val_accuracy: 0.6482\n",
      "Epoch 132/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6499 - val_accuracy: 0.6482\n",
      "Epoch 133/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6498 - val_accuracy: 0.6482\n",
      "Epoch 134/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6489 - val_accuracy: 0.6482\n",
      "Epoch 135/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6489 - val_accuracy: 0.6482\n",
      "Epoch 136/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6493 - val_accuracy: 0.6482\n",
      "Epoch 137/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6488 - val_accuracy: 0.6482\n",
      "Epoch 138/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6500 - val_accuracy: 0.6482\n",
      "Epoch 139/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6487 - val_accuracy: 0.6482\n",
      "Epoch 140/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6500 - val_accuracy: 0.6482\n",
      "Epoch 141/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6493 - val_accuracy: 0.6482\n",
      "Epoch 142/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6491 - val_accuracy: 0.6482\n",
      "Epoch 143/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6492 - val_accuracy: 0.6482\n",
      "Epoch 144/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6490 - val_accuracy: 0.6482\n",
      "Epoch 145/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6488 - val_accuracy: 0.6482\n",
      "Epoch 146/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6491 - val_accuracy: 0.6482\n",
      "Epoch 147/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6489 - val_accuracy: 0.6482\n",
      "Epoch 148/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6497 - val_accuracy: 0.6482\n",
      "Epoch 149/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6492 - val_accuracy: 0.6482\n",
      "Epoch 150/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6498 - val_accuracy: 0.6482\n",
      "Epoch 151/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6493 - val_accuracy: 0.6482\n",
      "Epoch 152/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6493 - val_accuracy: 0.6482\n",
      "Epoch 153/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6493 - val_accuracy: 0.6482\n",
      "Epoch 154/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6489 - val_accuracy: 0.6482\n",
      "Epoch 155/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6499 - val_accuracy: 0.6482\n",
      "Epoch 156/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6504 - val_accuracy: 0.6482\n",
      "Epoch 157/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6495 - val_accuracy: 0.6482\n",
      "Epoch 158/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6494 - val_accuracy: 0.6482\n",
      "Epoch 159/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6493 - val_accuracy: 0.6482\n",
      "Epoch 160/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6501 - val_accuracy: 0.6482\n",
      "Epoch 161/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6500 - val_accuracy: 0.6482\n",
      "Epoch 162/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6496 - val_accuracy: 0.6482\n",
      "Epoch 163/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6593 - accuracy: 0.6294 - val_loss: 0.6508 - val_accuracy: 0.6482\n",
      "Epoch 164/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6501 - val_accuracy: 0.6482\n",
      "Epoch 165/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6490 - val_accuracy: 0.6482\n",
      "Epoch 166/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6491 - val_accuracy: 0.6482\n",
      "Epoch 167/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6495 - val_accuracy: 0.6482\n",
      "Epoch 168/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6492 - val_accuracy: 0.6482\n",
      "Epoch 169/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6500 - val_accuracy: 0.6482\n",
      "Epoch 170/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6493 - val_accuracy: 0.6482\n",
      "Epoch 171/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6496 - val_accuracy: 0.6482\n",
      "Epoch 172/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6492 - val_accuracy: 0.6482\n",
      "Epoch 173/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6492 - val_accuracy: 0.6482\n",
      "Epoch 174/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6492 - val_accuracy: 0.6482\n",
      "Epoch 175/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6492 - val_accuracy: 0.6482\n",
      "Epoch 176/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6491 - val_accuracy: 0.6482\n",
      "Epoch 177/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6491 - val_accuracy: 0.6482\n",
      "Epoch 178/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6491 - val_accuracy: 0.6482\n",
      "Epoch 179/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6488 - val_accuracy: 0.6482\n",
      "Epoch 180/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6495 - val_accuracy: 0.6482\n",
      "Epoch 181/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6490 - val_accuracy: 0.6482\n",
      "Epoch 182/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6490 - val_accuracy: 0.6482\n",
      "Epoch 183/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6495 - val_accuracy: 0.6482\n",
      "Epoch 184/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6496 - val_accuracy: 0.6482\n",
      "Epoch 185/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6490 - val_accuracy: 0.6482\n",
      "Epoch 186/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6490 - val_accuracy: 0.6482\n",
      "Epoch 187/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6593 - accuracy: 0.6294 - val_loss: 0.6503 - val_accuracy: 0.6482\n",
      "Epoch 188/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6503 - val_accuracy: 0.6482\n",
      "Epoch 189/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6496 - val_accuracy: 0.6482\n",
      "Epoch 190/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6498 - val_accuracy: 0.6482\n",
      "Epoch 191/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6492 - val_accuracy: 0.6482\n",
      "Epoch 192/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6593 - accuracy: 0.6294 - val_loss: 0.6488 - val_accuracy: 0.6482\n",
      "Epoch 193/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.6294 - val_loss: 0.6495 - val_accuracy: 0.6482\n",
      "Epoch 194/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6497 - val_accuracy: 0.6482\n",
      "Epoch 195/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6496 - val_accuracy: 0.6482\n",
      "Epoch 196/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6492 - val_accuracy: 0.6482\n",
      "Epoch 197/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6492 - val_accuracy: 0.6482\n",
      "Epoch 198/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6496 - val_accuracy: 0.6482\n",
      "Epoch 199/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6492 - val_accuracy: 0.6482\n",
      "Epoch 200/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.6294 - val_loss: 0.6495 - val_accuracy: 0.6482\n",
      "157/157 [==============================] - 0s 863us/step\n",
      "\n",
      "--- Performance Metrics ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1754\n",
      "           1       0.65      1.00      0.79      3246\n",
      "\n",
      "    accuracy                           0.65      5000\n",
      "   macro avg       0.32      0.50      0.39      5000\n",
      "weighted avg       0.42      0.65      0.51      5000\n",
      "\n",
      "AUC-ROC: 0.50\n",
      "Specificity: 0.00\n",
      "\n",
      "Confusion Matrix:\n",
      "[[   0 1754]\n",
      " [   0 3246]]\n",
      "\n",
      "--- Performance Metrics ---\n",
      "Test Accuracy: 64.92%\n",
      "Precision: 64.92%\n",
      "Recall: 100.00%\n",
      "F1 Score: 78.73%\n",
      "AUC-ROC: 50.00%\n",
      "Specificity: 0.00%\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "[[   0 1754]\n",
      " [   0 3246]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pulip\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\pulip\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\pulip\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Load your dataset (assuming it's already preprocessed)\n",
    "# data = pd.read_csv(\"DATA.csv\")  # Uncomment and modify this line to load your actual dataset\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop(['MonkeyPox'], axis=1)  # Features (10 features)\n",
    "y = data['MonkeyPox']  # Target variable (0 for Negative, 1 for Positive)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the features (optional but recommended)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the model builder function for Keras Tuner\n",
    "def model_builder(hp):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # Tune the number of hidden layers (1 to 8)\n",
    "    for i in range(hp.Int('num_layers', 1, 8)):\n",
    "        # Tune the number of units in each layer (32 to 128)\n",
    "        model.add(keras.layers.Dense(units=hp.Int('units_' + str(i), min_value=32, max_value=128, step=16),\n",
    "                                      activation='relu'))\n",
    "    \n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Instantiate the Keras Tuner\n",
    "tuner = kt.Hyperband(\n",
    "    model_builder,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=50,\n",
    "    factor=3,\n",
    "    directory='my_dir',\n",
    "    project_name='hyperparameter_tuning'\n",
    ")\n",
    "\n",
    "# Run the hyperparameter search\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Retrieve the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete.\n",
    "The optimal number of layers is {best_hps.get('num_layers')}.\n",
    "The optimal number of units in each layer is:\n",
    "\"\"\")\n",
    "for i in range(best_hps.get('num_layers')):\n",
    "    print(f\"Layer {i + 1}: {best_hps.get('units_' + str(i))} units\")\n",
    "\n",
    "# Train the best model found by Keras Tuner on the entire training dataset\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "best_model.fit(X_train, y_train, epochs=200, validation_split=0.2)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_prob = best_model.predict(X_test).flatten()  # Get predicted probabilities\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)            # Convert probabilities to binary predictions\n",
    "\n",
    "# Calculate performance metrics\n",
    "print(\"\\n--- Performance Metrics ---\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Calculate AUC-ROC score\n",
    "auc_roc = roc_auc_score(y_test, y_pred_prob)\n",
    "print(f'AUC-ROC: {auc_roc:.2f}')\n",
    "\n",
    "# Calculate confusion matrix for specificity calculation\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "TN = conf_matrix[0][0]  # True Negatives\n",
    "FP = conf_matrix[0][1]  # False Positives\n",
    "\n",
    "specificity = TN / (TN + FP) if (TN + FP) > 0 else 0  # Specificity calculation\n",
    "print(f'Specificity: {specificity:.2f}')\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Print all results at once\n",
    "print(\"\\n--- Performance Metrics ---\")\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {classification_rep['1']['precision'] * 100:.2f}%\")\n",
    "print(f\"Recall: {classification_rep['1']['recall'] * 100:.2f}%\")\n",
    "print(f\"F1 Score: {classification_rep['1']['f1-score'] * 100:.2f}%\")\n",
    "print(f\"AUC-ROC: {auc_roc * 100:.2f}%\")\n",
    "print(f\"Specificity: {specificity * 100:.2f}%\")\n",
    "\n",
    "# Display confusion matrix\n",
    "print(\"\\n--- Confusion Matrix ---\")\n",
    "print(conf_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb4b033-d413-432b-8e33-27d93d88db83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7c715d-2cf1-4050-807f-31f25ecc28d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "APPLYING K-FOLD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b8428d6-45eb-44fa-a6cf-b0981cd35ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir\\hyperparameter_tuning\\tuner0.json\n",
      "\n",
      "    Fold Results:\n",
      "    Optimal number of layers: 2\n",
      "    Optimal units in each layer:\n",
      "    \n",
      "Layer 1: 64 units\n",
      "Layer 2: 128 units\n",
      "Epoch 1/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6590 - accuracy: 0.6329\n",
      "Epoch 2/50\n",
      "625/625 [==============================] - 1s 960us/step - loss: 0.6575 - accuracy: 0.6331\n",
      "Epoch 3/50\n",
      "625/625 [==============================] - 1s 896us/step - loss: 0.6576 - accuracy: 0.6331\n",
      "Epoch 4/50\n",
      "625/625 [==============================] - 1s 908us/step - loss: 0.6575 - accuracy: 0.6331\n",
      "Epoch 5/50\n",
      "625/625 [==============================] - 1s 906us/step - loss: 0.6576 - accuracy: 0.6331\n",
      "Epoch 6/50\n",
      "625/625 [==============================] - 1s 897us/step - loss: 0.6576 - accuracy: 0.6331\n",
      "Epoch 7/50\n",
      "625/625 [==============================] - 1s 891us/step - loss: 0.6576 - accuracy: 0.6331\n",
      "Epoch 8/50\n",
      "625/625 [==============================] - 1s 901us/step - loss: 0.6576 - accuracy: 0.6331\n",
      "Epoch 9/50\n",
      "625/625 [==============================] - 1s 891us/step - loss: 0.6573 - accuracy: 0.6331\n",
      "Epoch 10/50\n",
      "625/625 [==============================] - 1s 878us/step - loss: 0.6575 - accuracy: 0.6331\n",
      "Epoch 11/50\n",
      "625/625 [==============================] - 1s 869us/step - loss: 0.6575 - accuracy: 0.6331\n",
      "Epoch 12/50\n",
      "625/625 [==============================] - 1s 948us/step - loss: 0.6575 - accuracy: 0.6331\n",
      "Epoch 13/50\n",
      "625/625 [==============================] - 1s 851us/step - loss: 0.6574 - accuracy: 0.6331\n",
      "Epoch 14/50\n",
      "625/625 [==============================] - 1s 873us/step - loss: 0.6574 - accuracy: 0.6331\n",
      "Epoch 15/50\n",
      "625/625 [==============================] - 1s 873us/step - loss: 0.6576 - accuracy: 0.6331\n",
      "Epoch 16/50\n",
      "625/625 [==============================] - 1s 875us/step - loss: 0.6574 - accuracy: 0.6331\n",
      "Epoch 17/50\n",
      "625/625 [==============================] - 1s 848us/step - loss: 0.6575 - accuracy: 0.6331\n",
      "Epoch 18/50\n",
      "625/625 [==============================] - 1s 889us/step - loss: 0.6575 - accuracy: 0.6331\n",
      "Epoch 19/50\n",
      "625/625 [==============================] - 1s 872us/step - loss: 0.6574 - accuracy: 0.6331\n",
      "Epoch 20/50\n",
      "625/625 [==============================] - 1s 854us/step - loss: 0.6576 - accuracy: 0.6331\n",
      "Epoch 21/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6575 - accuracy: 0.6331\n",
      "Epoch 22/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6577 - accuracy: 0.6331\n",
      "Epoch 23/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6575 - accuracy: 0.6331\n",
      "Epoch 24/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6574 - accuracy: 0.6331\n",
      "Epoch 25/50\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.6575 - accuracy: 0.6331\n",
      "Epoch 26/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6574 - accuracy: 0.6331\n",
      "Epoch 27/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6574 - accuracy: 0.6331\n",
      "Epoch 28/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6576 - accuracy: 0.6331\n",
      "Epoch 29/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6575 - accuracy: 0.6331\n",
      "Epoch 30/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6573 - accuracy: 0.6331\n",
      "Epoch 31/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6576 - accuracy: 0.6331\n",
      "Epoch 32/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6575 - accuracy: 0.6331\n",
      "Epoch 33/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6576 - accuracy: 0.6331\n",
      "Epoch 34/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6575 - accuracy: 0.6331\n",
      "Epoch 35/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6575 - accuracy: 0.6331\n",
      "Epoch 36/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6574 - accuracy: 0.6331\n",
      "Epoch 37/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6576 - accuracy: 0.6331\n",
      "Epoch 38/50\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.6576 - accuracy: 0.6331\n",
      "Epoch 39/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6575 - accuracy: 0.6331\n",
      "Epoch 40/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6575 - accuracy: 0.6331\n",
      "Epoch 41/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6574 - accuracy: 0.6331\n",
      "Epoch 42/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6574 - accuracy: 0.6331\n",
      "Epoch 43/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6574 - accuracy: 0.6331\n",
      "Epoch 44/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6574 - accuracy: 0.6331\n",
      "Epoch 45/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6574 - accuracy: 0.6331\n",
      "Epoch 46/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6574 - accuracy: 0.6331\n",
      "Epoch 47/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6575 - accuracy: 0.6331\n",
      "Epoch 48/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6574 - accuracy: 0.6331\n",
      "Epoch 49/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6574 - accuracy: 0.6331\n",
      "Epoch 50/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6575 - accuracy: 0.6331\n",
      "157/157 [==============================] - 0s 920us/step\n",
      "Reloading Tuner from my_dir\\hyperparameter_tuning\\tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pulip\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\pulip\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\pulip\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Fold Results:\n",
      "    Optimal number of layers: 2\n",
      "    Optimal units in each layer:\n",
      "    \n",
      "Layer 1: 32 units\n",
      "Layer 2: 112 units\n",
      "Epoch 1/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6583 - accuracy: 0.6358\n",
      "Epoch 2/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6560 - accuracy: 0.6360\n",
      "Epoch 3/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6560 - accuracy: 0.6360\n",
      "Epoch 4/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6559 - accuracy: 0.6360\n",
      "Epoch 5/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6557 - accuracy: 0.6360\n",
      "Epoch 6/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6560 - accuracy: 0.6360\n",
      "Epoch 7/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6558 - accuracy: 0.6360\n",
      "Epoch 8/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6560 - accuracy: 0.6360\n",
      "Epoch 9/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6559 - accuracy: 0.6360\n",
      "Epoch 10/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6560 - accuracy: 0.6360\n",
      "Epoch 11/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6559 - accuracy: 0.6360\n",
      "Epoch 12/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6559 - accuracy: 0.6360\n",
      "Epoch 13/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6558 - accuracy: 0.6360\n",
      "Epoch 14/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6559 - accuracy: 0.6360\n",
      "Epoch 15/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6558 - accuracy: 0.6360\n",
      "Epoch 16/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6559 - accuracy: 0.6360\n",
      "Epoch 17/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6558 - accuracy: 0.6360\n",
      "Epoch 18/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6560 - accuracy: 0.6360\n",
      "Epoch 19/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6559 - accuracy: 0.6360\n",
      "Epoch 20/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6559 - accuracy: 0.6360\n",
      "Epoch 21/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6560 - accuracy: 0.6360\n",
      "Epoch 22/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6559 - accuracy: 0.6360\n",
      "Epoch 23/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6559 - accuracy: 0.6360\n",
      "Epoch 24/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6559 - accuracy: 0.6360\n",
      "Epoch 25/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6558 - accuracy: 0.6360\n",
      "Epoch 26/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6558 - accuracy: 0.6360\n",
      "Epoch 27/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6558 - accuracy: 0.6360\n",
      "Epoch 28/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6558 - accuracy: 0.6360\n",
      "Epoch 29/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6559 - accuracy: 0.6360\n",
      "Epoch 30/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6560 - accuracy: 0.6360\n",
      "Epoch 31/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6560 - accuracy: 0.6360\n",
      "Epoch 32/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6558 - accuracy: 0.6360\n",
      "Epoch 33/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6559 - accuracy: 0.6360\n",
      "Epoch 34/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6558 - accuracy: 0.6360\n",
      "Epoch 35/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6559 - accuracy: 0.6360\n",
      "Epoch 36/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6557 - accuracy: 0.6360\n",
      "Epoch 37/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6560 - accuracy: 0.6360\n",
      "Epoch 38/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6558 - accuracy: 0.6360\n",
      "Epoch 39/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6558 - accuracy: 0.6360\n",
      "Epoch 40/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6558 - accuracy: 0.6360\n",
      "Epoch 41/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6559 - accuracy: 0.6360\n",
      "Epoch 42/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6558 - accuracy: 0.6360\n",
      "Epoch 43/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6558 - accuracy: 0.6360\n",
      "Epoch 44/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6559 - accuracy: 0.6360\n",
      "Epoch 45/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6559 - accuracy: 0.6360\n",
      "Epoch 46/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6557 - accuracy: 0.6360\n",
      "Epoch 47/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6558 - accuracy: 0.6360\n",
      "Epoch 48/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6558 - accuracy: 0.6360\n",
      "Epoch 49/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6559 - accuracy: 0.6360\n",
      "Epoch 50/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6558 - accuracy: 0.6360\n",
      "157/157 [==============================] - 0s 1ms/step\n",
      "Reloading Tuner from my_dir\\hyperparameter_tuning\\tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pulip\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\pulip\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\pulip\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Fold Results:\n",
      "    Optimal number of layers: 3\n",
      "    Optimal units in each layer:\n",
      "    \n",
      "Layer 1: 80 units\n",
      "Layer 2: 96 units\n",
      "Layer 3: 48 units\n",
      "Epoch 1/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6558 - accuracy: 0.6378\n",
      "Epoch 2/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6549 - accuracy: 0.6381\n",
      "Epoch 3/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6551 - accuracy: 0.6381\n",
      "Epoch 4/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6549 - accuracy: 0.6381\n",
      "Epoch 5/50\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.6548 - accuracy: 0.6381\n",
      "Epoch 6/50\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.6549 - accuracy: 0.6381\n",
      "Epoch 7/50\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.6551 - accuracy: 0.6381\n",
      "Epoch 8/50\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.6549 - accuracy: 0.6381\n",
      "Epoch 9/50\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.6547 - accuracy: 0.6381\n",
      "Epoch 10/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6549 - accuracy: 0.6381\n",
      "Epoch 11/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6549 - accuracy: 0.6381\n",
      "Epoch 12/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6549 - accuracy: 0.6381\n",
      "Epoch 13/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6548 - accuracy: 0.6381\n",
      "Epoch 14/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6547 - accuracy: 0.6381\n",
      "Epoch 15/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6549 - accuracy: 0.6381\n",
      "Epoch 16/50\n",
      "625/625 [==============================] - 2s 2ms/step - loss: 0.6548 - accuracy: 0.6381\n",
      "Epoch 17/50\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.6548 - accuracy: 0.6381\n",
      "Epoch 18/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6547 - accuracy: 0.6381\n",
      "Epoch 19/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6547 - accuracy: 0.6381\n",
      "Epoch 20/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6547 - accuracy: 0.6381\n",
      "Epoch 21/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6548 - accuracy: 0.6381\n",
      "Epoch 22/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6548 - accuracy: 0.6381\n",
      "Epoch 23/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6548 - accuracy: 0.6381\n",
      "Epoch 24/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6547 - accuracy: 0.6381\n",
      "Epoch 25/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6546 - accuracy: 0.6381\n",
      "Epoch 26/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6547 - accuracy: 0.6381\n",
      "Epoch 27/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6548 - accuracy: 0.6381\n",
      "Epoch 28/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6547 - accuracy: 0.6381\n",
      "Epoch 29/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6547 - accuracy: 0.6381\n",
      "Epoch 30/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6548 - accuracy: 0.6381\n",
      "Epoch 31/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6547 - accuracy: 0.6381\n",
      "Epoch 32/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6547 - accuracy: 0.6381\n",
      "Epoch 33/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6547 - accuracy: 0.6381\n",
      "Epoch 34/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6548 - accuracy: 0.6381\n",
      "Epoch 35/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6547 - accuracy: 0.6381\n",
      "Epoch 36/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6548 - accuracy: 0.6381\n",
      "Epoch 37/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6547 - accuracy: 0.6381\n",
      "Epoch 38/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6548 - accuracy: 0.6381\n",
      "Epoch 39/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6547 - accuracy: 0.6381\n",
      "Epoch 40/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6547 - accuracy: 0.6381\n",
      "Epoch 41/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6545 - accuracy: 0.6381\n",
      "Epoch 42/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6547 - accuracy: 0.6381\n",
      "Epoch 43/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6548 - accuracy: 0.6381\n",
      "Epoch 44/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6545 - accuracy: 0.6381\n",
      "Epoch 45/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6547 - accuracy: 0.6381\n",
      "Epoch 46/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6547 - accuracy: 0.6381\n",
      "Epoch 47/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6547 - accuracy: 0.6381\n",
      "Epoch 48/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6546 - accuracy: 0.6381\n",
      "Epoch 49/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6547 - accuracy: 0.6381\n",
      "Epoch 50/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6546 - accuracy: 0.6381\n",
      "157/157 [==============================] - 0s 904us/step\n",
      "Reloading Tuner from my_dir\\hyperparameter_tuning\\tuner0.json\n",
      "\n",
      "    Fold Results:\n",
      "    Optimal number of layers: 3\n",
      "    Optimal units in each layer:\n",
      "    \n",
      "Layer 1: 64 units\n",
      "Layer 2: 32 units\n",
      "Layer 3: 32 units\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pulip\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\pulip\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\pulip\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6544 - accuracy: 0.6405\n",
      "Epoch 2/50\n",
      "625/625 [==============================] - 1s 921us/step - loss: 0.6532 - accuracy: 0.6410\n",
      "Epoch 3/50\n",
      "625/625 [==============================] - 1s 980us/step - loss: 0.6531 - accuracy: 0.6410\n",
      "Epoch 4/50\n",
      "625/625 [==============================] - 1s 913us/step - loss: 0.6531 - accuracy: 0.6410\n",
      "Epoch 5/50\n",
      "625/625 [==============================] - 1s 990us/step - loss: 0.6529 - accuracy: 0.6410\n",
      "Epoch 6/50\n",
      "625/625 [==============================] - 1s 933us/step - loss: 0.6529 - accuracy: 0.6410\n",
      "Epoch 7/50\n",
      "625/625 [==============================] - 1s 894us/step - loss: 0.6530 - accuracy: 0.6410\n",
      "Epoch 8/50\n",
      "625/625 [==============================] - 1s 909us/step - loss: 0.6532 - accuracy: 0.6410\n",
      "Epoch 9/50\n",
      "625/625 [==============================] - 1s 906us/step - loss: 0.6530 - accuracy: 0.6410\n",
      "Epoch 10/50\n",
      "625/625 [==============================] - 1s 949us/step - loss: 0.6528 - accuracy: 0.6410\n",
      "Epoch 11/50\n",
      "625/625 [==============================] - 1s 914us/step - loss: 0.6532 - accuracy: 0.6410\n",
      "Epoch 12/50\n",
      "625/625 [==============================] - 1s 934us/step - loss: 0.6531 - accuracy: 0.6410\n",
      "Epoch 13/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6530 - accuracy: 0.6410\n",
      "Epoch 14/50\n",
      "625/625 [==============================] - 1s 911us/step - loss: 0.6531 - accuracy: 0.6410\n",
      "Epoch 15/50\n",
      "625/625 [==============================] - 1s 925us/step - loss: 0.6531 - accuracy: 0.6410\n",
      "Epoch 16/50\n",
      "625/625 [==============================] - 1s 943us/step - loss: 0.6531 - accuracy: 0.6410\n",
      "Epoch 17/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6530 - accuracy: 0.6410\n",
      "Epoch 18/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6529 - accuracy: 0.6410\n",
      "Epoch 19/50\n",
      "625/625 [==============================] - 1s 927us/step - loss: 0.6529 - accuracy: 0.6410\n",
      "Epoch 20/50\n",
      "625/625 [==============================] - 1s 919us/step - loss: 0.6530 - accuracy: 0.6410\n",
      "Epoch 21/50\n",
      "625/625 [==============================] - 1s 940us/step - loss: 0.6529 - accuracy: 0.6410\n",
      "Epoch 22/50\n",
      "625/625 [==============================] - 1s 909us/step - loss: 0.6530 - accuracy: 0.6410\n",
      "Epoch 23/50\n",
      "625/625 [==============================] - 1s 908us/step - loss: 0.6530 - accuracy: 0.6410\n",
      "Epoch 24/50\n",
      "625/625 [==============================] - 1s 935us/step - loss: 0.6530 - accuracy: 0.6410\n",
      "Epoch 25/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6530 - accuracy: 0.6410\n",
      "Epoch 26/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6530 - accuracy: 0.6410\n",
      "Epoch 27/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6531 - accuracy: 0.6410\n",
      "Epoch 28/50\n",
      "625/625 [==============================] - 1s 965us/step - loss: 0.6530 - accuracy: 0.6410\n",
      "Epoch 29/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6528 - accuracy: 0.6410\n",
      "Epoch 30/50\n",
      "625/625 [==============================] - 1s 942us/step - loss: 0.6530 - accuracy: 0.6410\n",
      "Epoch 31/50\n",
      "625/625 [==============================] - 1s 919us/step - loss: 0.6530 - accuracy: 0.6410\n",
      "Epoch 32/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6530 - accuracy: 0.6410\n",
      "Epoch 33/50\n",
      "625/625 [==============================] - 1s 934us/step - loss: 0.6531 - accuracy: 0.6410\n",
      "Epoch 34/50\n",
      "625/625 [==============================] - 1s 939us/step - loss: 0.6530 - accuracy: 0.6410\n",
      "Epoch 35/50\n",
      "625/625 [==============================] - 1s 925us/step - loss: 0.6531 - accuracy: 0.6410\n",
      "Epoch 36/50\n",
      "625/625 [==============================] - 1s 908us/step - loss: 0.6530 - accuracy: 0.6410\n",
      "Epoch 37/50\n",
      "625/625 [==============================] - 1s 959us/step - loss: 0.6530 - accuracy: 0.6410\n",
      "Epoch 38/50\n",
      "625/625 [==============================] - 1s 951us/step - loss: 0.6530 - accuracy: 0.6410\n",
      "Epoch 39/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6530 - accuracy: 0.6410\n",
      "Epoch 40/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6530 - accuracy: 0.6410\n",
      "Epoch 41/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6530 - accuracy: 0.6410\n",
      "Epoch 42/50\n",
      "625/625 [==============================] - 1s 969us/step - loss: 0.6530 - accuracy: 0.6410\n",
      "Epoch 43/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6530 - accuracy: 0.6410\n",
      "Epoch 44/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6529 - accuracy: 0.6410\n",
      "Epoch 45/50\n",
      "625/625 [==============================] - 1s 970us/step - loss: 0.6529 - accuracy: 0.6410\n",
      "Epoch 46/50\n",
      "625/625 [==============================] - 1s 935us/step - loss: 0.6530 - accuracy: 0.6410\n",
      "Epoch 47/50\n",
      "625/625 [==============================] - 1s 922us/step - loss: 0.6530 - accuracy: 0.6410\n",
      "Epoch 48/50\n",
      "625/625 [==============================] - 1s 942us/step - loss: 0.6529 - accuracy: 0.6410\n",
      "Epoch 49/50\n",
      "625/625 [==============================] - 1s 933us/step - loss: 0.6530 - accuracy: 0.6410\n",
      "Epoch 50/50\n",
      "625/625 [==============================] - 1s 985us/step - loss: 0.6529 - accuracy: 0.6410\n",
      "157/157 [==============================] - 0s 860us/step\n",
      "Reloading Tuner from my_dir\\hyperparameter_tuning\\tuner0.json\n",
      "\n",
      "    Fold Results:\n",
      "    Optimal number of layers: 3\n",
      "    Optimal units in each layer:\n",
      "    \n",
      "Layer 1: 32 units\n",
      "Layer 2: 80 units\n",
      "Layer 3: 48 units\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pulip\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\pulip\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\pulip\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6585 - accuracy: 0.6335\n",
      "Epoch 2/50\n",
      "625/625 [==============================] - 1s 943us/step - loss: 0.6573 - accuracy: 0.6335\n",
      "Epoch 3/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6575 - accuracy: 0.6335\n",
      "Epoch 4/50\n",
      "625/625 [==============================] - 1s 927us/step - loss: 0.6574 - accuracy: 0.6335\n",
      "Epoch 5/50\n",
      "625/625 [==============================] - 1s 970us/step - loss: 0.6574 - accuracy: 0.6335\n",
      "Epoch 6/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6574 - accuracy: 0.6335\n",
      "Epoch 7/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6575 - accuracy: 0.6335\n",
      "Epoch 8/50\n",
      "625/625 [==============================] - 1s 960us/step - loss: 0.6573 - accuracy: 0.6335\n",
      "Epoch 9/50\n",
      "625/625 [==============================] - 1s 913us/step - loss: 0.6572 - accuracy: 0.6335\n",
      "Epoch 10/50\n",
      "625/625 [==============================] - 1s 943us/step - loss: 0.6575 - accuracy: 0.6335\n",
      "Epoch 11/50\n",
      "625/625 [==============================] - 1s 957us/step - loss: 0.6573 - accuracy: 0.6335\n",
      "Epoch 12/50\n",
      "625/625 [==============================] - 1s 958us/step - loss: 0.6575 - accuracy: 0.6335\n",
      "Epoch 13/50\n",
      "625/625 [==============================] - 1s 904us/step - loss: 0.6571 - accuracy: 0.6335\n",
      "Epoch 14/50\n",
      "625/625 [==============================] - 1s 999us/step - loss: 0.6573 - accuracy: 0.6335\n",
      "Epoch 15/50\n",
      "625/625 [==============================] - 1s 950us/step - loss: 0.6573 - accuracy: 0.6335\n",
      "Epoch 16/50\n",
      "625/625 [==============================] - 1s 957us/step - loss: 0.6573 - accuracy: 0.6335\n",
      "Epoch 17/50\n",
      "625/625 [==============================] - 1s 932us/step - loss: 0.6573 - accuracy: 0.6335\n",
      "Epoch 18/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6573 - accuracy: 0.6335\n",
      "Epoch 19/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6574 - accuracy: 0.6335\n",
      "Epoch 20/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6573 - accuracy: 0.6335\n",
      "Epoch 21/50\n",
      "625/625 [==============================] - 1s 935us/step - loss: 0.6573 - accuracy: 0.6335\n",
      "Epoch 22/50\n",
      "625/625 [==============================] - 1s 955us/step - loss: 0.6572 - accuracy: 0.6335\n",
      "Epoch 23/50\n",
      "625/625 [==============================] - 1s 935us/step - loss: 0.6574 - accuracy: 0.6335\n",
      "Epoch 24/50\n",
      "625/625 [==============================] - 1s 958us/step - loss: 0.6573 - accuracy: 0.6335\n",
      "Epoch 25/50\n",
      "625/625 [==============================] - 1s 963us/step - loss: 0.6572 - accuracy: 0.6335\n",
      "Epoch 26/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6573 - accuracy: 0.6335\n",
      "Epoch 27/50\n",
      "625/625 [==============================] - 1s 944us/step - loss: 0.6572 - accuracy: 0.6335\n",
      "Epoch 28/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6571 - accuracy: 0.6335\n",
      "Epoch 29/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6573 - accuracy: 0.6335\n",
      "Epoch 30/50\n",
      "625/625 [==============================] - 1s 960us/step - loss: 0.6571 - accuracy: 0.6335\n",
      "Epoch 31/50\n",
      "625/625 [==============================] - 1s 952us/step - loss: 0.6573 - accuracy: 0.6335\n",
      "Epoch 32/50\n",
      "625/625 [==============================] - 1s 885us/step - loss: 0.6572 - accuracy: 0.6335\n",
      "Epoch 33/50\n",
      "625/625 [==============================] - 1s 864us/step - loss: 0.6573 - accuracy: 0.6335\n",
      "Epoch 34/50\n",
      "625/625 [==============================] - 1s 915us/step - loss: 0.6572 - accuracy: 0.6335\n",
      "Epoch 35/50\n",
      "625/625 [==============================] - 1s 861us/step - loss: 0.6572 - accuracy: 0.6335\n",
      "Epoch 36/50\n",
      "625/625 [==============================] - 1s 884us/step - loss: 0.6573 - accuracy: 0.6335\n",
      "Epoch 37/50\n",
      "625/625 [==============================] - 1s 859us/step - loss: 0.6572 - accuracy: 0.6335\n",
      "Epoch 38/50\n",
      "625/625 [==============================] - 1s 891us/step - loss: 0.6573 - accuracy: 0.6335\n",
      "Epoch 39/50\n",
      "625/625 [==============================] - 1s 881us/step - loss: 0.6573 - accuracy: 0.6335\n",
      "Epoch 40/50\n",
      "625/625 [==============================] - 1s 924us/step - loss: 0.6571 - accuracy: 0.6335\n",
      "Epoch 41/50\n",
      "625/625 [==============================] - 1s 901us/step - loss: 0.6572 - accuracy: 0.6335\n",
      "Epoch 42/50\n",
      "625/625 [==============================] - 1s 895us/step - loss: 0.6572 - accuracy: 0.6335\n",
      "Epoch 43/50\n",
      "625/625 [==============================] - 1s 885us/step - loss: 0.6573 - accuracy: 0.6335\n",
      "Epoch 44/50\n",
      "625/625 [==============================] - 1s 930us/step - loss: 0.6571 - accuracy: 0.6335\n",
      "Epoch 45/50\n",
      "625/625 [==============================] - 1s 916us/step - loss: 0.6572 - accuracy: 0.6335\n",
      "Epoch 46/50\n",
      "625/625 [==============================] - 1s 863us/step - loss: 0.6572 - accuracy: 0.6335\n",
      "Epoch 47/50\n",
      "625/625 [==============================] - 1s 883us/step - loss: 0.6572 - accuracy: 0.6335\n",
      "Epoch 48/50\n",
      "625/625 [==============================] - 1s 851us/step - loss: 0.6572 - accuracy: 0.6335\n",
      "Epoch 49/50\n",
      "625/625 [==============================] - 1s 893us/step - loss: 0.6572 - accuracy: 0.6335\n",
      "Epoch 50/50\n",
      "625/625 [==============================] - 1s 864us/step - loss: 0.6572 - accuracy: 0.6335\n",
      "157/157 [==============================] - 0s 813us/step\n",
      "\n",
      "--- Overall Performance Metrics ---\n",
      "\n",
      "Fold 1 Results:\n",
      "Accuracy: 0.65\n",
      "Precision: 0.65\n",
      "Recall: 1.00\n",
      "F1 Score: 0.79\n",
      "AUC-ROC: 0.50\n",
      "Specificity: 0.00\n",
      "Confusion Matrix:\n",
      "[[   0 1754]\n",
      " [   0 3246]]\n",
      "\n",
      "Fold 2 Results:\n",
      "Accuracy: 0.64\n",
      "Precision: 0.64\n",
      "Recall: 1.00\n",
      "F1 Score: 0.78\n",
      "AUC-ROC: 0.50\n",
      "Specificity: 0.00\n",
      "Confusion Matrix:\n",
      "[[   0 1812]\n",
      " [   0 3188]]\n",
      "\n",
      "Fold 3 Results:\n",
      "Accuracy: 0.63\n",
      "Precision: 0.63\n",
      "Recall: 1.00\n",
      "F1 Score: 0.77\n",
      "AUC-ROC: 0.50\n",
      "Specificity: 0.00\n",
      "Confusion Matrix:\n",
      "[[   0 1852]\n",
      " [   0 3148]]\n",
      "\n",
      "Fold 4 Results:\n",
      "Accuracy: 0.62\n",
      "Precision: 0.62\n",
      "Recall: 1.00\n",
      "F1 Score: 0.76\n",
      "AUC-ROC: 0.50\n",
      "Specificity: 0.00\n",
      "Confusion Matrix:\n",
      "[[   0 1912]\n",
      " [   0 3088]]\n",
      "\n",
      "Fold 5 Results:\n",
      "Accuracy: 0.65\n",
      "Precision: 0.65\n",
      "Recall: 1.00\n",
      "F1 Score: 0.79\n",
      "AUC-ROC: 0.50\n",
      "Specificity: 0.00\n",
      "Confusion Matrix:\n",
      "[[   0 1761]\n",
      " [   0 3239]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pulip\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\pulip\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\pulip\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Load your dataset (assuming it's already preprocessed)\n",
    "# data = pd.read_csv(\"DATA.csv\")  # Uncomment and modify this line to load your actual dataset\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop(['MonkeyPox', 'Patient_ID'], axis=1)  # Features (10 features)\n",
    "y = data['MonkeyPox']  # Target variable (0 for Negative, 1 for Positive)\n",
    "\n",
    "# Normalize the features (optional but recommended)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Define the model builder function for Keras Tuner\n",
    "def model_builder(hp):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # Tune the number of hidden layers (1 to 8)\n",
    "    for i in range(hp.Int('num_layers', 1, 8)):\n",
    "        # Tune the number of units in each layer (32 to 128)\n",
    "        model.add(keras.layers.Dense(units=hp.Int('units_' + str(i), min_value=32, max_value=128, step=16),\n",
    "                                      activation='relu'))\n",
    "    \n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Set up K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store results for each fold\n",
    "results = []\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "    y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "\n",
    "    # Instantiate the Keras Tuner\n",
    "    tuner = kt.Hyperband(\n",
    "        model_builder,\n",
    "        objective='val_accuracy',\n",
    "        max_epochs=50,\n",
    "        factor=3,\n",
    "        directory='my_dir',\n",
    "        project_name='hyperparameter_tuning'\n",
    "    )\n",
    "\n",
    "    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "    # Run the hyperparameter search on the training fold\n",
    "    tuner.search(X_train_fold, y_train_fold, epochs=50, validation_data=(X_val_fold, y_val_fold), callbacks=[stop_early])\n",
    "\n",
    "    # Retrieve the best hyperparameters from this fold\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    \n",
    "    print(f\"\"\"\n",
    "    Fold Results:\n",
    "    Optimal number of layers: {best_hps.get('num_layers')}\n",
    "    Optimal units in each layer:\n",
    "    \"\"\")\n",
    "    \n",
    "    for i in range(best_hps.get('num_layers')):\n",
    "        print(f\"Layer {i + 1}: {best_hps.get('units_' + str(i))} units\")\n",
    "\n",
    "    # Train the best model found by Keras Tuner on the entire training dataset of this fold\n",
    "    best_model = tuner.hypermodel.build(best_hps)\n",
    "    best_model.fit(X_train_fold, y_train_fold, epochs=50)\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_pred_prob = best_model.predict(X_val_fold).flatten()  # Get predicted probabilities\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int)                # Convert probabilities to binary predictions\n",
    "\n",
    "    # Calculate performance metrics for this fold\n",
    "    report = classification_report(y_val_fold, y_pred, output_dict=True)\n",
    "    \n",
    "    auc_roc = roc_auc_score(y_val_fold, y_pred_prob)\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_val_fold, y_pred)\n",
    "    \n",
    "    TN = conf_matrix[0][0]  # True Negatives\n",
    "    FP = conf_matrix[0][1]  # False Positives\n",
    "\n",
    "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0  # Specificity calculation\n",
    "    \n",
    "    results.append({\n",
    "        'accuracy': report['accuracy'],\n",
    "        'precision': report['1']['precision'],\n",
    "        'recall': report['1']['recall'],\n",
    "        'f1_score': report['1']['f1-score'],\n",
    "        'auc_roc': auc_roc,\n",
    "        'specificity': specificity,\n",
    "        'confusion_matrix': conf_matrix.tolist()  # Convert to list for easier printing\n",
    "    })\n",
    "\n",
    "# Print overall results across folds\n",
    "print(\"\\n--- Overall Performance Metrics ---\")\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"\\nFold {i + 1} Results:\")\n",
    "    print(f\"Accuracy: {result['accuracy']:.2f}\")\n",
    "    print(f\"Precision: {result['precision']:.2f}\")\n",
    "    print(f\"Recall: {result['recall']:.2f}\")\n",
    "    print(f\"F1 Score: {result['f1_score']:.2f}\")\n",
    "    print(f\"AUC-ROC: {result['auc_roc']:.2f}\")\n",
    "    print(f\"Specificity: {result['specificity']:.2f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(np.array(result['confusion_matrix']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdb1918-b3a3-4bc1-a201-037d739d7c37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f0faa4-3d1c-4064-a998-dad75ca049e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7d293b-7e89-4303-9007-470da8712e41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00c1f4c7-00a7-4ec8-a571-cb007745d7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Systemic Illness</th>\n",
       "      <th>Rectal Pain</th>\n",
       "      <th>Sore Throat</th>\n",
       "      <th>Penile Oedema</th>\n",
       "      <th>Oral Lesions</th>\n",
       "      <th>Solitary Lesion</th>\n",
       "      <th>Swollen Tonsils</th>\n",
       "      <th>HIV Infection</th>\n",
       "      <th>Sexually Transmitted Infection</th>\n",
       "      <th>MonkeyPox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>24995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>24996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>24997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>24998</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>24999</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Patient_ID  Systemic Illness  Rectal Pain  Sore Throat  Penile Oedema  \\\n",
       "0               0               NaN            0            1              1   \n",
       "1               1               1.0            1            0              1   \n",
       "2               2               1.0            0            1              1   \n",
       "3               3               NaN            1            0              0   \n",
       "4               4               2.0            1            1              1   \n",
       "...           ...               ...          ...          ...            ...   \n",
       "24995       24995               NaN            1            1              0   \n",
       "24996       24996               1.0            0            1              1   \n",
       "24997       24997               NaN            1            1              0   \n",
       "24998       24998               2.0            0            1              0   \n",
       "24999       24999               2.0            0            0              1   \n",
       "\n",
       "       Oral Lesions  Solitary Lesion  Swollen Tonsils  HIV Infection  \\\n",
       "0                 1                0                1              0   \n",
       "1                 1                0                0              1   \n",
       "2                 0                0                0              1   \n",
       "3                 0                1                1              1   \n",
       "4                 0                0                1              1   \n",
       "...             ...              ...              ...            ...   \n",
       "24995             1                1                0              0   \n",
       "24996             0                1                1              1   \n",
       "24997             0                1                1              0   \n",
       "24998             1                1                1              0   \n",
       "24999             0                0                1              1   \n",
       "\n",
       "       Sexually Transmitted Infection  MonkeyPox  \n",
       "0                                   0          0  \n",
       "1                                   0          1  \n",
       "2                                   0          1  \n",
       "3                                   0          1  \n",
       "4                                   0          1  \n",
       "...                               ...        ...  \n",
       "24995                               1          1  \n",
       "24996                               1          1  \n",
       "24997                               0          1  \n",
       "24998                               0          0  \n",
       "24999                               0          1  \n",
       "\n",
       "[25000 rows x 11 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e832fe-05bd-4cc7-8755-04757b7f68fd",
   "metadata": {},
   "source": [
    "# Feature selection using PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "723a630e-580a-4191-ab96-69962c765f59",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nPCA does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m n_components \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m9\u001b[39m  \u001b[38;5;66;03m# Specify the number of components you want to keep\u001b[39;00m\n\u001b[0;32m     24\u001b[0m pca \u001b[38;5;241m=\u001b[39m PCA(n_components\u001b[38;5;241m=\u001b[39mn_components)\n\u001b[1;32m---> 25\u001b[0m X_pca \u001b[38;5;241m=\u001b[39m \u001b[43mpca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_scaled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal number of features: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReduced number of features after PCA: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_pca\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\utils\\_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    319\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:474\u001b[0m, in \u001b[0;36mPCA.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    453\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \n\u001b[0;32m    455\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;124;03m    C-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 474\u001b[0m     U, S, _, X, x_is_centered, xp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m U \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    476\u001b[0m         U \u001b[38;5;241m=\u001b[39m U[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components_]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:511\u001b[0m, in \u001b[0;36mPCA._fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    502\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPCA with svd_solver=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marpack\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not supported for Array API inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    503\u001b[0m     )\n\u001b[0;32m    505\u001b[0m \u001b[38;5;66;03m# Validate the data, without ever forcing a copy as any solver that\u001b[39;00m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# supports sparse input data and the `covariance_eigh` solver are\u001b[39;00m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;66;03m# written in a way to avoid the need for any inplace modification of\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# the input data contrary to the other solvers.\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;66;03m# The copy will happen\u001b[39;00m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# later, only if needed, once the solver negotiation below is done.\u001b[39;00m\n\u001b[1;32m--> 511\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msvd_solver\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m issparse(X):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\utils\\validation.py:1064\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1061\u001b[0m     )\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m-> 1064\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\utils\\validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\utils\\validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    171\u001b[0m     )\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nPCA does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Load your dataset (assuming it's already preprocessed)\n",
    "# data = pd.read_csv(\"DATA.csv\")  # Uncomment and modify this line to load your actual dataset\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop(['MonkeyPox'], axis=1)  # Features (10 features)\n",
    "y = data['MonkeyPox']  # Target variable (0 for Negative, 1 for Positive)\n",
    "\n",
    "# Normalize the features (optional but recommended)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA for feature selection based on a fixed number of components\n",
    "n_components = 9  # Specify the number of components you want to keep\n",
    "pca = PCA(n_components=n_components)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(f\"Original number of features: {X.shape[1]}\")\n",
    "print(f\"Reduced number of features after PCA: {X_pca.shape[1]}\")\n",
    "\n",
    "# Set up K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the model builder function for Keras Tuner\n",
    "def model_builder(hp):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # Tune the number of hidden layers (1 to 8)\n",
    "    for i in range(hp.Int('num_layers', 1, 8)):\n",
    "        # Tune the number of units in each layer (32 to 128)\n",
    "        model.add(keras.layers.Dense(units=hp.Int('units_' + str(i), min_value=32, max_value=128, step=16),\n",
    "                                      activation='relu'))\n",
    "    \n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Store results for each fold\n",
    "results = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_pca):\n",
    "    X_train_fold, X_val_fold = X_pca[train_index], X_pca[val_index]\n",
    "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    # Instantiate the Keras Tuner\n",
    "    tuner = kt.Hyperband(\n",
    "        model_builder,\n",
    "        objective='val_accuracy',\n",
    "        max_epochs=50,\n",
    "        factor=3,\n",
    "        directory='my_dir',\n",
    "        project_name='hyperparameter_tuning'\n",
    "    )\n",
    "\n",
    "    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "    # Run the hyperparameter search on the training fold\n",
    "    tuner.search(X_train_fold, y_train_fold, epochs=50, validation_data=(X_val_fold, y_val_fold), callbacks=[stop_early])\n",
    "\n",
    "    # Retrieve the best hyperparameters from this fold\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    \n",
    "    print(f\"\"\"\n",
    "    Fold Results:\n",
    "    Optimal number of layers: {best_hps.get('num_layers')}\n",
    "    Optimal units in each layer:\n",
    "    \"\"\")\n",
    "    \n",
    "    for i in range(best_hps.get('num_layers')):\n",
    "        print(f\"Layer {i + 1}: {best_hps.get('units_' + str(i))} units\")\n",
    "\n",
    "    # Train the best model found by Keras Tuner on the entire training dataset of this fold\n",
    "    best_model = tuner.hypermodel.build(best_hps)\n",
    "    best_model.fit(X_train_fold, y_train_fold, epochs=50)\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_pred_prob = best_model.predict(X_val_fold).flatten()  # Get predicted probabilities\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int)                # Convert probabilities to binary predictions\n",
    "\n",
    "    # Calculate performance metrics for this fold\n",
    "    report = classification_report(y_val_fold, y_pred, output_dict=True)\n",
    "    \n",
    "    auc_roc = roc_auc_score(y_val_fold, y_pred_prob)\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_val_fold, y_pred)\n",
    "    \n",
    "    TN = conf_matrix[0][0]  # True Negatives\n",
    "    FP = conf_matrix[0][1]  # False Positives\n",
    "\n",
    "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0  # Specificity calculation\n",
    "    \n",
    "    results.append({\n",
    "        'accuracy': report['accuracy'],\n",
    "        'precision': report['1']['precision'],\n",
    "        'recall': report['1']['recall'],\n",
    "        'f1_score': report['1']['f1-score'],\n",
    "        'auc_roc': auc_roc,\n",
    "        'specificity': specificity,\n",
    "        'confusion_matrix': conf_matrix.tolist()  # Convert to list for easier printing\n",
    "    })\n",
    "\n",
    "# Print overall results across folds\n",
    "print(\"\\n--- Overall Performance Metrics ---\")\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"\\nFold {i + 1} Results:\")\n",
    "    print(f\"Accuracy: {result['accuracy']:.2f}\")\n",
    "    print(f\"Precision: {result['precision']:.2f}\")\n",
    "    print(f\"Recall: {result['recall']:.2f}\")\n",
    "    print(f\"F1 Score: {result['f1_score']:.2f}\")\n",
    "    print(f\"AUC-ROC: {result['auc_roc']:.2f}\")\n",
    "    print(f\"Specificity: {result['specificity']:.2f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(np.array(result['confusion_matrix']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe2e4a8-4507-466f-958c-870c183aea0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ce2ca4-8bc9-42e0-8b16-5317114a3fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d98e8de-f1fd-4cd2-87ba-6946678c36b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "If no scoring is specified, the estimator passed should have a 'score' method. The estimator <keras.engine.sequential.Sequential object at 0x0000018AE778F160> does not.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m initial_model\u001b[38;5;241m.\u001b[39mfit(X_scaled, y, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Calculate permutation importance\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mpermutation_importance\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Get feature importance and sort them\u001b[39;00m\n\u001b[0;32m     37\u001b[0m importance_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m'\u001b[39m: X\u001b[38;5;241m.\u001b[39mcolumns,\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m'\u001b[39m: result\u001b[38;5;241m.\u001b[39mimportances_mean,\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStd\u001b[39m\u001b[38;5;124m'\u001b[39m: result\u001b[38;5;241m.\u001b[39mimportances_std\n\u001b[0;32m     41\u001b[0m })\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\inspection\\_permutation_importance.py:281\u001b[0m, in \u001b[0;36mpermutation_importance\u001b[1;34m(estimator, X, y, scoring, n_repeats, n_jobs, random_state, sample_weight, max_samples)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m max_samples \u001b[38;5;241m>\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_samples must be <= n_samples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 281\u001b[0m scorer \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_scoring\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscoring\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    282\u001b[0m baseline_score \u001b[38;5;241m=\u001b[39m _weights_scorer(scorer, estimator, X, y, sample_weight)\n\u001b[0;32m    284\u001b[0m scores \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs)(\n\u001b[0;32m    285\u001b[0m     delayed(_calculate_permutation_scores)(\n\u001b[0;32m    286\u001b[0m         estimator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    297\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:1036\u001b[0m, in \u001b[0;36mcheck_scoring\u001b[1;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[0;32m   1034\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1036\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   1037\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf no scoring is specified, the estimator passed should \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1038\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m method. The estimator \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m does not.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m estimator\n\u001b[0;32m   1039\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: If no scoring is specified, the estimator passed should have a 'score' method. The estimator <keras.engine.sequential.Sequential object at 0x0000018AE778F160> does not."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Load your dataset (assuming it's already preprocessed)\n",
    "# data = pd.read_csv(\"DATA.csv\")  # Uncomment and modify this line to load your actual dataset\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop(['MonkeyPox', 'Patient_ID'], axis=1)  # Features (10 features)\n",
    "y = data['MonkeyPox']  # Target variable (0 for Negative, 1 for Positive)\n",
    "\n",
    "# Normalize the features (optional but recommended)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Initial model to compute permutation importance\n",
    "initial_model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(X_scaled.shape[1],)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "initial_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "initial_model.fit(X_scaled, y, epochs=50, verbose=0)\n",
    "\n",
    "# Calculate permutation importance\n",
    "result = permutation_importance(initial_model, X_scaled, y, n_repeats=30, random_state=42)\n",
    "\n",
    "# Get feature importance and sort them\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': result.importances_mean,\n",
    "    'Std': result.importances_std\n",
    "})\n",
    "\n",
    "# Sort by importance\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(\"Permutation Importance of Features:\")\n",
    "print(importance_df)\n",
    "\n",
    "# Select important features based on a threshold (e.g., keep features with importance > 0)\n",
    "selected_features = importance_df[importance_df['Importance'] > 0]['Feature'].values\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "print(f\"\\nSelected Features: {selected_features}\")\n",
    "\n",
    "# Set up K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the model builder function for Keras Tuner\n",
    "def model_builder(hp):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # Tune the number of hidden layers (1 to 8)\n",
    "    for i in range(hp.Int('num_layers', 1, 8)):\n",
    "        # Tune the number of units in each layer (32 to 128)\n",
    "        model.add(keras.layers.Dense(units=hp.Int('units_' + str(i), min_value=32, max_value=128, step=16),\n",
    "                                      activation='relu'))\n",
    "    \n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Store results for each fold\n",
    "results = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_selected):\n",
    "    X_train_fold, X_val_fold = X_selected.iloc[train_index], X_selected.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    # Instantiate the Keras Tuner\n",
    "    tuner = kt.Hyperband(\n",
    "        model_builder,\n",
    "        objective='val_accuracy',\n",
    "        max_epochs=50,\n",
    "        factor=3,\n",
    "        directory='my_dir',\n",
    "        project_name='hyperparameter_tuning'\n",
    "    )\n",
    "\n",
    "    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "    # Run the hyperparameter search on the training fold\n",
    "    tuner.search(X_train_fold, y_train_fold, epochs=50, validation_data=(X_val_fold, y_val_fold), callbacks=[stop_early])\n",
    "\n",
    "    # Retrieve the best hyperparameters from this fold\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    \n",
    "    print(f\"\"\"\n",
    "    Fold Results:\n",
    "    Optimal number of layers: {best_hps.get('num_layers')}\n",
    "    Optimal units in each layer:\n",
    "    \"\"\")\n",
    "    \n",
    "    for i in range(best_hps.get('num_layers')):\n",
    "        print(f\"Layer {i + 1}: {best_hps.get('units_' + str(i))} units\")\n",
    "\n",
    "    # Train the best model found by Keras Tuner on the entire training dataset of this fold\n",
    "    best_model = tuner.hypermodel.build(best_hps)\n",
    "    best_model.fit(X_train_fold, y_train_fold, epochs=50)\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_pred_prob = best_model.predict(X_val_fold).flatten()  # Get predicted probabilities\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int)                # Convert probabilities to binary predictions\n",
    "\n",
    "    # Calculate performance metrics for this fold\n",
    "    report = classification_report(y_val_fold, y_pred, output_dict=True)\n",
    "    \n",
    "    auc_roc = roc_auc_score(y_val_fold, y_pred_prob)\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_val_fold, y_pred)\n",
    "    \n",
    "    TN = conf_matrix[0][0]  # True Negatives\n",
    "    FP = conf_matrix[0][1]  # False Positives\n",
    "\n",
    "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0  # Specificity calculation\n",
    "    \n",
    "    results.append({\n",
    "        'accuracy': report['accuracy'],\n",
    "        'precision': report['1']['precision'],\n",
    "        'recall': report['1']['recall'],\n",
    "        'f1_score': report['1']['f1-score'],\n",
    "        'auc_roc': auc_roc,\n",
    "        'specificity': specificity,\n",
    "        'confusion_matrix': conf_matrix.tolist()  # Convert to list for easier printing\n",
    "    })\n",
    "\n",
    "# Print overall results across folds\n",
    "print(\"\\n--- Overall Performance Metrics ---\")\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"\\nFold {i + 1} Results:\")\n",
    "    print(f\"Accuracy: {result['accuracy']:.2f}\")\n",
    "    print(f\"Precision: {result['precision']:.2f}\")\n",
    "    print(f\"Recall: {result['recall']:.2f}\")\n",
    "    print(f\"F1 Score: {result['f1_score']:.2f}\")\n",
    "    print(f\"AUC-ROC: {result['auc_roc']:.2f}\")\n",
    "    print(f\"Specificity: {result['specificity']:.2f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(np.array(result['confusion_matrix']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6125d7-fd41-43dc-8736-494abe30c58b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70666250-f67b-4e6b-b1d0-ff82a8b710fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "If no scoring is specified, the estimator passed should have a 'score' method. The estimator <keras.engine.sequential.Sequential object at 0x0000018AD5B3DCF0> does not.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m initial_model\u001b[38;5;241m.\u001b[39mfit(X_scaled, y, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Calculate permutation importance\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mpermutation_importance\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Get feature importance and sort them\u001b[39;00m\n\u001b[0;32m     36\u001b[0m importance_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m'\u001b[39m: X\u001b[38;5;241m.\u001b[39mcolumns,\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m'\u001b[39m: result\u001b[38;5;241m.\u001b[39mimportances_mean,\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStd\u001b[39m\u001b[38;5;124m'\u001b[39m: result\u001b[38;5;241m.\u001b[39mimportances_std\n\u001b[0;32m     40\u001b[0m })\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\inspection\\_permutation_importance.py:281\u001b[0m, in \u001b[0;36mpermutation_importance\u001b[1;34m(estimator, X, y, scoring, n_repeats, n_jobs, random_state, sample_weight, max_samples)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m max_samples \u001b[38;5;241m>\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_samples must be <= n_samples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 281\u001b[0m scorer \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_scoring\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscoring\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    282\u001b[0m baseline_score \u001b[38;5;241m=\u001b[39m _weights_scorer(scorer, estimator, X, y, sample_weight)\n\u001b[0;32m    284\u001b[0m scores \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs)(\n\u001b[0;32m    285\u001b[0m     delayed(_calculate_permutation_scores)(\n\u001b[0;32m    286\u001b[0m         estimator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    297\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:1036\u001b[0m, in \u001b[0;36mcheck_scoring\u001b[1;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[0;32m   1034\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1036\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   1037\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf no scoring is specified, the estimator passed should \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1038\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m method. The estimator \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m does not.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m estimator\n\u001b[0;32m   1039\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: If no scoring is specified, the estimator passed should have a 'score' method. The estimator <keras.engine.sequential.Sequential object at 0x0000018AD5B3DCF0> does not."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Load your dataset (assuming it's already preprocessed)\n",
    "# data = pd.read_csv(\"DATA.csv\")  # Uncomment and modify this line to load your actual dataset\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop(['MonkeyPox'], axis=1)  # Features (10 features)\n",
    "y = data['MonkeyPox']  # Target variable (0 for Negative, 1 for Positive)\n",
    "\n",
    "# Normalize the features (optional but recommended)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Initial model to compute permutation importance\n",
    "initial_model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(X_scaled.shape[1],)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "initial_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "initial_model.fit(X_scaled, y, epochs=50, verbose=0)\n",
    "\n",
    "# Calculate permutation importance\n",
    "result = permutation_importance(initial_model, X_scaled, y, n_repeats=30, random_state=42)\n",
    "\n",
    "# Get feature importance and sort them\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': result.importances_mean,\n",
    "    'Std': result.importances_std\n",
    "})\n",
    "\n",
    "# Sort by importance\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(\"Permutation Importance of Features:\")\n",
    "print(importance_df)\n",
    "\n",
    "# Select important features based on a threshold (e.g., keep features with importance > 0)\n",
    "selected_features = importance_df[importance_df['Importance'] > 0]['Feature'].values\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "print(f\"\\nSelected Features: {selected_features}\")\n",
    "\n",
    "# Set up K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the model builder function for Keras Tuner\n",
    "def model_builder(hp):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # Tune the number of hidden layers (1 to 8)\n",
    "    for i in range(hp.Int('num_layers', 1, 8)):\n",
    "        # Tune the number of units in each layer (32 to 128)\n",
    "        model.add(keras.layers.Dense(units=hp.Int('units_' + str(i), min_value=32, max_value=128, step=16),\n",
    "                                      activation='relu'))\n",
    "    \n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Store results for each fold\n",
    "results = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_selected):\n",
    "    X_train_fold, X_val_fold = X_selected.iloc[train_index], X_selected.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    # Instantiate the Keras Tuner\n",
    "    tuner = kt.Hyperband(\n",
    "        model_builder,\n",
    "        objective='val_accuracy',\n",
    "        max_epochs=50,\n",
    "        factor=3,\n",
    "        directory='my_dir',\n",
    "        project_name='hyperparameter_tuning'\n",
    "    )\n",
    "\n",
    "    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "    # Run the hyperparameter search on the training fold\n",
    "    tuner.search(X_train_fold, y_train_fold, epochs=50, validation_data=(X_val_fold, y_val_fold), callbacks=[stop_early])\n",
    "\n",
    "    # Retrieve the best hyperparameters from this fold\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    \n",
    "    print(f\"\"\"\n",
    "    Fold Results:\n",
    "    Optimal number of layers: {best_hps.get('num_layers')}\n",
    "    Optimal units in each layer:\n",
    "    \"\"\")\n",
    "    \n",
    "    for i in range(best_hps.get('num_layers')):\n",
    "        print(f\"Layer {i + 1}: {best_hps.get('units_' + str(i))} units\")\n",
    "\n",
    "    # Train the best model found by Keras Tuner on the entire training dataset of this fold\n",
    "    best_model = tuner.hypermodel.build(best_hps)\n",
    "    best_model.fit(X_train_fold, y_train_fold, epochs=50)\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_pred_prob = best_model.predict(X_val_fold).flatten()  # Get predicted probabilities\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int)                # Convert probabilities to binary predictions\n",
    "\n",
    "    # Calculate performance metrics for this fold\n",
    "    report = classification_report(y_val_fold, y_pred, output_dict=True)\n",
    "    \n",
    "    auc_roc = roc_auc_score(y_val_fold, y_pred_prob)\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_val_fold, y_pred)\n",
    "    \n",
    "    TN = conf_matrix[0][0]  # True Negatives\n",
    "    FP = conf_matrix[0][1]  # False Positives\n",
    "\n",
    "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0  # Specificity calculation\n",
    "    \n",
    "    results.append({\n",
    "        'accuracy': report['accuracy'],\n",
    "        'precision': report['1']['precision'],\n",
    "        'recall': report['1']['recall'],\n",
    "        'f1_score': report['1']['f1-score'],\n",
    "        'auc_roc': auc_roc,\n",
    "        'specificity': specificity,\n",
    "        'confusion_matrix': conf_matrix.tolist()  # Convert to list for easier printing\n",
    "    })\n",
    "\n",
    "# Print overall results across folds\n",
    "print(\"\\n--- Overall Performance Metrics ---\")\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"\\nFold {i + 1} Results:\")\n",
    "    print(f\"Accuracy: {result['accuracy']:.2f}\")\n",
    "    print(f\"Precision: {result['precision']:.2f}\")\n",
    "    print(f\"Recall: {result['recall']:.2f}\")\n",
    "    print(f\"F1 Score: {result['f1_score']:.2f}\")\n",
    "    print(f\"AUC-ROC: {result['auc_roc']:.2f}\")\n",
    "    print(f\"Specificity: {result['specificity']:.2f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(np.array(result['confusion_matrix']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17246fc8-c88c-44df-9e04-bd103be3b57a",
   "metadata": {},
   "source": [
    "# SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca1f80fe-fe33-43bd-a201-3af283257127",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nMLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Feature selection with SHAP\u001b[39;00m\n\u001b[0;32m     24\u001b[0m model \u001b[38;5;241m=\u001b[39m MLPClassifier(hidden_layer_sizes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m100\u001b[39m,), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m explainer \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mExplainer(model, X_train)\n\u001b[0;32m     28\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m explainer(X_test)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:751\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[0;32m    735\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and target(s) y.\u001b[39;00m\n\u001b[0;32m    736\u001b[0m \n\u001b[0;32m    737\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;124;03m        Returns a trained MLP model.\u001b[39;00m\n\u001b[0;32m    750\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincremental\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:441\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._fit\u001b[1;34m(self, X, y, incremental)\u001b[0m\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    435\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_layer_sizes must be > 0, got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m hidden_layer_sizes\n\u001b[0;32m    436\u001b[0m     )\n\u001b[0;32m    437\u001b[0m first_pass \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoefs_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarm_start \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m incremental\n\u001b[0;32m    439\u001b[0m )\n\u001b[1;32m--> 441\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincremental\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_pass\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m n_samples, n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# Ensure y is 2D\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1096\u001b[0m, in \u001b[0;36mMLPClassifier._validate_input\u001b[1;34m(self, X, y, incremental, reset)\u001b[0m\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_input\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, incremental, reset):\n\u001b[1;32m-> 1096\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1097\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1098\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1105\u001b[0m         y \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\utils\\validation.py:1301\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1296\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1299\u001b[0m     )\n\u001b[1;32m-> 1301\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1306\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1315\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1320\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\utils\\validation.py:1064\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1061\u001b[0m     )\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m-> 1064\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\utils\\validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\utils\\validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    171\u001b[0m     )\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nMLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop(['MonkeyPox', 'Patient_ID'], axis=1)  # Features (10 features)\n",
    "y = data['MonkeyPox']  # Target variable (0 for Negative, 1 for Positive)\n",
    "\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature selection with SHAP\n",
    "model = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "explainer = shap.Explainer(model, X_train)\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "shap.summary_plot(shap_values, X_test)\n",
    "\n",
    "# Determine optimal hidden layers and neurons using GridSearchCV\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(100,), (100, 100), (100, 100, 100)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['adam', 'lbfgs']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9992a334-34a1-402b-b306-7f6e397d36bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6917c0b8-12e2-413d-a425-6b7d1541d399",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nGradientBoostingClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Train Gradient Boosting model\u001b[39;00m\n\u001b[0;32m     24\u001b[0m gb_model \u001b[38;5;241m=\u001b[39m GradientBoostingClassifier()\n\u001b[1;32m---> 25\u001b[0m \u001b[43mgb_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Calculate SHAP values\u001b[39;00m\n\u001b[0;32m     28\u001b[0m explainer \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mTreeExplainer(gb_model)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:659\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    653\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_state()\n\u001b[0;32m    655\u001b[0m \u001b[38;5;66;03m# Check input\u001b[39;00m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;66;03m# Since check_array converts both X and y to the same dtype, but the\u001b[39;00m\n\u001b[0;32m    657\u001b[0m \u001b[38;5;66;03m# trees use different types for X and y, checking them separately.\u001b[39;00m\n\u001b[1;32m--> 659\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    660\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    661\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    662\u001b[0m sample_weight_is_none \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    663\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\utils\\validation.py:1301\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1296\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1299\u001b[0m     )\n\u001b[1;32m-> 1301\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1306\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1315\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1320\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\utils\\validation.py:1064\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1061\u001b[0m     )\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m-> 1064\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\utils\\validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\utils\\validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    171\u001b[0m     )\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nGradientBoostingClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop(['MonkeyPox'], axis=1)  # Features (10 features)\n",
    "y = data['MonkeyPox']  # Target variable (0 for Negative, 1 for Positive)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier()\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Calculate SHAP values\n",
    "explainer = shap.TreeExplainer(gb_model)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "# Select features based on SHAP values (adjust threshold as needed)\n",
    "important_features = X.columns[np.abs(shap_values).mean(0) > 0.1]\n",
    "\n",
    "# Create a function to build the ANN model\n",
    "def create_ann_model(input_dim, hidden_layers, neurons_per_layer):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons_per_layer, activation='relu', input_dim=input_dim))\n",
    "    for _ in range(hidden_layers - 1):\n",
    "        model.add(Dense(neurons_per_layer, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Adjust activation for regression\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  # Adjust loss and metrics\n",
    "    return model\n",
    "\n",
    "# Hyperparameter tuning (adjust grid as needed)\n",
    "param_grid = {\n",
    "    'hidden_layers': [1, 2, 3,4,5,6],\n",
    "    'neurons_per_layer': [32, 64, 128]\n",
    "}\n",
    "\n",
    "# Grid search\n",
    "best_params = None\n",
    "best_score = 0\n",
    "for hidden_layers in param_grid['hidden_layers']:\n",
    "    for neurons_per_layer in param_grid['neurons_per_layer']:\n",
    "        model = create_ann_model(X_train.shape[1], hidden_layers, neurons_per_layer)\n",
    "        model.fit(X_train, y_train, epochs=100, validation_split=0.2)\n",
    "        score = model.evaluate(X_test, y_test)\n",
    "        if score[1] > best_score:\n",
    "            best_params = {'hidden_layers': hidden_layers, 'neurons_per_layer': neurons_per_layer}\n",
    "            best_score = score[1]\n",
    "\n",
    "# Build and train the final ANN model with the best parameters\n",
    "final_model = create_ann_model(**best_params)\n",
    "final_model.fit(X_train, y_train, epochs=100)\n",
    "\n",
    "# Evaluate the final model on the test set\n",
    "y_pred = final_model.predict(X_test)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)  # Adjust threshold if needed\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_binary) * 100\n",
    "precision = precision_score(y_test, y_pred_binary) * 100\n",
    "recall = recall_score(y_test, y_pred_binary) * 100\n",
    "f1 = f1_score(y_test, y_pred_binary) * 100\n",
    "specificity = recall_score(y_test, y_pred_binary, pos_label=0) * 100\n",
    "auc = roc_auc_score(y_test, y_pred) * 100\n",
    "\n",
    "print(\"Performance Metrics:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ab11ff-dd4e-4bfb-80cf-4a8007be3d13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21fafe68-f30b-425b-aab2-94f1307c2031",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nSelectKBest does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Feature selection with chi-squared test (select 9 features)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m chi2_selector \u001b[38;5;241m=\u001b[39m SelectKBest(score_func\u001b[38;5;241m=\u001b[39mchi2, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m X_train_chi2 \u001b[38;5;241m=\u001b[39m \u001b[43mchi2_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m X_test_chi2 \u001b[38;5;241m=\u001b[39m chi2_selector\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Get selected feature names\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\utils\\_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    319\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\base.py:1101\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m-> 1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:562\u001b[0m, in \u001b[0;36m_BaseFilter.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    560\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 562\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params(X, y)\n\u001b[0;32m    567\u001b[0m score_func_ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_func(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\utils\\validation.py:1301\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1296\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1299\u001b[0m     )\n\u001b[1;32m-> 1301\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1306\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1315\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1320\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\utils\\validation.py:1064\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1061\u001b[0m     )\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m-> 1064\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\utils\\validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\utils\\validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    171\u001b[0m     )\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nSelectKBest does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Load your data (replace 'data' with your actual DataFrame)\n",
    "X = data.drop('MonkeyPox', axis=1)\n",
    "y = data['MonkeyPox']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature selection with chi-squared test (select 9 features)\n",
    "chi2_selector = SelectKBest(score_func=chi2, k=9)\n",
    "X_train_chi2 = chi2_selector.fit_transform(X_train, y_train)\n",
    "X_test_chi2 = chi2_selector.transform(X_test)\n",
    "\n",
    "# Get selected feature names\n",
    "selected_feature_indices = chi2_selector.get_support(indices=True)\n",
    "selected_feature_names = X.columns[selected_feature_indices].tolist()\n",
    "print(\"Selected Features: \", selected_feature_names)\n",
    "print(\"Number of Selected Features:\", len(selected_feature_names))\n",
    "\n",
    "# Define function to create ANN model\n",
    "def create_ann_model(input_dim, hidden_layers, neurons_per_layer):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons_per_layer, activation='relu', input_dim=input_dim))\n",
    "    for _ in range(hidden_layers - 1):\n",
    "        model.add(Dense(neurons_per_layer, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define hyperparameter grid for Randomized Search\n",
    "param_dist = {\n",
    "    'hidden_layers': [1, 2, 3],\n",
    "    'neurons_per_layer': [32, 64, 128],\n",
    "    'epochs': [50, 100, 150]\n",
    "}\n",
    "\n",
    "# Implement Stratified K-Fold Cross-Validation with Randomized Search\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "random_search = RandomizedSearchCV(estimator=create_ann_model(X_train_chi2.shape[1]),\n",
    "                                   param_distributions=param_dist,\n",
    "                                   n_iter=50,\n",
    "                                   cv=skf,\n",
    "                                   scoring='accuracy',\n",
    "                                   random_state=42,\n",
    "                                   verbose=1)\n",
    "\n",
    "# Fit the Randomized Search\n",
    "random_search.fit(X_train_chi2, y_train)\n",
    "\n",
    "# Best parameters and score from Randomized Search\n",
    "print(\"Best Parameters from Randomized Search:\", random_search.best_params_)\n",
    "print(\"Best Score from Randomized Search:\", random_search.best_score_)\n",
    "\n",
    "# Evaluate on test set with best parameters\n",
    "best_model_random = random_search.best_estimator_\n",
    "y_pred_random = best_model_random.predict_classes(X_test_chi2)  # Use predict_classes for classification\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy_random = accuracy_score(y_test, y_pred_random)\n",
    "precision_random = precision_score(y_test, y_pred_random)\n",
    "recall_random = recall_score(y_test, y_pred_random)\n",
    "f1_random = f1_score(y_test, y_pred_random)\n",
    "auc_roc_random = roc_auc_score(y_test, y_pred_random)\n",
    "\n",
    "# Get confusion matrix for calculating specificity\n",
    "cm_random = confusion_matrix(y_test, y_pred_random)\n",
    "tn_random = cm_random[0, 0]  # True Negatives\n",
    "fp_random = cm_random[0, 1]  # False Positives\n",
    "specificity_random = tn_random / (tn_random + fp_random) if (tn_random + fp_random) > 0 else 0\n",
    "\n",
    "print(\"\\nRandomized Search Model Performance on Test Set:\")\n",
    "print(f\"Accuracy: {accuracy_random * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_random * 100:.2f}%\")\n",
    "print(f\"Recall: {recall_random * 100:.2f}%\")\n",
    "print(f\"F1-score: {f1_random * 100:.2f}%\")\n",
    "print(f\"AUC-ROC: {auc_roc_random * 100:.2f}%\")\n",
    "print(f\"Specificity: {specificity_random * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31c3c6d-3d7a-41cd-b81f-0f11946739c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fcb2ca-2ce8-42a8-a28f-b97357f33294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad6ac7c-6184-45d8-8168-3b4c37d8a09a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "954958e6-245c-4c21-9880-1f4e573c02e6",
   "metadata": {},
   "source": [
    "# CHECKING  FOR 1 TO 7 HIDDEN LAYERS AND WITH VARIOUS NO OF NEURONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78beb42a-079c-44c0-aa27-20ca77fc8764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir\\hyperparameter_tuning\\tuner0.json\n",
      "\n",
      "The hyperparameter search is complete.\n",
      "The optimal number of layers is 2.\n",
      "The optimal number of units in each layer is:\n",
      "\n",
      "Layer 1: 96 units\n",
      "Layer 2: 48 units\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop(['MonkeyPox'], axis=1)  # Features (10 features)\n",
    "y = data['MonkeyPox']  # Target variable (0 for Negative, 1 for Positive)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the features (optional but recommended)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the model builder function for Keras Tuner\n",
    "def model_builder(hp):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # Tune the number of hidden layers (1 to 8)\n",
    "    for i in range(hp.Int('num_layers', 1, 8)):\n",
    "        # Tune the number of units in each layer (32 to 128)\n",
    "        model.add(keras.layers.Dense(units=hp.Int('units_' + str(i), min_value=16, max_value=256, step=16),\n",
    "                                      activation='relu'))\n",
    "    \n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Instantiate the Keras Tuner\n",
    "tuner = kt.Hyperband(\n",
    "    model_builder,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=50,\n",
    "    factor=3,\n",
    "    directory='my_dir',\n",
    "    project_name='hyperparameter_tuning'\n",
    ")\n",
    "\n",
    "# Run the hyperparameter search\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Retrieve the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete.\n",
    "The optimal number of layers is {best_hps.get('num_layers')}.\n",
    "The optimal number of units in each layer is:\n",
    "\"\"\")\n",
    "for i in range(best_hps.get('num_layers')):\n",
    "    print(f\"Layer {i + 1}: {best_hps.get('units_' + str(i))} units\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66aa31d2-f53b-4239-b310-910e89cc3f25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb0b65a-4d63-495c-8c8d-a768e5c41c70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1fc4606-f2c4-4124-82af-fdc201fbc769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir\\hyperparameter_tuning\\tuner0.json\n",
      "\n",
      "The hyperparameter search is complete.\n",
      "The optimal number of layers is 1.\n",
      "The optimal number of units in each layer is:\n",
      "\n",
      "Layer 1: 32 units\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop(['MonkeyPox'], axis=1)  # Features (10 features)\n",
    "y = data['MonkeyPox']  # Target variable (0 for Negative, 1 for Positive)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the features (optional but recommended)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the model builder function for Keras Tuner\n",
    "def model_builder(hp):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # Tune the number of hidden layers (1 to 5)\n",
    "    for i in range(hp.Int('num_layers', 1, 5)):  # Allow up to 5 hidden layers\n",
    "        # Tune the number of units in each layer (16 to 256)\n",
    "        model.add(keras.layers.Dense(units=hp.Int('units_' + str(i), min_value=16, max_value=256, step=16),\n",
    "                                      activation='relu'))\n",
    "    \n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Instantiate the Keras Tuner\n",
    "tuner = kt.Hyperband(\n",
    "    model_builder,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=50,\n",
    "    factor=3,\n",
    "    directory='my_dir',\n",
    "    project_name='hyperparameter_tuning'\n",
    ")\n",
    "\n",
    "# Run the hyperparameter search\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Retrieve the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete.\n",
    "The optimal number of layers is {best_hps.get('num_layers')}.\n",
    "The optimal number of units in each layer is:\n",
    "\"\"\")\n",
    "for i in range(best_hps.get('num_layers')):\n",
    "    print(f\"Layer {i + 1}: {best_hps.get('units_' + str(i))} units\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096a6eec-a2a4-412f-98eb-7242cefa883a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
