{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0612f200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d357599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Patient_ID                           0\n",
       "Systemic Illness                  6216\n",
       "Rectal Pain                          0\n",
       "Sore Throat                          0\n",
       "Penile Oedema                        0\n",
       "Oral Lesions                         0\n",
       "Solitary Lesion                      0\n",
       "Swollen Tonsils                      0\n",
       "HIV Infection                        0\n",
       "Sexually Transmitted Infection       0\n",
       "MonkeyPox                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"DATA.csv\")\n",
    "# CHECKING  NO OF MISSING VALUES IN EACH COLUMN\n",
    "data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f1b054d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MonkeyPox\n",
      "Positive    15909\n",
      "Negative     9091\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentage of No Positive cases: 63.64%\n",
      "Percentage of Negative cases: 36.36%\n"
     ]
    }
   ],
   "source": [
    "# DISTRIBUTION  OF Positive cases and negative cases \n",
    "print(data['MonkeyPox'].value_counts())\n",
    "print()\n",
    "\n",
    "print('Percentage of No Positive cases: {}%'.format(round(data.MonkeyPox.value_counts()['Positive']/len(data) * 100.0,2)))\n",
    "print('Percentage of Negative cases: {}%'.format(round(data.MonkeyPox.value_counts()['Negative']/len(data) * 100.0,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a69eee75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIQUE VALUES IN A COLUMN'Patient_ID':['P0' 'P1' 'P2' ... 'P24997' 'P24998' 'P24999']'\n",
      "\n",
      "UNIQUE VALUES IN A COLUMN'Systemic Illness':[nan 'Fever' 'Swollen Lymph Nodes' 'Muscle Aches and Pain']'\n",
      "\n",
      "UNIQUE VALUES IN A COLUMN'Rectal Pain':[False  True]'\n",
      "\n",
      "UNIQUE VALUES IN A COLUMN'Sore Throat':[ True False]'\n",
      "\n",
      "UNIQUE VALUES IN A COLUMN'Penile Oedema':[ True False]'\n",
      "\n",
      "UNIQUE VALUES IN A COLUMN'Oral Lesions':[ True False]'\n",
      "\n",
      "UNIQUE VALUES IN A COLUMN'Solitary Lesion':[False  True]'\n",
      "\n",
      "UNIQUE VALUES IN A COLUMN'Swollen Tonsils':[ True False]'\n",
      "\n",
      "UNIQUE VALUES IN A COLUMN'HIV Infection':[False  True]'\n",
      "\n",
      "UNIQUE VALUES IN A COLUMN'Sexually Transmitted Infection':[False  True]'\n",
      "\n",
      "UNIQUE VALUES IN A COLUMN'MonkeyPox':['Negative' 'Positive']'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pulip\\AppData\\Local\\Temp\\ipykernel_37428\\3847041099.py:10: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[col]=data[col].replace({True:1,False:0})\n",
      "C:\\Users\\pulip\\AppData\\Local\\Temp\\ipykernel_37428\\3847041099.py:12: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data['MonkeyPox']=data['MonkeyPox'].replace({'Negative':0,'Positive':1})\n",
      "C:\\Users\\pulip\\AppData\\Local\\Temp\\ipykernel_37428\\3847041099.py:15: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data['Systemic Illness']=data['Systemic Illness'].replace({'None':0,'Fever':1,'Swollen Lymph Nodes':2,'Muscle Aches and Pain':3})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Systemic Illness</th>\n",
       "      <th>Rectal Pain</th>\n",
       "      <th>Sore Throat</th>\n",
       "      <th>Penile Oedema</th>\n",
       "      <th>Oral Lesions</th>\n",
       "      <th>Solitary Lesion</th>\n",
       "      <th>Swollen Tonsils</th>\n",
       "      <th>HIV Infection</th>\n",
       "      <th>Sexually Transmitted Infection</th>\n",
       "      <th>MonkeyPox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>24995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>24996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>24997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>24998</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>24999</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Patient_ID  Systemic Illness  Rectal Pain  Sore Throat  Penile Oedema  \\\n",
       "0               0               NaN            0            1              1   \n",
       "1               1               1.0            1            0              1   \n",
       "2               2               1.0            0            1              1   \n",
       "3               3               NaN            1            0              0   \n",
       "4               4               2.0            1            1              1   \n",
       "...           ...               ...          ...          ...            ...   \n",
       "24995       24995               NaN            1            1              0   \n",
       "24996       24996               1.0            0            1              1   \n",
       "24997       24997               NaN            1            1              0   \n",
       "24998       24998               2.0            0            1              0   \n",
       "24999       24999               2.0            0            0              1   \n",
       "\n",
       "       Oral Lesions  Solitary Lesion  Swollen Tonsils  HIV Infection  \\\n",
       "0                 1                0                1              0   \n",
       "1                 1                0                0              1   \n",
       "2                 0                0                0              1   \n",
       "3                 0                1                1              1   \n",
       "4                 0                0                1              1   \n",
       "...             ...              ...              ...            ...   \n",
       "24995             1                1                0              0   \n",
       "24996             0                1                1              1   \n",
       "24997             0                1                1              0   \n",
       "24998             1                1                1              0   \n",
       "24999             0                0                1              1   \n",
       "\n",
       "       Sexually Transmitted Infection  MonkeyPox  \n",
       "0                                   0          0  \n",
       "1                                   0          1  \n",
       "2                                   0          1  \n",
       "3                                   0          1  \n",
       "4                                   0          1  \n",
       "...                               ...        ...  \n",
       "24995                               1          1  \n",
       "24996                               1          1  \n",
       "24997                               0          1  \n",
       "24998                               0          0  \n",
       "24999                               0          1  \n",
       "\n",
       "[25000 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Unique values present in every column  \n",
    "for col in data.columns:\n",
    "    unique_values=data[col].unique()\n",
    "    print(f\"UNIQUE VALUES IN A COLUMN'{col}':{unique_values}'\")\n",
    "    print()\n",
    "\n",
    "#Converting the text into numerical of all the columns \n",
    "features=[\"Rectal Pain\",\"Sore Throat\",\"Penile Oedema\",\"Oral Lesions\",\"Solitary Lesion\",\"Swollen Tonsils\",\"HIV Infection\",\"Sexually Transmitted Infection\"]\n",
    "for col in features:\n",
    "    data[col]=data[col].replace({True:1,False:0})\n",
    "    \n",
    "data['MonkeyPox']=data['MonkeyPox'].replace({'Negative':0,'Positive':1})\n",
    "\n",
    "# None =0  fever =1   Swollen Lymph Nodes=2     Muscle Aches and Pain=3\n",
    "data['Systemic Illness']=data['Systemic Illness'].replace({'None':0,'Fever':1,'Swollen Lymph Nodes':2,'Muscle Aches and Pain':3})\n",
    "\n",
    "data['Patient_ID'] = data['Patient_ID'].str.replace('P','', regex=False).astype(int)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a40e45",
   "metadata": {},
   "source": [
    "# FEATURE SELECTION PROCESS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7cd3bb",
   "metadata": {},
   "source": [
    "# Filter Methods (Logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cc99385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Selected Features: 5\n",
      "Selected Features: ['Systemic Illness', 'Rectal Pain', 'Swollen Tonsils', 'HIV Infection', 'Sexually Transmitted Infection']\n",
      "Model Accuracy: 0.6704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"# Plotting feature scores\\nplt.bar(range(len(feature_scores)), feature_scores)\\nplt.title('Feature Scores using Mutual Information')\\nplt.xlabel('Feature Index')\\nplt.ylabel('Score')\\nplt.show() \""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MUTUAL INFORMATION = measures how much a given feature can explain another\n",
    "\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "X = data.drop('MonkeyPox', axis=1)  # Replace 'target_column' with your target variable\n",
    "y = data['MonkeyPox']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SelectKBest with mutual_info_classif\n",
    "k =5 # Change k to select the desired number of features\n",
    "fs = SelectKBest(score_func=mutual_info_classif, k=k)\n",
    "fs.fit(X_train, y_train)\n",
    "\n",
    "# Transform the training and testing data\n",
    "X_train_fs = fs.transform(X_train)\n",
    "X_test_fs = fs.transform(X_test)\n",
    "\n",
    "# Get the feature scores\n",
    "feature_scores = fs.scores_\n",
    "\n",
    "# Get the names of the selected features\n",
    "selected_features = X.columns[fs.get_support()]\n",
    "\n",
    "# Fit a model to evaluate accuracy\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_fs, y_train)\n",
    "\n",
    "# Make predictions and calculate accuracy\n",
    "y_pred = model.predict(X_test_fs)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"Number of Selected Features:\", len(selected_features))\n",
    "print(\"Selected Features:\", selected_features.tolist())\n",
    "print(\"Model Accuracy:\", accuracy)\n",
    "\n",
    "'''# Plotting feature scores\n",
    "plt.bar(range(len(feature_scores)), feature_scores)\n",
    "plt.title('Feature Scores using Mutual Information')\n",
    "plt.xlabel('Feature Index')\n",
    "plt.ylabel('Score')\n",
    "plt.show() '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab79465a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Selected Features: 5\n",
      "Selected Features: ['Rectal Pain', 'Sore Throat', 'Penile Oedema', 'HIV Infection', 'Sexually Transmitted Infection']\n",
      "Performance Metrics:\n",
      "Accuracy: 0.6690\n",
      "Precision: 0.6886\n",
      "Recall: 0.8949\n",
      "F1 Score: 0.7783\n",
      "ROC/AUC: 0.5729\n",
      "Specificity: 0.2509\n",
      "Confusion Matrix:\n",
      "[[ 440 1314]\n",
      " [ 341 2905]]\n"
     ]
    }
   ],
   "source": [
    "#It can be used to select the best categorical features for a \n",
    "#classification model. ANOVA (Analysis of Variance) is a\n",
    "#statistical test that is used to compare the means of two or more groups. \n",
    "\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest,f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             confusion_matrix, roc_auc_score,classification_report, roc_curve,f1_score)\n",
    "\n",
    "\n",
    "\n",
    "X = data.drop('MonkeyPox', axis=1)  # Replace 'target_column' with your target variable\n",
    "y = data['MonkeyPox']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SelectKBest with mutual_info_classif\n",
    "k =5 # Change k to select the desired number of features\n",
    "fs = SelectKBest(score_func=f_classif, k=k)\n",
    "fs.fit(X_train, y_train)\n",
    "\n",
    "# Transform the training and testing data\n",
    "X_train_fs = fs.transform(X_train)\n",
    "X_test_fs = fs.transform(X_test)\n",
    "\n",
    "# Get the feature scores\n",
    "feature_scores = fs.scores_\n",
    "\n",
    "# Get the names of the selected features\n",
    "selected_features = X.columns[fs.get_support()]\n",
    "\n",
    "# Fit a model to evaluate accuracy\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_fs, y_train)\n",
    "\n",
    "# Make predictions and calculate accuracy\n",
    "y_pred = model.predict(X_test_fs)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "f1= f1_score(y_test, y_pred)\n",
    "\n",
    "# Calculate specificity\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Print the results\n",
    "print(\"Number of Selected Features:\", len(selected_features))\n",
    "print(\"Selected Features:\", selected_features.tolist())\n",
    "\n",
    "print(\"Performance Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC/AUC: {roc_auc:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d2de94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c8d994f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Selected Features: 7\n",
      "Selected Features: ['Patient_ID', 'Rectal Pain', 'Sore Throat', 'Penile Oedema', 'Oral Lesions', 'HIV Infection', 'Sexually Transmitted Infection']\n",
      "Model Accuracy: 0.6592\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest,chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "X = data.drop('MonkeyPox', axis=1)  # Replace 'target_column' with your target variable\n",
    "y = data['MonkeyPox']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SelectKBest with mutual_info_classif\n",
    "k =7 # Change k to select the desired number of features\n",
    "fs = SelectKBest(score_func=chi2, k=k)\n",
    "fs.fit(X_train, y_train)\n",
    "\n",
    "# Transform the training and testing data\n",
    "X_train_fs = fs.transform(X_train)\n",
    "X_test_fs = fs.transform(X_test)\n",
    "\n",
    "# Get the feature scores\n",
    "feature_scores = fs.scores_\n",
    "\n",
    "# Get the names of the selected features\n",
    "selected_features = X.columns[fs.get_support()]\n",
    "\n",
    "# Fit a model to evaluate accuracy\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_fs, y_train)\n",
    "\n",
    "# Make predictions and calculate accuracy\n",
    "y_pred = model.predict(X_test_fs)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"Number of Selected Features:\", len(selected_features))\n",
    "print(\"Selected Features:\", selected_features.tolist())\n",
    "print(\"Model Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aa98b2",
   "metadata": {},
   "source": [
    "# Filter Methods (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18e2ce9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6746\n",
      "Precision: 0.6921433657726086\n",
      "Recall: 0.8983364140480592\n",
      "F1-score: 0.7818742458774636\n",
      "ROC AUC: 0.5794418672292747\n",
      "Confusion Matrix:\n",
      " [[ 457 1297]\n",
      " [ 330 2916]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "\n",
    "X = data.drop('MonkeyPox', axis=1)  # Replace 'target_column' with your target variable\n",
    "y = data['MonkeyPox']\n",
    "\n",
    "\n",
    "# Apply SelectKBest with chi-square as the scoring function\n",
    "selector = SelectKBest(f_classif, k=8)  # Select the top 10 features\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train SVM on the selected features\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df25293",
   "metadata": {},
   "source": [
    "# Filter Methods (Decision  Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c06574ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics:\n",
      "Number of Selected Features: 5\n",
      "Selected Features: ['Systemic Illness', 'Rectal Pain', 'Penile Oedema', 'HIV Infection', 'Sexually Transmitted Infection']\n",
      "Accuracy: 0.7000\n",
      "Precision: 0.7150\n",
      "Recall: 0.8943\n",
      "F1 Score: 0.7947\n",
      "ROC AUC: 0.6173\n",
      "Confusion Matrix:\n",
      " [[ 597 1157]\n",
      " [ 343 2903]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score, confusion_matrix)\n",
    "\n",
    "X = data.drop('MonkeyPox', axis=1)  # Replace 'target_column' with your target variable\n",
    "y = data['MonkeyPox']\n",
    "\n",
    "\n",
    "# Apply SelectKBest with chi-square as the scoring function\n",
    "selector = SelectKBest(mutual_info_classif, k=5)  # Select the top 10 features based on chi-square test\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Decision Tree Classifier on the selected features\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"Performance Metrics:\")\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "print(\"Number of Selected Features:\", len(selected_features))\n",
    "\n",
    "# Print selected feature names\n",
    "\n",
    "print(\"Selected Features:\", selected_features.tolist())\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7f7308",
   "metadata": {},
   "source": [
    "# Filter Method (Gradient Boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a24a6f22",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GradientBoostingClassifier\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (accuracy_score, precision_score, recall_score,\n\u001b[0;32m      6\u001b[0m                              f1_score, roc_auc_score, confusion_matrix)\n\u001b[1;32m----> 8\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMonkeyPox\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Replace 'target_column' with your target variable\u001b[39;00m\n\u001b[0;32m      9\u001b[0m y \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMonkeyPox\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Apply SelectKBest with chi-square as the scoring function\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score, confusion_matrix)\n",
    "\n",
    "X = data.drop('MonkeyPox', axis=1)  # Replace 'target_column' with your target variable\n",
    "y = data['MonkeyPox']\n",
    "\n",
    "# Apply SelectKBest with chi-square as the scoring function\n",
    "selector = SelectKBest(mutual_info_classif, k=7)  # Select the top 10 features based on chi-square test\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Gradient Boosting Classifier on the selected features\n",
    "clf = GradientBoostingClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "\n",
    "# Calculate confusion matrix for specificity calculation\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print performance metrics\n",
    "# Print selected feature names\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "print(\"Number of Selected Features:\", len(selected_features))\n",
    "print(\"Selected Features:\", selected_features.tolist())\n",
    "print(\"Performance Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84262953",
   "metadata": {},
   "source": [
    "# Filter Method (Adaboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dbc21fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pulip\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Selected Features: 6\n",
      "Selected Features: ['Systemic Illness', 'Rectal Pain', 'Sore Throat', 'Penile Oedema', 'HIV Infection', 'Sexually Transmitted Infection']\n",
      "Performance Metrics:\n",
      "Accuracy: 0.7008\n",
      "Precision: 0.7257\n",
      "Recall: 0.8666\n",
      "F1 Score: 0.7899\n",
      "ROC AUC: 0.7042\n",
      "Confusion Matrix:\n",
      " [[ 691 1063]\n",
      " [ 433 2813]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score, confusion_matrix)\n",
    "\n",
    "\n",
    "# Define features and target variable\n",
    "\n",
    "X = data.drop('MonkeyPox', axis=1)  # Replace 'target_column' with your target variable\n",
    "y = data['MonkeyPox']\n",
    "\n",
    "# Apply SelectKBest with chi-square as the scoring function\n",
    "selector = SelectKBest(mutual_info_classif, k=6)  # Select the top 10 features based on chi-square test\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train AdaBoost Classifier on the selected features\n",
    "base_estimator = DecisionTreeClassifier(max_depth=1)  # Using a decision stump as base estimator\n",
    "clf = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=50, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print performance metrics\n",
    "# Print selected feature names\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "print(\"Number of Selected Features:\", len(selected_features))\n",
    "print(\"Selected Features:\", selected_features.tolist())\n",
    "print(\"Performance Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fc1c55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3575cb28",
   "metadata": {},
   "source": [
    "# using varience threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ba0318c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.6674\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Apply variance threshold\n",
    "vt = VarianceThreshold(threshold=0.2)\n",
    "X_train_new = vt.fit_transform(X_train)\n",
    "X_test_new = vt.transform(X_test)\n",
    "\n",
    "# Get the selected feature names\n",
    "selected_features = X.columns[vt.get_support()]\n",
    "\n",
    "# Fit a model using the selected features\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_new, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = model.score(X_test_new, y_test)\n",
    "print(\"Model Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a758d48e",
   "metadata": {},
   "source": [
    "# Wrapped Method (RFE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "830733c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Selected Features: 5\n",
      "Selected Features: ['Rectal Pain', 'Sore Throat', 'Penile Oedema', 'HIV Infection', 'Sexually Transmitted Infection']\n",
      "Performance Metrics:\n",
      "Accuracy: 0.6690\n",
      "Precision: 0.6886\n",
      "Recall: 0.8949\n",
      "F1 Score: 0.7783\n",
      "ROC/AUC: 0.5729\n",
      "Specificity: 0.2509\n",
      "Confusion Matrix:\n",
      "[[ 440 1314]\n",
      " [ 341 2905]]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             confusion_matrix, roc_auc_score,classification_report, roc_curve,f1_score)\n",
    "\n",
    "\n",
    "X = data.drop('MonkeyPox', axis=1)  # Replace 'target_column' with your target variable\n",
    "y = data['MonkeyPox']\n",
    "\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Create the RFE model and select the top 5 features\n",
    "rfe = RFE(estimator=model, n_features_to_select=5)\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Transform the training and testing data\n",
    "X_train_selected = rfe.transform(X_train)\n",
    "X_test_selected = rfe.transform(X_test)\n",
    "\n",
    "# Get the selected feature names\n",
    "selected_features = X.columns[rfe.support_]\n",
    "\n",
    "# Fit the model on the selected features\n",
    "model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Make predictions and calculate accuracy\n",
    "y_pred = model.predict(X_test_selected)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "# Print results\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "f1= f1_score(y_test, y_pred)\n",
    "\n",
    "# Calculate specificity\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "\n",
    "# Print the results\n",
    "# Print results\n",
    "print(\"Number of Selected Features:\", len(selected_features))\n",
    "print(\"Selected Features:\", selected_features.tolist())\n",
    "print(\"Performance Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC/AUC: {roc_auc:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472e83ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91a355f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cf397f1",
   "metadata": {},
   "source": [
    "# RFE (Recursive Feature Selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f2f9a1",
   "metadata": {},
   "source": [
    "# RFE with Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0fbdd726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Selected Features: 8\n",
      "Selected Features: Index(['Patient_ID', 'Systemic Illness', 'Sore Throat', 'Penile Oedema',\n",
      "       'Oral Lesions', 'Solitary Lesion', 'Swollen Tonsils', 'HIV Infection'],\n",
      "      dtype='object')\n",
      "Performance Metrics:\n",
      "Accuracy: 0.5780\n",
      "Precision: 0.6772\n",
      "Recall: 0.6688\n",
      "F1 Score: 0.6730\n",
      "ROC/AUC: 0.5394\n",
      "Specificity: 0.4099\n",
      "Confusion Matrix:\n",
      "[[ 719 1035]\n",
      " [1075 2171]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.41      0.41      1754\n",
      "           1       0.68      0.67      0.67      3246\n",
      "\n",
      "    accuracy                           0.58      5000\n",
      "   macro avg       0.54      0.54      0.54      5000\n",
      "weighted avg       0.58      0.58      0.58      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             confusion_matrix, roc_auc_score,classification_report, roc_curve,f1_score)\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop('MonkeyPox', axis=1)  # Features\n",
    "y = data['MonkeyPox']  # Target variable\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Apply RFE\n",
    "rfe = RFE(estimator=model, n_features_to_select=8)  # Select the top 10 features\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = X.columns[rfe.support_]\n",
    "print(\"Number of Selected Features:\", len(selected_features))\n",
    "print(\"Selected Features:\", selected_features)\n",
    "\n",
    "# Transform the training and testing sets to include only the selected features\n",
    "X_train_rfe = rfe.transform(X_train)\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "\n",
    "# Train the model using the selected features\n",
    "model.fit(X_train_rfe, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_rfe)\n",
    "y_pred_proba = model.predict_proba(X_test_rfe)[:, 1]  # Probability estimates for ROC/AUC\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "f1= f1_score(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Calculate specificity\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Print the results\n",
    "print(\"Performance Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC/AUC: {roc_auc:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319dfc78",
   "metadata": {},
   "source": [
    "# RFE with Logistic Regression   (NO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f1027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             confusion_matrix, roc_auc_score, f1_score)\n",
    "\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop('MonkeyPox', axis=1)  # Features\n",
    "y = data['MonkeyPox']  # Target variable\n",
    "\n",
    "# Initialize the k-fold cross-validation\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store metrics for each fold\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "roc_auc_list = []\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "for train_index, test_index in kfold.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Create a Logistic Regression model\n",
    "    model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "    # Apply RFE\n",
    "    rfe = RFE(estimator=model, n_features_to_select=10)  # Select the top 10 features\n",
    "    rfe.fit(X_train, y_train)\n",
    "\n",
    "    # Transform the training and testing sets to include only the selected features\n",
    "    X_train_rfe = rfe.transform(X_train)\n",
    "    X_test_rfe = rfe.transform(X_test)\n",
    "\n",
    "    # Train the model using the selected features\n",
    "    model.fit(X_train_rfe, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_rfe)\n",
    "    y_pred_proba = model.predict_proba(X_test_rfe)[:, 1]  # Probability estimates for ROC/AUC\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    # Append metrics to the lists\n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "    roc_auc_list.append(roc_auc)\n",
    "\n",
    "# Calculate average metrics across all folds\n",
    "avg_accuracy = sum(accuracy_list) / len(accuracy_list)\n",
    "avg_precision = sum(precision_list) / len(precision_list)\n",
    "avg_recall = sum(recall_list) / len(recall_list)\n",
    "avg_f1 = sum(f1_list) / len(f1_list)\n",
    "avg_roc_auc = sum(roc_auc_list) / len(roc_auc_list)\n",
    "\n",
    "# Print the average results\n",
    "print(\"Average Performance Metrics across K-Folds:\")\n",
    "print(f\"Accuracy: {avg_accuracy:.4f}\")\n",
    "print(f\"Precision: {avg_precision:.4f}\")\n",
    "print(f\"Recall: {avg_recall:.4f}\")\n",
    "print(f\"F1 Score: {avg_f1:.4f}\")\n",
    "print(f\"ROC/AUC: {avg_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5825dd84",
   "metadata": {},
   "source": [
    "# RFE With Gradient Bossting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fc2006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             confusion_matrix, roc_auc_score, f1_score)\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop('MonkeyPox', axis=1)  # Features\n",
    "y = data['MonkeyPox']  # Target variable\n",
    "\n",
    "# Initialize the k-fold cross-validation\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store metrics for each fold\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "roc_auc_list = []\n",
    "specificity_list = []\n",
    "\n",
    "# Initialize the Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Initialize RFE with the Gradient Boosting model\n",
    "rfe = RFE(estimator=gb_model, n_features_to_select=4)  # Change n_features_to_select as needed\n",
    "\n",
    "# K-Fold Cross-Validation with Feature Selection\n",
    "for train_index, test_index in kfold.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Fit RFE on the training data\n",
    "    rfe.fit(X_train, y_train)\n",
    "\n",
    "    # Transform the training and testing sets to include only the selected features\n",
    "    X_train_rfe = rfe.transform(X_train)\n",
    "    X_test_rfe = rfe.transform(X_test)\n",
    "\n",
    "    # Train the Gradient Boosting model on the selected features\n",
    "    gb_model.fit(X_train_rfe, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = gb_model.predict(X_test_rfe)\n",
    "    y_pred_proba = gb_model.predict_proba(X_test_rfe)[:, 1]  # Probability estimates for ROC/AUC\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    # Calculate specificity\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "\n",
    "    # Append metrics to the lists\n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "    roc_auc_list.append(roc_auc)\n",
    "    specificity_list.append(specificity)\n",
    "\n",
    "# Calculate average metrics across all folds\n",
    "avg_accuracy = sum(accuracy_list) / len(accuracy_list)\n",
    "avg_precision = sum(precision_list) / len(precision_list)\n",
    "avg_recall = sum(recall_list) / len(recall_list)\n",
    "avg_f1 = sum(f1_list) / len(f1_list)\n",
    "avg_roc_auc = sum(roc_auc_list) / len(roc_auc_list)\n",
    "avg_specificity = sum(specificity_list) / len(specificity_list)\n",
    "\n",
    "# Print the average results\n",
    "print(\"Average Performance Metrics across K-Folds with RFE:\")\n",
    "print(f\"Accuracy: {avg_accuracy:.4f}\")\n",
    "print(f\"Precision: {avg_precision:.4f}\")\n",
    "print(f\"Recall: {avg_recall:.4f}\")\n",
    "print(f\"F1 Score: {avg_f1:.4f}\")\n",
    "print(f\"ROC/AUC: {avg_roc_auc:.4f}\")\n",
    "print(f\"Specificity: {avg_specificity:.4f}\")\n",
    "\n",
    "# Print selected features\n",
    "selected_features = X.columns[rfe.support_]\n",
    "print(\"Selected Features:\", selected_features.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549060e1",
   "metadata": {},
   "source": [
    "# RFE with Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e062806d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             confusion_matrix, roc_auc_score, f1_score)\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop('MonkeyPox', axis=1)  # Features\n",
    "y = data['MonkeyPox']  # Target variable\n",
    "\n",
    "# Split the dataset into training and testing sets (e.g., 80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Initialize RFE with the Gradient Boosting model\n",
    "rfe = RFE(estimator=gb_model, n_features_to_select=8)  # Change n_features_to_select as needed\n",
    "\n",
    "# Fit RFE on the training data\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Transform the training and testing sets to include only the selected features\n",
    "X_train_rfe = rfe.transform(X_train)\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "\n",
    "# Train the Gradient Boosting model on the selected features\n",
    "gb_model.fit(X_train_rfe, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = gb_model.predict(X_test_rfe)\n",
    "y_pred_proba = gb_model.predict_proba(X_test_rfe)[:, 1]  # Probability estimates for ROC/AUC\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Calculate specificity\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Print results\n",
    "print(\"Performance Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC/AUC: {roc_auc:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "\n",
    "# Print selected features\n",
    "selected_features = X.columns[rfe.support_]\n",
    "print(\"Selected Features:\", selected_features.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7cefb7",
   "metadata": {},
   "source": [
    "# RFE with Adaboost (NO k-fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4418a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             confusion_matrix, roc_auc_score, f1_score)\n",
    "\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop('MonkeyPox', axis=1)  # Features\n",
    "y = data['MonkeyPox']  # Target variable\n",
    "\n",
    "# Split the dataset into training and testing sets (e.g., 80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an AdaBoost model using a Decision Tree as the base estimator\n",
    "base_estimator = DecisionTreeClassifier(max_depth=1)  # Decision stump\n",
    "ada_model = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=50, random_state=42)\n",
    "\n",
    "# Initialize RFE with the AdaBoost model\n",
    "rfe = RFE(estimator=ada_model, n_features_to_select=7)  # Change n_features_to_select as needed\n",
    "\n",
    "# Fit RFE on the training data\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Transform the training and testing sets to include only the selected features\n",
    "X_train_rfe = rfe.transform(X_train)\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "\n",
    "# Train the AdaBoost model on the selected features\n",
    "ada_model.fit(X_train_rfe, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = ada_model.predict(X_test_rfe)\n",
    "y_pred_proba = ada_model.predict_proba(X_test_rfe)[:, 1]  # Probability estimates for ROC/AUC\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Calculate specificity\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Print results\n",
    "print(\"Performance Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC/AUC: {roc_auc:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "\n",
    "# Print selected features\n",
    "selected_features = X.columns[rfe.support_]\n",
    "print(\"Selected Features:\", selected_features.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e018d3ab",
   "metadata": {},
   "source": [
    "# RFE with XGBoost Without K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7866682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             confusion_matrix, roc_auc_score, f1_score)\n",
    "\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop('MonkeyPox', axis=1)  # Features\n",
    "y = data['MonkeyPox']  # Target variable\n",
    "\n",
    "# Split the dataset into training and testing sets (e.g., 80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an XGBoost model\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "# Initialize RFE with the XGBoost model\n",
    "rfe = RFE(estimator=model, n_features_to_select=7)  # Change n_features_to_select as needed\n",
    "\n",
    "# Fit RFE on the training data\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Transform the training and testing sets to include only the selected features\n",
    "X_train_rfe = rfe.transform(X_train)\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "\n",
    "# Train the XGBoost model on the selected features\n",
    "model.fit(X_train_rfe, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_rfe)\n",
    "y_pred_proba = model.predict_proba(X_test_rfe)[:, 1]  # Probability estimates for ROC/AUC\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Calculate specificity\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Print results\n",
    "print(\"Performance Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC/AUC: {roc_auc:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "\n",
    "# Print selected features\n",
    "selected_features = X.columns[rfe.support_]\n",
    "print(\"Selected Features:\", selected_features.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02521671",
   "metadata": {},
   "source": [
    "# Random Forest Feature Importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1bed5247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "                          Feature  Importance\n",
      "0                      Patient_ID    0.727945\n",
      "1                Systemic Illness    0.082671\n",
      "8                   HIV Infection    0.028580\n",
      "7                 Swollen Tonsils    0.025432\n",
      "2                     Rectal Pain    0.025329\n",
      "9  Sexually Transmitted Infection    0.024122\n",
      "6                 Solitary Lesion    0.023763\n",
      "5                    Oral Lesions    0.022080\n",
      "3                     Sore Throat    0.020502\n",
      "4                   Penile Oedema    0.019576\n",
      "Selected Features: ['Patient_ID', 'Systemic Illness', 'HIV Infection', 'Swollen Tonsils', 'Rectal Pain', 'Sexually Transmitted Infection']\n",
      "\n",
      "Performance Metrics:\n",
      "Accuracy: 0.6058\n",
      "Precision: 0.7002\n",
      "Recall: 0.6870\n",
      "F1 Score: 0.6935\n",
      "ROC AUC: 0.6147\n",
      "Confusion Matrix:\n",
      " [[ 799  955]\n",
      " [1016 2230]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score, confusion_matrix)\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop('MonkeyPox', axis=1)  # Features\n",
    "y = data['MonkeyPox']  # Target variable\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "# Create a DataFrame to hold feature names and their importance scores\n",
    "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
    "\n",
    "# Sort the DataFrame by importance scores in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print the feature importance\n",
    "print(\"Feature Importances:\")\n",
    "print(feature_importance_df)\n",
    "\n",
    "# Select features based on importance (e.g., top 10)\n",
    "top_features = feature_importance_df.head(6)['Feature'].tolist()\n",
    "X_train_selected = X_train[top_features]\n",
    "X_test_selected = X_test[top_features]\n",
    "\n",
    "# Train Random Forest on the selected features\n",
    "rf_model_selected = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_selected.fit(X_train_selected, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model_selected.predict(X_test_selected)\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, rf_model_selected.predict_proba(X_test_selected)[:, 1])\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print performance metrics\n",
    "# Print selected feature names\n",
    "print(\"Selected Features:\", top_features)\n",
    "print(\"\\nPerformance Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0925f23",
   "metadata": {},
   "source": [
    "# Lasso Regression Feature Importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "db9ad654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of selected features: 1\n",
      "Selected Features: ['Patient_ID']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "predict_proba is not available when  probability=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m recall \u001b[38;5;241m=\u001b[39m recall_score(y_test, y_pred)\n\u001b[0;32m     42\u001b[0m f1 \u001b[38;5;241m=\u001b[39m f1_score(y_test, y_pred)\n\u001b[1;32m---> 43\u001b[0m roc_auc \u001b[38;5;241m=\u001b[39m roc_auc_score(y_test, final_model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test_selected)[:, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Calculate confusion matrix\u001b[39;00m\n\u001b[0;32m     46\u001b[0m conf_matrix \u001b[38;5;241m=\u001b[39m confusion_matrix(y_test, y_pred)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_available_if.py:32\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor.__get__\u001b[1;34m(self, obj, owner)\u001b[0m\n\u001b[0;32m     26\u001b[0m attr_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(owner\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattribute_name)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# delegate only on instances, not the classes.\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;66;03m# this is to allow access to the docstrings.\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck(obj):\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m attr_err\n\u001b[0;32m     34\u001b[0m     out \u001b[38;5;241m=\u001b[39m MethodType(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn, obj)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:829\u001b[0m, in \u001b[0;36mBaseSVC._check_proba\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobability:\n\u001b[1;32m--> 829\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    830\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba is not available when  probability=False\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m         )\n\u001b[0;32m    832\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc_svc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnu_svc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    833\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba only implemented for SVC and NuSVC\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: predict_proba is not available when  probability=False"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score, confusion_matrix)\n",
    "from sklearn.svm import SVC  # Example model to train with selected features\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop('MonkeyPox', axis=1)  # Features\n",
    "y = data['MonkeyPox']  # Target variable\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and fit the Lasso Regression model\n",
    "lasso = Lasso(alpha=0.1)  # Set the regularization parameter\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances (coefficients)\n",
    "feature_importances = lasso.coef_\n",
    "\n",
    "# Select features based on non-zero coefficients\n",
    "selected_features =X.columns[feature_importances != 0]\n",
    "print(\"No of selected features:\",len(selected_features))\n",
    "print(\"Selected Features:\", selected_features.tolist())\n",
    "\n",
    "# Transform the training and testing sets to include only the selected features\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "# Train a model (e.g., SVM) on the selected features\n",
    "final_model = SVC()  # You can replace this with any other model you prefer\n",
    "final_model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = final_model.predict(X_test_selected)\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, final_model.predict_proba(X_test_selected)[:, 1])\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"\\nPerformance Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f028ef",
   "metadata": {},
   "source": [
    "# PCA with Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf16498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             confusion_matrix, roc_auc_score, f1_score)\n",
    "\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop('MonkeyPox', axis=1)  # Features\n",
    "y = data['MonkeyPox']  # Target variable\n",
    "\n",
    "# Split the dataset into training and testing sets (e.g., 80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features (important for PCA)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply PCA to reduce dimensions\n",
    "pca = PCA(n_components=8)  # Change n_components as needed\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Create a Gradient Boosting model\n",
    "model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model on the PCA-transformed data\n",
    "model.fit(X_train_pca, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_pca)\n",
    "y_pred_proba = model.predict_proba(X_test_pca)[:, 1]  # Probability estimates for ROC/AUC\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Calculate specificity\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Print results\n",
    "print(\"Performance Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC/AUC: {roc_auc:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "\n",
    "# Print explained variance ratio of the components\n",
    "print(\"Explained Variance Ratio of PCA Components:\", pca.explained_variance_ratio_)\n",
    "print(\"Selected Features:\", selected_features.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50870e8",
   "metadata": {},
   "source": [
    "# PCA  with Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395e757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             confusion_matrix, roc_auc_score, f1_score)\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop('MonkeyPox', axis=1)  # Features\n",
    "y = data['MonkeyPox']  # Target variable\n",
    "\n",
    "# Split the dataset into training and testing sets (e.g., 80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features (important for PCA)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply PCA to reduce dimensions\n",
    "pca = PCA(n_components=8)  # Change n_components as needed\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Create an AdaBoost model using a Decision Tree as the base estimator\n",
    "base_estimator = DecisionTreeClassifier(max_depth=1)  # Decision stump\n",
    "ada_model = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=50, random_state=42)\n",
    "\n",
    "# Train the model on the PCA-transformed data\n",
    "ada_model.fit(X_train_pca, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = ada_model.predict(X_test_pca)\n",
    "y_pred_proba = ada_model.predict_proba(X_test_pca)[:, 1]  # Probability estimates for ROC/AUC\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Calculate specificity\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Print results\n",
    "print(\"Performance Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC/AUC: {roc_auc:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "\n",
    "# Print explained variance ratio of the components and selected features names from PCA\n",
    "print(\"Explained Variance Ratio of PCA Components:\", pca.explained_variance_ratio_)\n",
    "\n",
    "# Print component loadings for understanding feature contributions\n",
    "loadings = pd.DataFrame(pca.components_.T, index=X.columns, columns=[f'PC{i+1}' for i in range(pca.n_components_)])\n",
    "print(\"PCA Component Loadings:\")\n",
    "print(loadings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48678bb5",
   "metadata": {},
   "source": [
    "# PCA  with  XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26d2907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             confusion_matrix, roc_auc_score, f1_score)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop('MonkeyPox', axis=1)  # Features\n",
    "y = data['MonkeyPox']  # Target variable\n",
    "\n",
    "# Split the dataset into training and testing sets (e.g., 80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features (important for PCA)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply PCA to reduce dimensions\n",
    "pca = PCA(n_components=8)  # Change n_components as needed\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Create an XGBoost model\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "# Train the model on the PCA-transformed data\n",
    "model.fit(X_train_pca, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_pca)\n",
    "y_pred_proba = model.predict_proba(X_test_pca)[:, 1]  # Probability estimates for ROC/AUC\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Calculate specificity\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Print results\n",
    "print(\"Performance Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC/AUC: {roc_auc:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "\n",
    "# Print explained variance ratio of the components and selected features names from PCA\n",
    "print(\"Explained Variance Ratio of PCA Components:\", pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6601913e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
